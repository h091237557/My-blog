<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>It 鐵人賽 2019 on 拿鐵派的馬克 Blog</title>
    <link>https://mark-lin.com/tags/it-%E9%90%B5%E4%BA%BA%E8%B3%BD-2019/</link>
    <description>Recent content in It 鐵人賽 2019 on 拿鐵派的馬克 Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <managingEditor>h091237557@gmail.com (marklin)</managingEditor>
    <webMaster>h091237557@gmail.com (marklin)</webMaster>
    <lastBuildDate>Mon, 30 Sep 2019 20:16:57 +0800</lastBuildDate>
    
        <atom:link href="https://mark-lin.com/tags/it-%E9%90%B5%E4%BA%BA%E8%B3%BD-2019/index.xml" rel="self" type="application/rss+xml" />
    


    <item>
      <title>30-30 之馬克版的一個好的系統攻略本 - 性能基礎篇</title>
      <link>https://mark-lin.com/posts/20190930/</link>
      <pubDate>Mon, 30 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190930/</guid>
      <description>這漫長辛苦的 30 天總於結束囉 ~ 接下來依慣例第 30 天都是總結篇。
這 30 天的過程咱們都在追求『 一個好的系統 』中的其中一個重點 :
 性能
 性能越高的系統，可以帶給『 公司 』與『 用戶 』雙方都達到愉悅的情況。
咱們先看看第一階段最基本系統的樣子。
單機的優化方向 應用層方面性能優化重點知識 這下面 7 篇文章，應該涵蓋住了應用層性能方面所需要注意的重點，雖然有分 cpu 與 i/o 優化，但是我是覺得也不用分到那麼清楚，只要記得，你是要儘可能的以最少資源來做事情就對囉。
 運算與 i/o 是重點，但總結來說就是『 儘可能的以最少資源來做最多的事情 』
  30-03 之應用層的運算加速 - 演算法 30-04 之應用層的運算加速 - 並行運算 30-05 之應用層的 I / O 加速 - 零拷貝 ( Zero Copy ) 30-06 之應用層的 I / O 優化 - Stream ( 與一些 IPC 知識 ) 30-07 之應用層的 I/O 優化 - 非阻塞 I/O 模型 Reactor 30-08 之應用層的 I/O 優化 ( 維護性 ) - 協程 Coroutine 30-09之應用層的兩個池 - 進 ( 線 ) 程池與連線池  資料庫層優化重點知識 接下來到一個系統的命脈『 資料庫層 』的性能優化知識。這裡的最大重點在於 :</description>
    </item>
    
    <item>
      <title>30-29 之資料庫層擴展中間件 - MyCAT 的淺淺談</title>
      <link>https://mark-lin.com/posts/20190929/</link>
      <pubDate>Sun, 29 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190929/</guid>
      <description>正文開始 前面幾篇文章中，咱們提到了如何擴展資料庫層級服務，讓它可以接更多的客，但是這些擴展方法中，都有提到一個『 中間件 』來使用，接下後本篇文章中，咱們將介紹其中一種比較常見的中間件 :
 MyCAT
 本篇文章分為以下幾個章節 :
 MyCAT 基本概念 MyCAT 的各種架構實現配置 使用 Docker 來實現 MyCAT 讀寫分離  MyCAT 基本概念 在資料庫中間件中，事實上分為兩種類型 :
 proxy smart-client  它們兩個的基本差別如下圖 1 所示，proxy 是一個外部的服務，所有的應用都會透過這個 proxy 服務來操作資料庫。
而 smart-client 概念就是包在應用層中，當成一個 sdk 概念的程式碼。
圖 1 : proxy vs smart-client
而其中 mycat 就是屬於 proxy 的其中一種應用。
~ 小知識 ~
現在幾個比較可以說的出名字的中間件有 :
proxy : cobar、mycat、mysql-router、atlas、vitess smart-client : 大部份語言有實現簡單版的，而如果是支援比較多功能的有 sharding-jdbc、tddl。
有興趣的友人可以自已查查來比較看看。
這裡問一下，那一種比較好呢 ? 首先咱們先說說 smart-client 的優點 :</description>
    </item>
    
    <item>
      <title>30-28 之資料庫層擴展難題 -  MySQL 分散式事務處理</title>
      <link>https://mark-lin.com/posts/20190928/</link>
      <pubDate>Sat, 28 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190928/</guid>
      <description>正文開始 本篇文章中，咱們要來說說分散式系統中，最麻煩的部份『 分散式事務 』這一塊，接下來咱們來認真的理一下這個鬼。
本篇分為以下幾個章節 :
 分散式事務難題 分散式事務的處理方案 : 2 PC 二階段提交（ Two-phase Commit ） MySQL XA 事務實現與使用 MySQL XA 問題 - 性能  分散式事務難題 首先咱們都知道資料庫有所謂的『 事務 』機制，比較準備的說是事務這個『 單位 』，它當初建立出來是為了解決所謂的 :
 確保『 同一組資料庫業務操作 』可以有正確的結果
 它們不會因為某項業務的其中一項操作錯誤了，導致整個資料庫的資料不正確 ( A )。
它們不會因為系統固障而導致原本成功修改的資料消失 ( D )。
它們不會因為並行操作，導致資料產生產生無法預期的結果 ( I )。
總而言之，事務在固障與並行的情況下，不會產生所謂的『 資料不一致性 』 ( C )
如果事務可以確保上述事情，那就可以說 :
 這個事務有 ACID 的特性
 然後咱們在以下三篇文章中，咱們有談到，在 mysql 單機事務的情況下，它們用了以下的機制來確保這些機制 :
 原子性 A : undo log 持久性 D : redo log 隔離性 I : 鎖 + mvcc  30-15 之資料庫層的難題 - 單機『 故障 』一致性難題</description>
    </item>
    
    <item>
      <title>30-27之資料庫層的擴展 - 分區表</title>
      <link>https://mark-lin.com/posts/20190927/</link>
      <pubDate>Fri, 27 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190927/</guid>
      <description>正文開始 上一篇文章中，咱們有提到了兩種資料庫層的擴展方式 :
 分庫 分表  其中分表是用來解決單表太大的問題，而接下來本章節要來介紹另一種處理單表太的工具 :
 分區表
 本篇文章分以下幾個章節 :
 分區概念 MySQL 分區的切分類型 分區使用的注意事項  分區概念 分區表的核心概念為 :
 將一張大表，根據『 規則 』拆分為『 隱藏 』的小表
 觀念和分表事實上完全相同，就差在『 隱藏 』這個字詞上。它們的差異如下
 分表 : 分表後，應用層需要修改 sql 操作位置，指定到對應的分表上。 分區 : 分區後，應用層『 不 』需要修改 sql 操作位置，資料庫層會自動幫你處理。  也就是說假設是使用 type 這個欄位來『 分表 』那你在查詢時可能需為變成如下指令 :
user 根據 type 拆分成三個表 : 1. user_type_A 表 2. user_type_B 表 3. user_type_C 長 SELECT * FROM user_type_A WHERE name = &#39;mark&#39;; 而如果是『 分區表 』的話為 :</description>
    </item>
    
    <item>
      <title>30-26之資料庫層的擴展 - 分庫分表架構</title>
      <link>https://mark-lin.com/posts/20190926/</link>
      <pubDate>Thu, 26 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190926/</guid>
      <description>正文開始 上一篇文章中，咱們介紹了資料庫層的分散的第一個起手式『 讀寫分離 』，這個方案是將寫與讀分散在不同的機器上，正常情況下，大部份的系統使用這種方案就已經可以處理很好了。
但 !
如果你已經將資料庫層與緩存層的架構都已經建立好，但還是發現有性能貧頸，那接下來才會建議使用幾個方案，因為這些方案沒用好，會衍生出非常多的問題。
本篇文章分為以下幾個章節，這些就是接下來咱們要來學的擴展法。
 分庫 分表 分庫與分表的問題  重要 : 使用前注意事項 要使用以下的擴展方法時，先確認你的資料庫是否以下的問題是否有發生。
 問題 1 : 單庫太大，導致硬碟空間不夠囉。 問題 2 : 單庫寫入量太大，導致每一次新增或更新性能非常的吃緊，感覺隨時都會上天堂。 問題 3 : 單表資料量太太，導致每一次操作時都非常的慢。  有以上事情發生才開始往接下來的擴展走。
 沒事真的別用它們
 分庫  它可以解決 問題 1 : 單庫太大，導致硬碟空間不夠囉 與 問題 2 : 單庫寫入量太大，導致每一次新增或更新性能非常的吃緊
 首先第一個要介紹的就是分庫，它的基本定義如下 :
 將一個大大的資料庫，依據『 規則 』拆分成小的資料庫
 其中上述說的規則，在傳統上可以分為以下幾種 :
 垂直切分 : 根據『 業務 』來拆分成多個小資料庫 ( 圖 1 所示 )。 水平切分 : 根據『 特性 』來拆分成多個小資料庫，例如地區 ( 圖 2 所示 )。  圖 1 : 垂直切分範例</description>
    </item>
    
    <item>
      <title>30-25之資料庫層的擴展 - 讀寫分離架構</title>
      <link>https://mark-lin.com/posts/20190925/</link>
      <pubDate>Wed, 25 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190925/</guid>
      <description>正文開始 前面的文章我們說明完應用層的分散式架構以後，接下來我們要來思考如果讓『 資料庫層 』做更多的事情。
在正式開始章節之前，我們先來想想看一件事情。
 資料庫層可以向應用層一樣加機器，就可以做更多的事情嗎 ?
 答案為是或不是，這個就取決於使用者的能力，因為假設你沒處理好，不但有可能性能下降，而且導致錯誤百出，它不像應用層那麼簡單的主要原因在於 :
 它有狀態的，因為它有儲資料，所有會有一致性問題。
 應用層在進行分散式時，基本上都是處於無狀態狀況，所以在進行多台機器時，事實上我們不太需要考慮什麼資料一致的問題，而資料庫則否，當多台時，就要面臨到所謂的資料一致性問題。
接下來的文章與章節我們將要來細說，資料庫層如何的使用分散式架構來讓它做更多的事情，並且有更高的可用性，以及它接下來要面對的種種問題。
本篇文章中，咱們將要先來談談，第一種資料庫層的分散式架構方案『 讀寫分離架構 』:
 它適用於讀多寫少情況
 本篇文章共分為以下幾個章節 :
 讀寫分離架構概念 MySQL 的讀寫分離架構實現 可能面臨問題探討  這個分散技術基本上應該是資料庫層分散的第一個起手式，單完成這個架構就已經可以處理不少的事情囉。
資料庫層的讀寫分離架構 基本架構 讀寫分離最簡單的就是所有寫入的都寫入到一台服務，讀取時讀取一台服務，然後你們之間會進行資料同步。
然後在實務上，咱們通常都是會搭配主從架構 ( master-slave ) 來進行讀寫分離。主從架構本來存在的目的是為了可用，就也是如果 master 壞掉了，咱們還有 slave 有資料。
 master : 主要用寫的服務，會與 slave 進行資料同步。 slave : 主要用來讀的服務  圖 2 : master-slave 實現讀寫概念圖
讀進化型架構 之前咱們有提過，現在大部份的系統基本上應該是讀大於寫入，所以如果這時只有一台讀，也是有可能會讓它壓力很大，所以這時會變成如圖 3 所示，加個幾台讀機，這種架構被稱為『 一主多從 』。
然後這裡有幾個重點，那就是要如何實現圖 3 的『 分配器 』。
圖 3 : 讀進化型架構圖</description>
    </item>
    
    <item>
      <title>30-24 之應用層擴展『 外傳 』 - IM 服務擴展與雷坑</title>
      <link>https://mark-lin.com/posts/20190924/</link>
      <pubDate>Tue, 24 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190924/</guid>
      <description>正文開始 上一篇文章中，咱們理解了一般 web 系統的擴展方法後，接下來我們來一篇外傳，來說說關於 即時通訊服務 ( IM Instant Messaging Service ) 的擴展。
本篇文章共分以下幾個章節 :
 IM 服務的先行知識 IM 服務的擴展方案 1 - 負載均衡 IM 服務的擴展方案 2 : IM 服務分配器  在開台之前咱們先來簡單的談談，什麼是即時通訊服務的擴展。
簡單的說就是像 line 一樣可以進行即時的溝通。
傳統上要建立這種類型的系統，通常會使用以下兩種機制來建立雙向的溝通 :
IM 服務的先行知識 首先一般 web 應用都是使用 http 單向的來取得資料，也就是 request 然後 response 這種機制，但是在 im 這種服務系統中，場景通常都是 client A 發送訊息，然後 client B 會收到。
 IM 服務就是像聊天室例如 Line 這種類型的服務
 而通常要實現這個功能目前應該只有兩種機制 :
 long polling websocket  咱們來簡單用下圖 1 來看一下這兩種運行的差別。</description>
    </item>
    
    <item>
      <title>30-23 之應用層的擴展 - 負載均衡服務</title>
      <link>https://mark-lin.com/posts/20190923/</link>
      <pubDate>Mon, 23 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190923/</guid>
      <description>正文開始 前面幾篇的文章中，我們知道如何儘可能的在單機上，可以以最少的資源做最多的事，但是單機一定有它的限制，因此接下來我們要開始正式進入所謂的『 分散式系統 』。
分散式系統不是簡單的增加機器就可以增加效能那麼簡單，它不是簡單的 1 + 1 = 2 的這種概念，有時後 1 + 1 還會小於 2 或小於 1。
最要的原因在於要達成一致性的難度更高，並且維護與管理更複雜，除非你單機真的已經到了極限，不然如果是為了『 性能 』而加機器，那也只是會浪費你更多的時間，不過在實務上有時是為了可用性而加機器那這到還可接受。
本篇文章將分為以下幾個章節 :
 應用層擴展基本架構 負載均衡架構優化 擴展後第一個問題 - Session  應用層擴展基本架構 應用層擴展基本上 90 % 都會是長的如下圖 1 架構。
圖 1 : 基本擴展型
基本上會將應用服務變成多台，然後前面加一個負載均衡 ( Load balancing )，每當用戶有請求進來時，會先通過負載均衡服務，然後它會選一台應用服務來將請求送過去。
目前在 web 領域比較常用的負載均衡服務應該是『 nginx 』，它的基本架構就如同咱們前面章節所說的 reactor 架構，所以基本上它可以處理非常多的連線。
30-07 之應用層的 I/O 優化 - 非阻塞 I/O 模型 Reactor
然後 nginx 它有提供以下幾種的分配演算法 :
 輪詢 : 也就是所謂的輪流分配，每個能基本上都可以平均的收到。 加權 : 根據應用服務的能力來決定分配，例如機器性能較好的就給他權限較高，差的則給權限較低，這個地方在 nginx 還有很多變化。 ip_hash : 就是同 ip 的都會打到同一台，這個在 socketio 擴展時很重要，如果沒設置，建立 socketio 連線時會打錯台。 url_hash : 打同一個 url 會到同一台。 fair : 簡單的說就是智能的演算法，它會根據頁面大小、加載時間來智慧的選擇應用服務。  負載均衡優化方向 接下來這個章節，咱們要來看看負載均衡的一些優化方向</description>
    </item>
    
    <item>
      <title>30-22 之網路傳輸的優化 - HTTP 1.0 至 HTTP 3.0</title>
      <link>https://mark-lin.com/posts/20190922/</link>
      <pubDate>Sun, 22 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190922/</guid>
      <description>正文開始 本篇文章中，網路世界最重的協議 http，不只如上圖應用所示只有用戶端那有用到，現階段大部份很多 server 都還是會實用 http 去其它 server 取資料，所以一個系統中，最重要的應用層協議，咱們幾乎可能說是『 Http 』。
本篇文章分為以下幾個章節，事實上也就是所謂的 http 進化史 :
 HTTP 行前基本知識 HTTP 1.X 的過去式 HTTP 2.0 的現在式 HTTP 3.0 的未來式  網路層的 http 優化事實上沒有啥重點，那就是 :
 儘可能將 http 升級更高的版本
 但是，為什麼要升級才是這一篇文章的重點。
Http 行前基本知識 在這篇文章正式開始一前，咱們有些前知識要來學習一下，不然下面會有很多東西看不太種。
首先 http 基本上可以說是網路世界的基礎，它當初建立出來的目的是為讓瀏覽器這個應用層的應用使用，然後它在傳輸資料時所使用的協議為『 TCP 』，所以當咱們要建立連線時會進行所謂的『 TCP 三次握手 』如下圖 1 所示 :
圖 1 : tcp 建立連線 ( 三次握手 )
然後有了這個連線以後，咱們就可以開始進行資料傳輸。
圖 2 : tcp 傳輸資料
最後斷線時就有所謂的四次揮手。
圖 3 : tcp 斷線 ( 四次揮手 )</description>
    </item>
    
    <item>
      <title>30-21 之網路傳輸的加速 - CDN 與 HTTP 緩存</title>
      <link>https://mark-lin.com/posts/20190921/</link>
      <pubDate>Sat, 21 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190921/</guid>
      <description>正文開始 前幾篇文章中，咱們討論完資料庫層的資料緩存以後，接下來咱們要來談談另外兩個緩存 :
 CDN ( Content Delivery Network ) HTTP 緩存  本篇文章分為以下幾個章節 :
 CDN 與運行流程 HTTP 緩存與運行流程 CDN 與 HTTP 緩存搞在一起用  這裡先說一下，接下來有一些 cdn 的章節我是直接抓以前我寫的文章來簡單修改一下，不然我還真想不到 cdn 這還要寫什麼。
30-23之 CDN 的說話島 ( AWS CloudFront CDN 實作 )
CDN 與運行流程 在開始理解 CDN 之前，咱們先來說說傳統上一個 client 連線到一個網站的流程。
首先看看下面這張圖 1 所示，這張圖說明了每當一個 client 發送一個請求到 web 網站時，web 網站會回傳 html、css 與 javascript 回來，這裡假設咱們的 web 網站還在台灣，然後回應時間大約在 100 ms 以內 (假設)。
圖 1 : 一個台灣用戶連到台灣網站的時間
然後呢 ~ 這時付你錢的老大叫你將 web 網路架設到美國，因爲免費，然後這時發現回應時間變成 1000 ms 左右，如下圖 2 所示。</description>
    </item>
    
  </channel>
</rss>