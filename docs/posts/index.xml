<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on 拿鐵派的馬克 Blog</title>
    <link>https://mark-lin.com/posts/</link>
    <description>Recent content in Posts on 拿鐵派的馬克 Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ja</language>
    <managingEditor>h091237557@gmail.com (marklin)</managingEditor>
    <webMaster>h091237557@gmail.com (marklin)</webMaster>
    <lastBuildDate>Mon, 30 Sep 2019 20:16:57 +0800</lastBuildDate>
    
	<atom:link href="https://mark-lin.com/posts/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>30-30 之馬克版的一個好的系統攻略本 - 性能基礎篇</title>
      <link>https://mark-lin.com/posts/20190930/</link>
      <pubDate>Mon, 30 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190930/</guid>
      <description>這漫長辛苦的 30 天總於結束囉 ~ 接下來依慣例第 30 天都是總結篇。
這 30 天的過程咱們都在追求『 一個好的系統 』中的其中一個重點 :
 性能
 性能越高的系統，可以帶給『 公司 』與『 用戶 』雙方都達到愉悅的情況。
咱們先看看第一階段最基本系統的樣子。
單機的優化方向 應用層方面性能優化重點知識 這下面 7 篇文章，應該涵蓋住了應用層性能方面所需要注意的重點，雖然有分 cpu 與 i/o 優化，但是我是覺得也不用分到那麼清楚，只要記得，你是要儘可能的以最少資源來做事情就對囉。
 運算與 i/o 是重點，但總結來說就是『 儘可能的以最少資源來做最多的事情 』
  30-03 之應用層的運算加速 - 演算法 30-04 之應用層的運算加速 - 並行運算 30-05 之應用層的 I / O 加速 - 零拷貝 ( Zero Copy ) 30-06 之應用層的 I / O 優化 - Stream ( 與一些 IPC 知識 ) 30-07 之應用層的 I/O 優化 - 非阻塞 I/O 模型 Reactor 30-08 之應用層的 I/O 優化 ( 維護性 ) - 協程 Coroutine 30-09之應用層的兩個池 - 進 ( 線 ) 程池與連線池  資料庫層優化重點知識 接下來到一個系統的命脈『 資料庫層 』的性能優化知識。這裡的最大重點在於 :</description>
    </item>
    
    <item>
      <title>30-29 之資料庫層擴展中間件 - MyCAT 的淺淺談</title>
      <link>https://mark-lin.com/posts/20190929/</link>
      <pubDate>Sun, 29 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190929/</guid>
      <description>正文開始 前面幾篇文章中，咱們提到了如何擴展資料庫層級服務，讓它可以接更多的客，但是這些擴展方法中，都有提到一個『 中間件 』來使用，接下後本篇文章中，咱們將介紹其中一種比較常見的中間件 :
 MyCAT
 本篇文章分為以下幾個章節 :
 MyCAT 基本概念 MyCAT 的各種架構實現配置 使用 Docker 來實現 MyCAT 讀寫分離  MyCAT 基本概念 在資料庫中間件中，事實上分為兩種類型 :
 proxy smart-client  它們兩個的基本差別如下圖 1 所示，proxy 是一個外部的服務，所有的應用都會透過這個 proxy 服務來操作資料庫。
而 smart-client 概念就是包在應用層中，當成一個 sdk 概念的程式碼。
圖 1 : proxy vs smart-client
而其中 mycat 就是屬於 proxy 的其中一種應用。
~ 小知識 ~
現在幾個比較可以說的出名字的中間件有 :
proxy : cobar、mycat、mysql-router、atlas、vitess smart-client : 大部份語言有實現簡單版的，而如果是支援比較多功能的有 sharding-jdbc、tddl。
有興趣的友人可以自已查查來比較看看。
這裡問一下，那一種比較好呢 ? 首先咱們先說說 smart-client 的優點 :</description>
    </item>
    
    <item>
      <title>30-28 之資料庫層擴展難題 -  MySQL 分散式事務處理</title>
      <link>https://mark-lin.com/posts/20190928/</link>
      <pubDate>Sat, 28 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190928/</guid>
      <description>正文開始 本篇文章中，咱們要來說說分散式系統中，最麻煩的部份『 分散式事務 』這一塊，接下來咱們來認真的理一下這個鬼。
本篇分為以下幾個章節 :
 分散式事務難題 分散式事務的處理方案 : 2 PC 二階段提交（ Two-phase Commit ） MySQL XA 事務實現與使用 MySQL XA 問題 - 性能  分散式事務難題 首先咱們都知道資料庫有所謂的『 事務 』機制，比較準備的說是事務這個『 單位 』，它當初建立出來是為了解決所謂的 :
 確保『 同一組資料庫業務操作 』可以有正確的結果
 它們不會因為某項業務的其中一項操作錯誤了，導致整個資料庫的資料不正確 ( A )。
它們不會因為系統固障而導致原本成功修改的資料消失 ( D )。
它們不會因為並行操作，導致資料產生產生無法預期的結果 ( I )。
總而言之，事務在固障與並行的情況下，不會產生所謂的『 資料不一致性 』 ( C )
如果事務可以確保上述事情，那就可以說 :
 這個事務有 ACID 的特性
 然後咱們在以下三篇文章中，咱們有談到，在 mysql 單機事務的情況下，它們用了以下的機制來確保這些機制 :
 原子性 A : undo log 持久性 D : redo log 隔離性 I : 鎖 + mvcc  30-15 之資料庫層的難題 - 單機『 故障 』一致性難題</description>
    </item>
    
    <item>
      <title>30-27之資料庫層的擴展 - 分區表</title>
      <link>https://mark-lin.com/posts/20190927/</link>
      <pubDate>Fri, 27 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190927/</guid>
      <description>正文開始 上一篇文章中，咱們有提到了兩種資料庫層的擴展方式 :
 分庫 分表  其中分表是用來解決單表太大的問題，而接下來本章節要來介紹另一種處理單表太的工具 :
 分區表
 本篇文章分以下幾個章節 :
 分區概念 MySQL 分區的切分類型 分區使用的注意事項  分區概念 分區表的核心概念為 :
 將一張大表，根據『 規則 』拆分為『 隱藏 』的小表
 觀念和分表事實上完全相同，就差在『 隱藏 』這個字詞上。它們的差異如下
 分表 : 分表後，應用層需要修改 sql 操作位置，指定到對應的分表上。 分區 : 分區後，應用層『 不 』需要修改 sql 操作位置，資料庫層會自動幫你處理。  也就是說假設是使用 type 這個欄位來『 分表 』那你在查詢時可能需為變成如下指令 :
user 根據 type 拆分成三個表 : 1. user_type_A 表 2. user_type_B 表 3. user_type_C 長 SELECT * FROM user_type_A WHERE name = &#39;mark&#39;; 而如果是『 分區表 』的話為 :</description>
    </item>
    
    <item>
      <title>30-26之資料庫層的擴展 - 分庫分表架構</title>
      <link>https://mark-lin.com/posts/20190926/</link>
      <pubDate>Thu, 26 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190926/</guid>
      <description>正文開始 上一篇文章中，咱們介紹了資料庫層的分散的第一個起手式『 讀寫分離 』，這個方案是將寫與讀分散在不同的機器上，正常情況下，大部份的系統使用這種方案就已經可以處理很好了。
但 !
如果你已經將資料庫層與緩存層的架構都已經建立好，但還是發現有性能貧頸，那接下來才會建議使用幾個方案，因為這些方案沒用好，會衍生出非常多的問題。
本篇文章分為以下幾個章節，這些就是接下來咱們要來學的擴展法。
 分庫 分表 分庫與分表的問題  重要 : 使用前注意事項 要使用以下的擴展方法時，先確認你的資料庫是否以下的問題是否有發生。
 問題 1 : 單庫太大，導致硬碟空間不夠囉。 問題 2 : 單庫寫入量太大，導致每一次新增或更新性能非常的吃緊，感覺隨時都會上天堂。 問題 3 : 單表資料量太太，導致每一次操作時都非常的慢。  有以上事情發生才開始往接下來的擴展走。
 沒事真的別用它們
 分庫  它可以解決 問題 1 : 單庫太大，導致硬碟空間不夠囉 與 問題 2 : 單庫寫入量太大，導致每一次新增或更新性能非常的吃緊
 首先第一個要介紹的就是分庫，它的基本定義如下 :
 將一個大大的資料庫，依據『 規則 』拆分成小的資料庫
 其中上述說的規則，在傳統上可以分為以下幾種 :
 垂直切分 : 根據『 業務 』來拆分成多個小資料庫 ( 圖 1 所示 )。 水平切分 : 根據『 特性 』來拆分成多個小資料庫，例如地區 ( 圖 2 所示 )。  圖 1 : 垂直切分範例</description>
    </item>
    
    <item>
      <title>30-25之資料庫層的擴展 - 讀寫分離架構</title>
      <link>https://mark-lin.com/posts/20190925/</link>
      <pubDate>Wed, 25 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190925/</guid>
      <description>正文開始 前面的文章我們說明完應用層的分散式架構以後，接下來我們要來思考如果讓『 資料庫層 』做更多的事情。
在正式開始章節之前，我們先來想想看一件事情。
 資料庫層可以向應用層一樣加機器，就可以做更多的事情嗎 ?
 答案為是或不是，這個就取決於使用者的能力，因為假設你沒處理好，不但有可能性能下降，而且導致錯誤百出，它不像應用層那麼簡單的主要原因在於 :
 它有狀態的，因為它有儲資料，所有會有一致性問題。
 應用層在進行分散式時，基本上都是處於無狀態狀況，所以在進行多台機器時，事實上我們不太需要考慮什麼資料一致的問題，而資料庫則否，當多台時，就要面臨到所謂的資料一致性問題。
接下來的文章與章節我們將要來細說，資料庫層如何的使用分散式架構來讓它做更多的事情，並且有更高的可用性，以及它接下來要面對的種種問題。
本篇文章中，咱們將要先來談談，第一種資料庫層的分散式架構方案『 讀寫分離架構 』:
 它適用於讀多寫少情況
 本篇文章共分為以下幾個章節 :
 讀寫分離架構概念 MySQL 的讀寫分離架構實現 可能面臨問題探討  這個分散技術基本上應該是資料庫層分散的第一個起手式，單完成這個架構就已經可以處理不少的事情囉。
資料庫層的讀寫分離架構 基本架構 讀寫分離最簡單的就是所有寫入的都寫入到一台服務，讀取時讀取一台服務，然後你們之間會進行資料同步。
然後在實務上，咱們通常都是會搭配主從架構 ( master-slave ) 來進行讀寫分離。主從架構本來存在的目的是為了可用，就也是如果 master 壞掉了，咱們還有 slave 有資料。
 master : 主要用寫的服務，會與 slave 進行資料同步。 slave : 主要用來讀的服務  圖 2 : master-slave 實現讀寫概念圖
讀進化型架構 之前咱們有提過，現在大部份的系統基本上應該是讀大於寫入，所以如果這時只有一台讀，也是有可能會讓它壓力很大，所以這時會變成如圖 3 所示，加個幾台讀機，這種架構被稱為『 一主多從 』。
然後這裡有幾個重點，那就是要如何實現圖 3 的『 分配器 』。
圖 3 : 讀進化型架構圖</description>
    </item>
    
    <item>
      <title>30-24 之應用層擴展『 外傳 』 - IM 服務擴展與雷坑</title>
      <link>https://mark-lin.com/posts/20190924/</link>
      <pubDate>Tue, 24 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190924/</guid>
      <description>正文開始 上一篇文章中，咱們理解了一般 web 系統的擴展方法後，接下來我們來一篇外傳，來說說關於 即時通訊服務 ( IM Instant Messaging Service ) 的擴展。
本篇文章共分以下幾個章節 :
 IM 服務的先行知識 IM 服務的擴展方案 1 - 負載均衡 IM 服務的擴展方案 2 : IM 服務分配器  在開台之前咱們先來簡單的談談，什麼是即時通訊服務的擴展。
簡單的說就是像 line 一樣可以進行即時的溝通。
傳統上要建立這種類型的系統，通常會使用以下兩種機制來建立雙向的溝通 :
IM 服務的先行知識 首先一般 web 應用都是使用 http 單向的來取得資料，也就是 request 然後 response 這種機制，但是在 im 這種服務系統中，場景通常都是 client A 發送訊息，然後 client B 會收到。
 IM 服務就是像聊天室例如 Line 這種類型的服務
 而通常要實現這個功能目前應該只有兩種機制 :
 long polling websocket  咱們來簡單用下圖 1 來看一下這兩種運行的差別。</description>
    </item>
    
    <item>
      <title>30-23 之應用層的擴展 - 負載均衡服務</title>
      <link>https://mark-lin.com/posts/20190923/</link>
      <pubDate>Mon, 23 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190923/</guid>
      <description>正文開始 前面幾篇的文章中，我們知道如何儘可能的在單機上，可以以最少的資源做最多的事，但是單機一定有它的限制，因此接下來我們要開始正式進入所謂的『 分散式系統 』。
分散式系統不是簡單的增加機器就可以增加效能那麼簡單，它不是簡單的 1 + 1 = 2 的這種概念，有時後 1 + 1 還會小於 2 或小於 1。
最要的原因在於要達成一致性的難度更高，並且維護與管理更複雜，除非你單機真的已經到了極限，不然如果是為了『 性能 』而加機器，那也只是會浪費你更多的時間，不過在實務上有時是為了可用性而加機器那這到還可接受。
本篇文章將分為以下幾個章節 :
 應用層擴展基本架構 負載均衡架構優化 擴展後第一個問題 - Session  應用層擴展基本架構 應用層擴展基本上 90 % 都會是長的如下圖 1 架構。
圖 1 : 基本擴展型
基本上會將應用服務變成多台，然後前面加一個負載均衡 ( Load balancing )，每當用戶有請求進來時，會先通過負載均衡服務，然後它會選一台應用服務來將請求送過去。
目前在 web 領域比較常用的負載均衡服務應該是『 nginx 』，它的基本架構就如同咱們前面章節所說的 reactor 架構，所以基本上它可以處理非常多的連線。
30-07 之應用層的 I/O 優化 - 非阻塞 I/O 模型 Reactor
然後 nginx 它有提供以下幾種的分配演算法 :
 輪詢 : 也就是所謂的輪流分配，每個能基本上都可以平均的收到。 加權 : 根據應用服務的能力來決定分配，例如機器性能較好的就給他權限較高，差的則給權限較低，這個地方在 nginx 還有很多變化。 ip_hash : 就是同 ip 的都會打到同一台，這個在 socketio 擴展時很重要，如果沒設置，建立 socketio 連線時會打錯台。 url_hash : 打同一個 url 會到同一台。 fair : 簡單的說就是智能的演算法，它會根據頁面大小、加載時間來智慧的選擇應用服務。  負載均衡優化方向 接下來這個章節，咱們要來看看負載均衡的一些優化方向</description>
    </item>
    
    <item>
      <title>30-22 之網路傳輸的優化 - HTTP 1.0 至 HTTP 3.0</title>
      <link>https://mark-lin.com/posts/20190922/</link>
      <pubDate>Sun, 22 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190922/</guid>
      <description>正文開始 本篇文章中，網路世界最重的協議 http，不只如上圖應用所示只有用戶端那有用到，現階段大部份很多 server 都還是會實用 http 去其它 server 取資料，所以一個系統中，最重要的應用層協議，咱們幾乎可能說是『 Http 』。
本篇文章分為以下幾個章節，事實上也就是所謂的 http 進化史 :
 HTTP 行前基本知識 HTTP 1.X 的過去式 HTTP 2.0 的現在式 HTTP 3.0 的未來式  網路層的 http 優化事實上沒有啥重點，那就是 :
 儘可能將 http 升級更高的版本
 但是，為什麼要升級才是這一篇文章的重點。
Http 行前基本知識 在這篇文章正式開始一前，咱們有些前知識要來學習一下，不然下面會有很多東西看不太種。
首先 http 基本上可以說是網路世界的基礎，它當初建立出來的目的是為讓瀏覽器這個應用層的應用使用，然後它在傳輸資料時所使用的協議為『 TCP 』，所以當咱們要建立連線時會進行所謂的『 TCP 三次握手 』如下圖 1 所示 :
圖 1 : tcp 建立連線 ( 三次握手 )
然後有了這個連線以後，咱們就可以開始進行資料傳輸。
圖 2 : tcp 傳輸資料
最後斷線時就有所謂的四次揮手。
圖 3 : tcp 斷線 ( 四次揮手 )</description>
    </item>
    
    <item>
      <title>30-21 之網路傳輸的加速 - CDN 與 HTTP 緩存</title>
      <link>https://mark-lin.com/posts/20190921/</link>
      <pubDate>Sat, 21 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190921/</guid>
      <description>正文開始 前幾篇文章中，咱們討論完資料庫層的資料緩存以後，接下來咱們要來談談另外兩個緩存 :
 CDN ( Content Delivery Network ) HTTP 緩存  本篇文章分為以下幾個章節 :
 CDN 與運行流程 HTTP 緩存與運行流程 CDN 與 HTTP 緩存搞在一起用  這裡先說一下，接下來有一些 cdn 的章節我是直接抓以前我寫的文章來簡單修改一下，不然我還真想不到 cdn 這還要寫什麼。
30-23之 CDN 的說話島 ( AWS CloudFront CDN 實作 )
CDN 與運行流程 在開始理解 CDN 之前，咱們先來說說傳統上一個 client 連線到一個網站的流程。
首先看看下面這張圖 1 所示，這張圖說明了每當一個 client 發送一個請求到 web 網站時，web 網站會回傳 html、css 與 javascript 回來，這裡假設咱們的 web 網站還在台灣，然後回應時間大約在 100 ms 以內 (假設)。
圖 1 : 一個台灣用戶連到台灣網站的時間
然後呢 ~ 這時付你錢的老大叫你將 web 網路架設到美國，因爲免費，然後這時發現回應時間變成 1000 ms 左右，如下圖 2 所示。</description>
    </item>
    
    <item>
      <title>30-20 之資料緩存失效問題</title>
      <link>https://mark-lin.com/posts/20190920/</link>
      <pubDate>Fri, 20 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190920/</guid>
      <description>正文開始 上一篇文章中咱們已經學習了一些緩存基本的策略，那接下來我們要來理解一下一個重要的主題 :
 如果緩存失效的情況，與可能會發生什麼事情呢 ?
 基本上緩存失效後的結果，會很慘，尤其是你當初建立緩存時，就是已經為了讀取接近性能臨異值而建立的情況，當緩存一失效，你的資料庫也會瞬間爆掉，然後用戶就不愈悅，你就完了。
圖 1 : 緩存失效圖
而在實務上，緩存失效大至可以分為以下幾類，也就是咱們接下來每個章節 :
 緩存失效情況 - 緩存穿透 緩存失效情況 - 緩存雪崩 緩存失效情況 - 緩存服務炸了  緩存失效情況 - 緩存穿透 這個的主要情境如下 :
 查詢一個不存在的資料，由於沒命中緩存，因此會一直往 DB 穿，如下圖 2 所示。
 圖 2 : 緩存穿透
通常這種情況有可能是前端出了錯，導致一直送不存在的資料，又或是人為刻意，就是要有人想打爆你整個系統。
解法 1 : 硬處理 這種方法就是，當用戶使用 a key 去 redis 找發現沒有 cache，然後再去 db 抓，也發現沒有，然後就將『 這個 a key 是空值 』也寫入到緩存中 ( 可以給它設個到期時間 )，如下程式碼範例。
這樣後面有人在使用這個 key 去打，會在 cache 這被防下來，然後將算後來真的有寫入 a key 時，咱們緩存寫入流程也是會將它處理 ( 詳見前篇文章 )。</description>
    </item>
    
    <item>
      <title>30-19 之資料庫層的優化  - 資料緩存策略</title>
      <link>https://mark-lin.com/posts/20190919/</link>
      <pubDate>Thu, 19 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190919/</guid>
      <description>正文開始 上一篇咱們基本上已經理解緩存服務 redis 的基本概念後，接下來咱們要進入正題 :
 緩存策略
 相信不少人應該會覺得這很簡單，不就是將熱資料丟到緩存，然後用戶先優先去緩存取得，沒有則去資料庫拿去嗎 ?
用腦袋想很簡單沒錯，但是難處就在於 :
 你要如何確保資料一致性呢 ?
 有沒有覺得這名詞很耳熟呢 ? 你只要記好，只要是多個服務，只要是共用資料的，那就一定會碰到它。
 什麼樣類型資料適合緩存呢 ? 緩存讀流程 緩存寫策略與難題 緩存寫策略的難題總結  什麼樣類型資料適合緩存呢 ? 在建立緩存時，我們需要先來決定一件重要的事情。
 什麼樣的資料需要存放到緩存中呢 ?
 基本上適合緩存資料的特點有以下幾點 :
 這個資料是常常被使用到的。 這個資料是不常被更新的。  且中如果符合上述兩個情況的那就可以算在『 適合建立緩存的資料 』選項中。
緩存讀流程 讀的基本流程如下 :
 (1) 用戶往應用服務發送請求。 (2) 應用服務至緩存服務看看是否有緩存。 (3A) 有，則回傳。 (3B) 無，則前往資料庫服務取得資料。 (4) 並將資料回寫入緩存服務。  基本上這種讀的流程比較沒有太大問題與爭論。
圖 1 : 緩存讀取流程
緩存寫策略與難題   緩存策略最大坑在這
 比較大的問題在於『 寫 』這裡，因為不同的寫入方式會產生不同的問題，而且這沒有 100% 的完美解，只能有較優但還是有缺點的解。接下來我們來一個一個慢慢看。</description>
    </item>
    
    <item>
      <title>30-18 之資料緩存層的服務 - Redis 概念與一致性難題</title>
      <link>https://mark-lin.com/posts/20190918/</link>
      <pubDate>Wed, 18 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190918/</guid>
      <description>正文開始 前面幾篇文章咱們已經學習完了資料層性能相關的知識，而接下來這篇文章，咱們要來學習，如何進一步的讓系統可以做更多的事情。
資料庫單機性能優化到最後，仍然還是逃不過性能的貧頸，但這並不是說單機優化沒有意義，因為單機如果沒有將它優化好，而直接開機器來增加性能，那只能說是拿錢堆起來的性能，而且可能會出問題。
那要如何在增加性能呢 ? 這時通常會使用以下的策略 :
 緩存
 也就是說架構會變的如上圖 1 所示，在 mysql 前面會多增加一個緩存服務，這個服務我們通常會選擇用 redis。當資料在緩存服務有時直接回傳，沒有則去資料庫服務取得。
圖 1 : 加入緩存服務圖
在開始緩存策略前，咱們要先來研究一下基本的緩存服務『 redis 』。
本篇文章分為以下幾個章節 :
 Redis 的架構 Redis 的一致性難題處理 Redis 性能使用的要點  Redis 的架構 首先咱們簡單的介紹一下 redis 是啥 ?
簡單的說它算是一種資料庫，redis 是將所有的資料存在『 記憶體 』中，而 mysql 則是將主要資料存在『 硬碟中 』。
 它適合當緩存服務的重點就在於儲『 記憶體 』。
 而它適合當緩存服務的重點就在於這裡，它將資料儲放在記憶體，因此操作速度非常的快，咱們來簡單複習一下儲硬碟和記憶體取資料的差異，如下圖 2 所示，mysql 讀取資料，基本上要運行 3 次的拷貝，而 redis 則只需要 1 次 ( 每條線就是一次拷貝 )。
圖 2 : redis vs mysql 讀取資料比較</description>
    </item>
    
    <item>
      <title>30-17 之資料庫層的難題 - 單機『 並行 』一致性難題 ( 2 )</title>
      <link>https://mark-lin.com/posts/20190917/</link>
      <pubDate>Tue, 17 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190917/</guid>
      <description>正文開始 上一章節咱們學習到了，在並行情況下 mysql 可能會發生什麼樣的資料不一致問題，並且也學習到了這些問題它又是如何解決。
雖然 innodb 已經儘可能的解決上述這些問題，但是如果要完全解決，性能代價太大，因此後來有了一些折衷方案，這個東西就叫做 :
 事務隔離級別
 接下來本篇文章將要談談這東西，並且整理一下 innodb 預設的一些鎖的設定。
 MySQL 的折衷解法 - 事務隔離級別 預設 RR 級別 - 鎖的操作總結 死鎖的小分析  MySQL 的折衷解法 - 事務隔離級別 資料庫在並行運行時，通常會發生以下幾種問題，並且也探討過這幾種問題的解法 :
 更新不一致 : 鎖 髒讀、不可重複讀 : mvcc 幻讀 : mvcc + next-key locking ( 有一些幻讀情境無解 )  而在 innodb 事實上可以『 完全簡單 』的處理上面幾種現象，解決方法如下圖 5 所示，也就是同一個時間，只能執行同一個事務，如下圖所示。也就是把發生問題的根本原因『 並行 』給移除。
圖 1 : 一致性的根本解法
但這會嚴重的影響到效能的問題，因此才有了『 隔離層級 』這東西。
 隔離層級可以讓你決定需要處理到什麼層級的一致性問題
 也就是說上面四個問題，它可以讓你根據性能的要求，來決定你要處理幾個問題，處理的越多代表性能越差，處理越少個則代表性能越好，但反之不一致性機率更高。
事務隔離級別 mysql 總共提供以下四個層級，不過比較準確的說，這是所有資料庫共有的層級，性能從高至低排序，而反之資料一致性性由低至高。</description>
    </item>
    
    <item>
      <title>30-16 之資料庫層的難題 - 單機『 並行 』一致性難題 ( 1 )</title>
      <link>https://mark-lin.com/posts/20190916/</link>
      <pubDate>Mon, 16 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190916/</guid>
      <description>正文開始 本篇文章中，咱們要說說另一種資料不一致性產生的場景，那就是 :
 『 並行 』產生的不一致性難題
 基本上並行所產生的不一致性難題，可以分為以下幾種類型 :
 更新不一致 髒讀 不可重讀 幻讀  本篇將會分為以下幾個章節來談談這幾個難題 :
 更新不一致難題與解法 - 鎖 髒讀與不可重讀難題與解法 - MVCC 幻讀難題與解法 - MVCC + Next-Lock 鎖  更新不一致難題與解法 - 鎖 這種情境如下圖 1 所示，a 與 b 兩個事務進行更新操作後，事務 a 再看看自已操作的結果，發現自已的更新消失了。這種情境被稱為『 更新不一致問題 』
圖 1 : 更新不一致問題
那這種情境 innodb 它是如何處理呢 ?
 它使用鎖來處理
 在 innodb 的預設，它會對要『 update、delete 』的『 行加鎖排他鎖 』，不過比較嚴格定義應該是說 :
 它會對有用到『 索引 』的『 行 』加『 排他鎖 』，不然會退化成『 表 』鎖</description>
    </item>
    
    <item>
      <title>30-15 之資料庫層的難題 - 單機『 故障 』一致性難題</title>
      <link>https://mark-lin.com/posts/20190915/</link>
      <pubDate>Sun, 15 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190915/</guid>
      <description>正文開始 前面幾篇文章中，咱們理解完了 mysql 的索引概念與原理，並且理解了在 mysql 中一個查詢的速度與否取決於索引與表的設計。接下來咱們要來理解一些會拖性能後腿的東西。
這個會性能後腿的東西就是 :
 一致性難題
 在追求高性能的路上，通常一定會面臨到資料一致性問題，而產生的原因通常可簡單的分為以下來個來源 :
 故障 併發  接下來本篇文章，咱們來看看 mysql 它是如何處理『 故障 』所引發的一致性問題。
 不一致資料產生原因。 MySQL 的解法。 ACID 的小關連。  不一致資料產生原因 原因 1 : 某項操作故障 假設咱們要將 a 帳戶的 1000 元轉到 b 帳戶去，但這時如果在處理 b 帳戶加錢時出錯了，那整個結果就錯誤了，如下圖 1 所示。
圖 1 : 故障導致資料不一致性
在圖 1 中正確的 b 帳戶應該是 1000 元，但是因為加錢失敗了，所以 b 帳戶變成 0 元，這就是產生了『 資料不一致性 』。
原因 2 : 單機故障 第二個產生的原因要先來理解一下，所謂的『 通常 』寫入硬碟的原理。
假設咱們有一個 insert 的指令，要將資料寫入到資料庫中，然後資料庫要將它寫到硬碟中，那它的運行過程如下。</description>
    </item>
    
    <item>
      <title>30-14 之資料庫層的優化 - 表的設計</title>
      <link>https://mark-lin.com/posts/20190914/</link>
      <pubDate>Sat, 14 Sep 2019 20:16:57 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190914/</guid>
      <description>正文開始 本篇文章中咱們將要從『 表 』的角度來儘可能的優化性能。
 表設計的幾個小建議 正規與非正規的小戰爭  表設計的幾個小建議 這個章節會給一些建立表時的小建議，雖然這裡優化的點不多，但是每一個地方都做到好，才是專業。
建議 1 : 選擇適當的欄位類型 - 字串 ( 性能 + ) 基本上在 mysql 中有一下文字類型的選擇，適當的選擇類型，可以省下不少資源 :
 char varchar text blob  char vs varchar char 的特點 :
 最大 255 byte 不管如何就是使用指定的空間 ex. char(4) 就是就算只有 1 個字元，就是花費 4 byte。 用 char 需要處理空白。  varchar 特色 :
 存幾個字就是需花費 n+1 個 byte。 Ex. varchar(4) 假設你儲 1 個字，那就是花費 1 + 1 = 2 byte。 65535 為最大，實際為 65532。 當 varchar 大於一定字數時，會自動轉成 text。  varchar (255+) 轉成 tinytext varchar (500+) 轉成 text varchar (20000+) 轉成 mediumtext 下表為 char 與 varchar 的實際存儲空間比較。</description>
    </item>
    
    <item>
      <title>30-13 之資料庫層的優化 - 索引設計與雷區</title>
      <link>https://mark-lin.com/posts/20190913/</link>
      <pubDate>Fri, 13 Sep 2019 20:12:39 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190913/</guid>
      <description>正文開始 前面兩篇文章中，咱們已經學習完索引的核心觀念以後，接下來咱們學學在使用時有那些的優質的方法與注意事項。
 30-11 之資料庫層的核心 - 索引結構演化論 B+樹 30-12 之資料庫層的核心 - MySQL 的索引實現  本篇文章分為以下幾個章節 :
 索引的重要小觀念 索引的設計流程 索引的使用注意事項 SQL 地雷區  索引的重要小觀念 觀念 1 : 不是索引越多越好 索引不是聖杯，它是雙刃刀，用的好上天堂，用不好下地獄。基本上資料庫的索引幾乎可以影響一個系統的 50% 以上的性能。
索引可以加快查詢速度，但注意它是以空間換取時間。
基本上它使用的資源如下 :
 每個索引都會建立一顆 b+ 樹。 每次新增、更新資料時都會改變 b+ 樹。  所以當你索引越多時，你所需要的記憶體與維護索引的 cpu 運算就需要越多。
觀念 2. 懂的使用 Explain 來分析你的 SQL 索引性能解析 explain 這個指令可以讓你知道你下的 sql 語句是否有命中索引。
EXPLAIN SELECT * FROM user_no WHERE name = &#39;mark&#39;; ===================================================== id: 1 select_type: SIMPLE table: user partitions: NULL type: const possible_keys: PRIMARY key: PRIMARY key_len: 8 ref: const rows: 1 filtered: 100.</description>
    </item>
    
    <item>
      <title>30-12 之資料庫層的核心 - MySQL 的索引實現</title>
      <link>https://mark-lin.com/posts/20190912/</link>
      <pubDate>Thu, 12 Sep 2019 20:11:06 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190912/</guid>
      <description>正文開始 上一篇文章中，我們理解了 innoDB 索引的基本原理 b+ 樹的，也理解了為什麼 innoDB 要選擇 b+ 樹的原因後，那接下來，我們要來理解，在 innoDB 中『 實際上 』是如何使用 b+ 樹來建立索引機制 ?
本篇文章分為以下幾個章節 :
 一張乾淨的表 InnoDB 實際上如何儲呢 ? ( Clustered Index ) 一張自加索引的表 InnoDB 實際上如何儲呢 ? ( Secondary Index ) InnoDB 所提供的索引類型  一張乾淨的表 InnoDB 實際上如何儲呢 ? ( Clustered Index ) 假設我們有以下的 table 表，然後咱們不要手動設什麼索引，那麼 innodb 會如何儲存它呢 ?
   Id ( PK ) Name age     1 Mark 18   2 Jack 10   3 Ian 36   4 Jiro 30   5 Fucc 27   &amp;hellip; &amp;hellip; &amp;hellip;   10 Fukk 46   表 1 : 範例      首先 innodb 會自動幫你建立一個叫『 clustered Index 』的東東，在 innodb 中，它就是這份資料實際上儲存的結構，請別管它叫索引，它就是你的實際資料，只是它是有規則的儲存結構。</description>
    </item>
    
    <item>
      <title>30-11 之資料庫層的核心 - 索引結構演化論 B&#43;樹</title>
      <link>https://mark-lin.com/posts/20190911/</link>
      <pubDate>Wed, 11 Sep 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190911/</guid>
      <description>正文開始 接下來咱們要來理解資料庫系統中最核心的問題 :
 要如何儲放資料，才能更快速的找到資料呢 ?
 而這個東西的技術就是所謂的 :
 索引
 而在 mysql 中決定如何儲放的是資料庫儲存引擎來決定，而這裡咱們將要從 mysql 預設引擎 innodb 來深入的理解一下。
在 InnoDB 中預設是使用『 B+樹 』來當資料儲放格式，而為什麼要選擇它呢 ?
這就是我們這篇文章的重點。
 InnoDB 為什麼選擇 B+ 樹 ?
 本篇文章分為以下幾個章節，這也就是 B+ 樹的誕生原由。
 二分搜尋 Binary Search 二元搜尋樹 Binary Search Tree 平衡二元搜尋樹 Balanced Binary Search Tree B 樹 B+樹 ( InnoDB 的選擇 )  二分搜尋 Binary Search 首先我們都知道，資料庫誕生出來的本質就是為了讓我們找東西更快速。
那是和什麼比呢 ? 就是所謂的『 線性搜尋 』，也就是說有 1000 筆資料，你要找到你想要的值，需要一筆一筆的慢慢查，而這種線性搜尋的時間複雜就是 O(n)，其中 n 就是你所有的資料量。如下圖 1 所示。</description>
    </item>
    
    <item>
      <title>30-10 之資料庫層架構與優化方向</title>
      <link>https://mark-lin.com/posts/20190910/</link>
      <pubDate>Tue, 10 Sep 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190910/</guid>
      <description>正文開始 前面幾篇文章中，咱們大致上學習完了應用層的一些性能優化的基本知識，接下來咱們要來學學資料庫層的高性能優化方向。
在這裡先說一下一個重點 :
 資料庫絕對是一個系統的性能核心，請把優質的 DBA 們當寶來餵食
 接下來幾篇資料庫層文章將會以『 MySQL 』來進行說明，雖然不同的資料庫可能實作上會有些不同，但是大致上原理不會差距太大。
開始第一篇文章，咱們將要先理解一些 MySQL 的基本架構，接下來才能理解那些地方可能可以進行性能優化，又是那一些地方可能是會拖後腿，但是又是必要存在的地方，這篇也算是資料庫篇的小目錄。
本篇文章分成以下幾個章節 :
 MySQL 基本架構。 資料庫層的優化方向。 資料庫層會拖性能後腿，但是又必須處理的地方。  MySQL 基本架構與運行 圖 1 : mysql 的基本架構
基本上分為以下幾個部份 :
 應用層 ( 紅色 ) 服務層 ( 綠色 ) 存儲引擎層 ( 藍色 )  應用層 應用層主要處理兩個工作 :
 連接處理任務 權限管理  其中連接處理任務就是每當一個 client 端發送一個請求到 mysql 時，它會在從 thread poll 中分配一個 thread 來處理此請求，然後之後從此 client 來的任務，都會由此 thread 來處理。
mysql 並沒有使用之前說的非阻塞 I/O 模型 ( reactor ) 來處理請求的，原因可能在於，mysql 的任務是屬於 cpu 運算密集與磁碟 I/O 密集任務，因此比較不適合使用 reactor 這種使用 epoll 的模型。</description>
    </item>
    
    <item>
      <title>30-09之應用層的兩個池 - 進 ( 線 ) 程池與連線池</title>
      <link>https://mark-lin.com/posts/20190909/</link>
      <pubDate>Mon, 09 Sep 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190909/</guid>
      <description>正文開始 接下來咱們要來談談，在應用層中很常提到的兩個池『線程池』與『連線池』，它們兩個在應用層扮演了性能方面什麼樣的角色。
本篇文章分為以下幾個章節 :
 什麼是進程池 ? 為什麼需要它呢 ? 進程池的數量設置。 什麼是連線池 ? 為什麼需要它呢 ? 連線池的數量設定。  什麼是進程池 ? 為什麼需要它呢 ? 先說以一下，這裡不一定是指進程 process ，也有可能是指線程 thread，反正都是代表一個池子裡裝了這兩種東西。
接下來咱們以 process 進程為主。
進程 process 咱們已經在前幾章很常看到它，它的基本概念就是 :
 作業系統的操作單位且是最小資源分配單位
 也就是在某個時間，會以 process 為單位開啟資源，並將 cpu 分配給它來工作。
而所謂的進程池的就是，一個裝了一堆進程的隊列，當你有需要進程時，去裡面拿，而不用在重新建立一個新的。
為什麼需要它呢 ? 先說一下，咱們什麼時後要開多個 process 或 thread 呢 ?
 並行運算，也就是多開個 process 或 thread 來幫忙計算。 i/o 處理，在某些情況下，咱們需要開一個 process 或 thread 來處理 i/o。  那為什麼需要進程池呢 ?
 可以節省建立與結束 process 所耗費資源 ( cpu 、 mem )。 可以有效的控制 process 的數量，如果一個不注意開太多，就算開時沒爆，你也有可能在上下文切換時爆了。 有了進程池事實上也代表有管理器，那這樣也代表有可能玩定時執行進程或線程 ( Java 就降玩 )。  這裡後我們簡單的複習一下，看看建立進程與結束是要做那些事情。基本上就如下面這張圖一樣，就是不斷的拷貝記憶體或移除記憶體。請別小看這一段工作，事實上要做不少事情的。</description>
    </item>
    
    <item>
      <title>30-08 之應用層的 I/O 優化 ( 維護性 ) - 協程 Coroutine</title>
      <link>https://mark-lin.com/posts/20190908/</link>
      <pubDate>Sun, 08 Sep 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190908/</guid>
      <description>正文開始 上一篇文章說明完了非阻塞 I/O 模式核心 reactor，並且它可以幫我們建立 :
 異步非阻塞的 I/O 操作。
 而接下這篇文章我們將要來說說 coroutine 協程這東西，協程這東西在 I/O 優化佔據什麼地位呢 ?
簡單的說它可以讓我們實現以下的事情 :
 可以在應用層實現同步非阻塞的 I/O 操作
 接下來我們來深入的探討一下，協程這東西可以解決什麼事情以下現階段有那些東西有在使用這個機制。本篇文章共分以下幾個章節。
 coroutine 協程想要解決的問題。 coroutine 協程實現原理。 Golang 的 goroutine。  coroutine 協程想要解決的問題 首先咱們先來看看它想要解決什麼問題呢 ?
 協程它想要將異步非阻塞的 I/O 操作變成同步的。
 異步非阻塞寫法 首先咱們來看看 reactor 所實現的異步非阻塞的 I/O 操作的寫法，如下程式碼，這一段是使用 php swoole 來打 redis 的模擬碼。然後重點在於以下兩點 :
 異步 : callback 機制，也就是下面程式碼裡面的 function。 非阻塞 : 當打這個 I/O 操作時，不會阻塞住整個進程。  &amp;lt;?php $client = new swoole_redis; $client-&amp;gt;connect(&amp;#39;127.</description>
    </item>
    
    <item>
      <title>30-07 之應用層的 I/O 優化 - 非阻塞 I/O 模型 Reactor</title>
      <link>https://mark-lin.com/posts/20190907/</link>
      <pubDate>Sat, 07 Sep 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190907/</guid>
      <description>正文開始 接下來本篇文章，咱們要來說明所謂的『 I/O 』模型。
這個東西我當初看到也有點不太能理解，為什麼需要它，但後來理解以後發覺，你只要知道一個 http 請求 web server 是如何處理的，從 0 至 1，那這樣的話當你完全通了，就知道這為什麼會有這些模式。
本篇文章共分以下幾個章節 :
 傳統的 Web Server 請求 I/O 處理與問題 非阻塞 I/O 模式核心 Reactor 模型。 一些常見的問題。  ~ 重要備註 ~ 相信有不少人聽過阻塞、非阻塞、同步、非同步，也相信有些熟悉 linux 的友人，聽過它所提供的一些上述名詞的方法，但這裡要先說明，接下來的說有上述詞語，都是指『 應用層 』的表達，而不是『 業系統層 』的所提供的方法，除非有特別說明才是作業系統的。
傳統的 I/O 處理與問題  一個 I/O 請求進來要如何處理呢 ?
 傳統的 I/O 請求處理 咱們這裡以 http server 處理請求時來當範例，如下圖所示，咱們以常見的 PHP + Apache 來看。如下圖 1 所示，每一個 http 請求都需要開啟一個或是使用一個進程來進行處理，這裡不是只有 http 請求會被阻塞，而是所有的 I/O ( ex. 網路請求、檔案讀取 ) 操作正常來說都是會被阻塞的。</description>
    </item>
    
    <item>
      <title>30-06 之應用層的 I/O 優化 - Stream ( 與一些 IPC 知識 )</title>
      <link>https://mark-lin.com/posts/20190906/</link>
      <pubDate>Fri, 06 Sep 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190906/</guid>
      <description>正文開始 Stream 這個東東，基本上在每一個語言你都看的到，而今天我們將要深入的來理解它到底是什麼東西，並且它在一些 I/O 操作上可以幫助我們解決什麼事情。
本篇文章將分為以下幾個章節
 Stream 是什麼 ? 可以解決什麼事情 ? Stream 在 IPC 通信的原理。 簡單的小範例。  Stream 是什麼 ? 可以解決什麼事情 ? 傳統資料傳輸流程問題 stream 它是一種技術，基本上專門用來傳輸資料用。
咱們先來看看傳統上，咱們如果要從硬碟拿個檔案是如何處理。
基本上流程如下圖 1 所示。
 應用程式發送 system call read 某個檔案給作業系統的內核。(用戶切內核) 內核看看內核緩衝區有沒有相關資料(也就是所謂的內核記憶體)。 有，則將內核緩衝區的資料，拷貝到用戶緩衝區(用戶進程記憶體)。 無，則前往硬碟取得。 將硬碟資料拷貝至內核緩衝區。 將內核緩存區資料，拷貝到用戶緩衝區。(內核切成用戶) 然後就可以使用資料了。  圖 1 : 傳統的資料傳輸流程
而重點在於這裡 :
 硬碟資料 copy 到內核緩衝區，接下來再從內核緩衝區 copy 到用戶緩衝區。
 然後問題出在於 :
 如果資料很大會發生什麼事呢 ?
 基本上結果就如下圖 2 所示，有可能在內核緩衝或用戶緩衝，就爆掉了，因為記憶體是整份 copy 過去，如果你硬碟資料有 10 gb，那就代表，要將這 10 gb 的資料 copy 到內核緩存，再 copy 到用戶緩存，這時後用戶進程才能拿到它。</description>
    </item>
    
    <item>
      <title>30-05 之應用層的 I/O 加速 - 零拷貝 ( Zero Copy )</title>
      <link>https://mark-lin.com/posts/20190905/</link>
      <pubDate>Thu, 05 Sep 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190905/</guid>
      <description>正文開始 前二篇文章中，咱們已經學習完運算方面的優化，而接下來幾篇文章，咱們要來說明 I/O 優化這個議題。
I/O 基本上可以分為兩種，『 文件 I/O 』與『 網路 I/O 』，這兩種 I/O 操作原理大同小議，但是優化方式卻有些不同，接下來這一篇文章，算是混合。
本篇文章分為以下幾個章節 :
 I/O 原理。 零拷貝 I/O 的概念與優化原理。 零拷貝的實現。 零拷貝的語言支援與問題探討。  I/O 原理 先從最基本的來看，何謂 I/O ?
I/O ( Input/Output) 通常是指資料在『系統』與『外部裝置』的輸入與輸入，最簡單的例子，抓取硬碟或 USB 資料就是所謂的 I/O 操作。
接下來我們簡單的來看一下，在 linux 操作系統上，所謂的『 從硬碟讀取資料，並結果輸出到網路 』到底是在做什麼。
記憶體層面來看 I/O 流程 記憶體就是作業系統最基本的資料儲放地，接下來我們從記憶體的層面來看，所謂的『從硬碟讀取資料，並將結果輸出到網路』它是如何變化的。
基本『 讀與寫 』流程如下 :
在看流程前先說明一下，等等到看到的所謂『 緩衝區 』 就是指在某個記憶體中，切割一些空間出來，來當緩衝區。像等等看到的內核緩衝區就是在內核的記憶體中，拿一些空間來儲放等等要進來的資料。
接下來就開始看流程。
 應用程式發送 system call read 某個檔案給作業系統的內核。(用戶切內核) 內核看看內核緩衝區有沒有相關資料。 有則將內核緩衝區的資料，拷貝到用戶緩衝區。 無則前網硬碟取得。 將硬碟資料拷貝至內核緩存區。 將內核緩衝區資料，拷貝到用戶緩衝區。(內核切成用戶) 在從用戶緩衝區發送 system call write 將用戶記憶體資料拷貝到 socket 緩衝區，這緩衝區也是在內核中。(用戶切內核) 用戶端收到 ack (內核切用戶) 資料飛向世界。  順到說一下，這樣的操作總共會進行 4 次的上下文切換。</description>
    </item>
    
    <item>
      <title>30-04 之應用層的運算加速 - 並行運算</title>
      <link>https://mark-lin.com/posts/20190904/</link>
      <pubDate>Wed, 04 Sep 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190904/</guid>
      <description>正文開始 假設你已經將你的演算法進行了優化，但是這時發現，這一項演算法工作還是需要花到非常多的時間處理，那要怎麼辦呢 ?
假設你所在的機器是多核心 CPU，那這時的確是有解，那就是本篇文章的主題 :
 開啟 Process 或 Thread 來幫忙進行運算。
 本篇文章就分為以下三個章節:
 CPU 運算與 process、thread 的關係。 CPU 密集任務處理。 多線程並行處理的淺在問題。  CPU 運算與 Process、Thread 的關係 在實際上理解如何開啟 process 或 thread 前，咱們先從最基本的東西說起。
何謂 process ? 何謂 thread 呢 ?
進程、行程 ( Process ) 首先咱們先來看看 process，基本上在你的電腦中每一個應用 ( ex. line、chrome ) 都是至少是一個 process，然後比較重要的一點在於 :
 對作業系統來說，它是資源分配的最小單位，並且同時是個『操作單位』
 在 linux 系統上，一個 process 的建立過程如下圖 1 所示 :
 母進程執行 fork() 建立一個子進程。 同時間建立子進程的記憶體空間。  圖 1 : 作業系統建立進程的概念圖</description>
    </item>
    
    <item>
      <title>30-03 之應用層的運算加速 - 演算法</title>
      <link>https://mark-lin.com/posts/20190903/</link>
      <pubDate>Tue, 03 Sep 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190903/</guid>
      <description>正文開始 本篇文章開始，我們將要深入的探討，每一個服務，要如何儘可能的達到高性能呢 ?
這首先第一部份，我們要探討以下主題 :
 在應用層，要如何儘可能的使用越少的資源( CPU、Memory )，來做最多的事情呢 ?
 而這一題的主要的答案就是不少人面試很排斥的『演算法』。
本篇文章會分為以下幾段 :
 一個好與不好的演算法性能差距多大呢 ? 演算法運算時間的分類 演算法優化建議  接下來正文開始。
一個好與不好的演算法性能差距多大呢 ? 一個演算法的效能基本上有兩個東東 :
 時間複雜度: 你可以把它想成演算法的運行時間。 空間複雜度: 這個可以想成你這個演算法需要花多少的空間來處理。  上面只是簡單說明它的代表概念，比較實際的運算方法直接去 wiki 看就夠囉。
那麼拉回拉，一個好與不好的演算法性能差距有多大呢 ?
呵 !
我們以一個最簡單的演算法『費波那契數列』來看看。
首先這是好的程式碼。
// good  console.time(&amp;#39;time&amp;#39;); function fib (n) { if ( n === 0 || n === 1) { return n; } let a = 0; let res = 1; let temp = 0; for (let i=2; i &amp;lt;= n; i++) { temp = res; res = a + res; a = temp; } return res; } fib(45); console.</description>
    </item>
    
    <item>
      <title>30-02 之單機架構的性能優化方向與目標</title>
      <link>https://mark-lin.com/posts/20190902/</link>
      <pubDate>Mon, 02 Sep 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190902/</guid>
      <description>接下來咱們會從最基本的開始 :
 儘可能的優化單機性能
 基本上不少高性能的書籍都是直接跳至分散式架構，但是如果一個開發者連單機都處理不好，我不太相信他開發出來的分散式架構是高性能的。
 單機處理的好，才是高性能的前提。
 本篇會分為以下幾個章節，來探討單機領域的優化方向，這個方向也就是之後文章的目錄。
 單機系統的優化路線 Step 1 (應用服務、資料庫服務)。 單機系統的優化路線 Step 2 (快取服務、CDN 服務)。 一個系統效能的評估指標。  單機系統的優化路線 Step 1 (應用服務、資料庫服務) 單機系統的最基本最基本架構應該長的如下圖 1，就是最簡單的應用服務與資料庫服務，咱們這裡先以最大眾的 web 服務為主 :
 應用層服務 資料庫層服務  圖 1 : 最簡單的應用架構。
單機應用層的性能優化方向 基本上單機應用層的優化目標如下 :
 以最快與最少的資源來處理請求，並且可以最快的速度將結果回應給客戶，讓客戶於愉悅。
 而要完成這件事情，基本上有幾個方向可以研究。
 以最少的資源進行運算，這裡比較白話文的來說就，用最少的 CPU 與 Memeory 來完成工作。 I/O 處理，大部份的 Web 應用都是讀取資料庫或啥的，這裡如果沒處理好，你的系統絕對只能做很少的事情。 I/O 的一些加速技術例如 stream、零拷貝、線程、連線池。  不過簡單來說就分兩種『運算』與『I/O』。
圖 2 : 應用服務性能重點。
資料庫層的性能優化方向 資料庫層是的優化目標基本上如上應用層一樣:
 以最快與最少的資源來處理請求，並且可以最快的速度將結果回應給客戶，讓客戶於愉悅。
 基本上在性能方向會有幾個方向可以研究 :</description>
    </item>
    
    <item>
      <title>30-01 之何謂一個好的系統呢  ?</title>
      <link>https://mark-lin.com/posts/20190901/</link>
      <pubDate>Sun, 01 Sep 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190901/</guid>
      <description>何謂一個好的系統呢 ?
 為什麼會問這個問題呢 ?
因為事實上這個是我原本想要撰寫的主題。咱們工程師在開發系統，所學習的大部份的技術，基本上都是為了追求『建立一個好的系統』，然後我本來想將建立一個好的系統的知識點，建立成一個 30 天的知識集，但就算進行精簡化，也很難進行有深度的探討。
因此後來才有了這 30 天這個主題 :
 30天之從 0 至 1 盡可能的建立一個好的系統 (性能基礎篇)
 接下來我們來說說，上述的主題『性能』，在一個好的系統中，是那一個部份。
何謂一個好的系統呢 ? 這個主題事實上非常的抽象與盤大，問十個人可能有十種答案，在這裡筆者將來說明心中理想的系統。
一個好的系統我覺得最重要的一點為 :
 要有人用
 這個是我覺得是最重要的一點，如果沒有人用，除非你裡面的技術是可以改變世界的，不然基本上是沒啥價值性的，不論是科學或是商業價值。
『要有人用』這個基本上咱們搞技術的除非你和老闆是好麻吉，不然事實上很難干涉行銷策略這個層級的事情，所以這一塊咱們先不管。
不過也不代表我們不用學這個領域的知識。
 你的知識越廣，就越不會被固定領域知識僵固，並且更能幫助你突然領域的深度。
 忘了是誰說的，不過我很喜歡這句話。
不過這句話我覺的有個前提假設 :
 不過你要先有一把刀，你才能去開拓世界。
 也就是說如果你沒有先在你的領域打個底，那麼你也沒有本事將從其它領域學到的東西，融入你的領域。
某些方面，我覺得學程式語言就如同上面這一句話一樣。
在有人用的情況下，何謂一個好的系統呢 ? 我覺得一個好的系統只有一個重點 :
 讓雙方愉悅
 這裡雙方是指『用戶』與『公司』。
 能夠讓使用者覺得好用，用起來就是愉悅兩字 (用戶愉悅)。 能夠以最少的資源(機器)做最多的事情 (公司愉悅)。 能夠讓開發人員未來花越少的時間在維護 (公司愉悅)。 安全 (用戶與公司都愉悅)。  能夠讓使用者覺得好用，用起來就是愉悅兩字 (用戶愉悅)  畫面讓人覺得愉悅。(設計) 畫面操作讓人覺得愉悅。(UI/UX、性能) 不會一下可以用，一下不能用。(可用性)  總結一句話 :</description>
    </item>
    
    <item>
      <title>PHP 的 Web 運行原理 ( 4 ) - Reactor 的實現之 Swoole</title>
      <link>https://mark-lin.com/posts/20190515/</link>
      <pubDate>Wed, 15 May 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190515/</guid>
      <description>本篇文章，咱們將要在說明另一個在 php 實現 reactor 模式的東西swoole。
本篇文章分為以下幾個章節 :
 Swoole 的架構 Swoole 非阻塞 I/O 的處理 Swoole 的 Coroutine Swoole 實際使用的注意事項  swoole 的架構 swoole 官網寫到 :
 event-driven asynchronous &amp;amp; coroutine-based concurrency networking communication engine with high performance written in C and C++ for PHP.
 swoole 它是一個用 c++ 所寫的 php extension，一個非常高效能的通訊引擎，而它能達到高效能的基礎在於以下幾個重點 :
 event-drivent coroutine  一句話來說他可以幹麻。
 它可以讓我們建立一個高效能的網路服務
 下面就是它實現非阻塞 I/O 的架構圖。
當它建立一個 http server 以後，你會看到產生出下圖這些 process 與 thread，基本上可以分為幾個部份 :</description>
    </item>
    
    <item>
      <title>PHP 的 Web 運行原理 ( 3 ) - Reactor 的實現之 reactPHP</title>
      <link>https://mark-lin.com/posts/20190514/</link>
      <pubDate>Tue, 14 May 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190514/</guid>
      <description>上一篇文章PHP 的 Web 運行原理 ( 2 ) - 非阻塞 I/O 之 Reactor 模式我們理解到實現非阻塞 I/O 的 reactor 模式以後，接下來本篇文章我們將來要說明，在 php 中的 reactor 實現reactPHP。
本篇文章分為以下三個章節 :
 reactPHP 基本概念 reactPHP 非阻塞 I/O 實現 reactPHP 使用時注意事項  reactPHP 基本概念 reactPHP 官網寫這一段話 :
 Event-driven, non-blocking I/O with PHP
 它是一個用 php 所寫的 libaray，可以幫助我們做以下的事情 :
 可以建立一個非阻塞 I/O 的網路服務。 可以建立一個定時排程服務。  http server 的範例 下面就是官網首頁的範例，我們可以用它簡單的建立一個非阻塞 I/O 的 http server，就如同 nodejs 一樣。
$loop = React\EventLoop\Factory::create(); $server = new React\Http\Server(function (Psr\Http\Message\ServerRequestInterface $request) { return new React\Http\Response( 200, array(&amp;#39;Content-Type&amp;#39; =&amp;gt; &amp;#39;text/plain&amp;#39;), &amp;#34;Hello World!</description>
    </item>
    
    <item>
      <title>PHP 的 Web 運行原理 ( 2 ) - 非阻塞 I/O 之 Reactor 模式</title>
      <link>https://mark-lin.com/posts/20190513/</link>
      <pubDate>Mon, 13 May 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190513/</guid>
      <description>前篇: PHP 的 Web 運行原理 ( 1 )
上面一篇文章中，我們有提到兩種 php 的 web 運行模式moduel與fast_cgi模式，它們在某種情況下，都會有些問題，而我們這篇文章就是要來理解是碰到什麼問題，然後又是如何解決呢 ?
 Reactor 模式想解決的問題 Reactor 模式原理 Reactor 的使用注意事項  Reactor 模式想解決的問題 使用 moduel 與 fast_cgi 模式 的 web server 模式基本上會有兩個問題存在。
1. 高併發請求，會爆 ! 如下面這張圖一樣，它每一個 http 請求都需要使用一個 process 或是 thread 來進行處理，而每一台機器的 process 與 thread 的數量都有限制，且操作系統進行 process 或 thread 上文文切換時非常耗的資源。
2. 服務如果是大量 I/O 操作會很浪費資源 ! ex. 讀 db 或 redis 啥的
主要耗資源的地方在於，每個 process 開啟後，大部份的時間者是在等待 I/O 的處理，而 CPU 都是閒在那。
上面兩個是看到的現象，而真正的問題點在於 :  為什麼每個請求都需要開啟一個 process 或 thread 來處理呢 ?</description>
    </item>
    
    <item>
      <title>Nodejs 之運行機制原理</title>
      <link>https://mark-lin.com/posts/20190308/</link>
      <pubDate>Fri, 08 Mar 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190308/</guid>
      <description>Nodejs 出來時它的官網寫這以下的描述 :
 Node.js is a JavaScript runtime built on Chrome’s V8 JavaScript engine. Node.js uses an event-driven, non-blocking I/O model that makes it lightweight and efficient. Node.js’ package ecosystem, npm, is the largest ecosystem of open source libraries in the world.
 簡而言之 Nodejs 是運行在 V8 javascript 引擎，並且使用 Event driven 與 non-blocking I/O 模式所建立出來的東東。
而這裡我們就要深入的來理解 Nodejs 的運行機制。
 Nodejs 核心設計 - 非阻塞 I/O 模式 Nodejs 架構與運行 Nodejs 為什麼需要使用 thread ?</description>
    </item>
    
    <item>
      <title>Socket.io 使用 AWS ALB 建立 Load Balance 問題</title>
      <link>https://mark-lin.com/posts/20190325/</link>
      <pubDate>Fri, 08 Mar 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190325/</guid>
      <description>socket.io 是一套可以讓我們快速與簡單的建立一套，讓 client 與 server 可以雙向溝通的 Libary，而當我們使用它來建立一個 message server 後，通常在一定的使用量以後，會開始的考慮要加機器來進行擴展，同時間也會建立一台 load balance 的應用來分散請求。
而這時如果你選擇使用AWS ALB (Application Load Balancer)來建立 load balance 你會發現它有個很大的問題，那就是 :
 使用非瀏覽器(未處理 cookie )的 client 無法使用 polling 來建立連線
 接下來我們將慢慢的來探討原因為何，並且來想想是否有什麼解法呢 ?
本篇文章架構如下 :
 原因 解法  原因 為什麼非瀏覽器的 Client 無法使用 polling 來建立連線呢 ?
這裡我們就要先從 socket.io 建立連線的流程開始說啟。
Socket.io 建立連線原理 假設我們在已經在 server 端使用 socket.io 來建立起 message server，然後接下來我們要在 client 端使用socket.io client來建立連線。
var socket = require(&amp;#39;socket.io-client&amp;#39;)(&amp;#39;http://localhost&amp;#39;); 而 socket.io client 這裡主要提供了兩種 transport 讓我們 client 與 server 可以互相的傳遞資料 :</description>
    </item>
    
    <item>
      <title>PHP 的 Web 運行原理 ( 1 )  - 傳統型</title>
      <link>https://mark-lin.com/posts/20190131/</link>
      <pubDate>Thu, 31 Jan 2019 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20190131/</guid>
      <description>這篇文章雖然主題為PHP 的 Web 運行原理，但是比較白話文的說，事實上是想要理解這件事情 :
 一個 http 請求進來後，php 到底是如何運行呢 ?
 要理解這件事情，有個最基本的觀念要先理解，那就是下面這段指令，它到底是如何運行的。
php index.php 然後接下來才能在理解 Web 是如何用 php 來處理。
這篇文章將分為以下幾個章節 :
 執行 php index.php 它是如何運行的呢 ? 三種用 PHP 來處理 HTTP 的模式 Web PHP 應用組合與問題  執行 php index.php 它是如何運行的呢 ? 假設我們在 Terminal 執行了如下的指令。
 php index.php
 那實際上它的運行流程會如下圖，而這張圖也代表 PHP 的基本運行架構。
 SAPI ( Server Application Programming Interface ) : 它就是一個應用環境與PHP 核心的一個 Interface，會有這層主要的原因在於，不同的應用環境，例如命令行環境(就是在 Terminal 執行 php) 或 Web 環境都需要不同的 PHP 環境配置，如果沒有這一層就代表 PHP 本身要針對不同的環境來考慮設計兼容，這也是為什麼會有 SAPI 的目的。 main : 它是 php 所有操作的整合者。 Zend 引擎 : 它就是將咱們編寫的 PHP 程式碼解釋成可以執行的 opcode 碼，其中 PHP7 與 PHP5 有速度上的飛升原因就在於此，PHP7 大幅度的優化了 Zend 引擎。 Extension : 它是 PHP 內核所提供的一套擴充 PHP 功能的方式，大部份都是使用 C/C++ 所撰寫，基本上可以分為 PHP extension 與 Zend extension。  三種用 PHP 來處理 HTTP 的模式 那如果改成 Web 情況下，上面那張圖會變成什麼樣子呢 ?</description>
    </item>
    
    <item>
      <title>PHP Laravel 的 Facade 的理解</title>
      <link>https://mark-lin.com/posts/20181228/</link>
      <pubDate>Fri, 28 Dec 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20181228/</guid>
      <description>什麼是 Laravel Facade ? 在一般情況咱們如果要使用物件的某個方法可能會寫成如下 :
&amp;lt;?php $userService = $app-&amp;gt;make(&amp;#39;UserService&amp;#39;); $userService-&amp;gt;createUser(); 但是有時後你會看到如下的程式碼 :
&amp;lt;?php UserService::createUser(); 而這就是 Laravel 所提供的 Facade 語法糖，而 Facade 實際上是一種設計模式。
Facade(外觀) 設計模式 Facade 設計模式基本的定義如下 :
 定義一個高層級的接口，客戶端只能透過它來與子系統進行溝通。
 畫成概念圖大概長的如下，客戶端當要使用某個子系統所提供的功能時，不會直接去使用，而是會透過 Facade 來進行操作。
程式碼範例 假設咱們現在有個功能是用使用 LineSDK 來將訊息推送到 Line 取，然後咱們假設 sdk 的程式碼如下。
&amp;lt;?php interface IMessage { public function push(); } class LineSDK implements IMessage { public function push() { var_dump(&amp;#39;I push a message to line&amp;#39;); } } 然後我們這裡會在寫一個 Facade 來讓我們的系統來使用。
&amp;lt;?php class MessageFacade { private $sdk; public function __construct(IMessage $sdk) { $this-&amp;gt;sdk = $sdk; } public function push() { $this-&amp;gt;sdk-&amp;gt;push(); } } 最後這個時候客戶端想要使用時，就會透過 Facade 來進行發送訊息，如下程式碼。</description>
    </item>
    
    <item>
      <title>PHP Laravel 的 Service Provider 理解</title>
      <link>https://mark-lin.com/posts/20181214/</link>
      <pubDate>Fri, 14 Dec 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20181214/</guid>
      <description>什麼是 Laravel Service Provider ? 上一篇文章『PHP Laravel 的 Container 理解』中咱們學習到了 Laravel 的 Container 是一種用來解決依賴與耦合的概念，它建立了一個容器並且在裡面定義好抽像與實際類別的對應，最後就可以自動的進行依賴性注入。如下偽程式碼。
&amp;lt;?php $containter = require(&amp;#39;Container&amp;#39;); // 建立抽象與實體類別的對應 $containter-&amp;gt;bind(ILogService, AWSLogServcie::class); $log = $container-&amp;gt;make(Log::class); $log-&amp;gt;send(&amp;#39;log....&amp;#39;); 其中上面的bind就是可以在這個容器內建立一個抽象類別舉實體類別的對應，也就是說如果後來要實體化有實作 ILogService 的類別，那他就會實體化 AWSLogServcie 出來。
那 Service Provider 是什麼 ?  它就個註冊與管理 Container 內服務的地方。
 下面的程式碼為 Laravel 專案的 Service Provider，其中有兩個重要的方法boot與register。
 register : 它就是用來寫 bind 的地方。 boot : 它就是當 register 結束以後會執行的方法。  &amp;lt;?php namespace App\Providers; use Illuminate\Support\ServiceProvider; class AppServiceProvider extends ServiceProvider { /** * Bootstrap any application services.</description>
    </item>
    
    <item>
      <title>PHP Laravel 的 Container 理解</title>
      <link>https://mark-lin.com/posts/20181030/</link>
      <pubDate>Tue, 30 Oct 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20181030/</guid>
      <description>Container 是什麼 ? Laravel Container 是什麼呢 ? 我們先來理解 Container 容器 是什麼。
容器抽象一點概念是指用來裝東西的載體，向菜籃也算個容器，而在 Laravel 中所代表的意思就是指 :
 裡面裝了一堆可以用的服務載體，就叫 Container。
 像我們每當要執行 Laravel 時，都會先執行下面這段程式碼，其中 $app 就是我們的 Container，然後接下來會使用 Container 來實體化一些物件，例如 $kernel。
&amp;lt;?php public/index.php $app = require_once __DIR__.&amp;#39;/../bootstrap/app.php&amp;#39;; /* |-------------------------------------------------------------------------- | Run The Application |-------------------------------------------------------------------------- | | Once we have the application, we can handle the incoming request | through the kernel, and send the associated response back to | the client&amp;#39;s browser allowing them to enjoy the creative | and wonderful application we have prepared for them.</description>
    </item>
    
    <item>
      <title>30-30之寫給想入門影音直播開發的 Junior 工程師攻略本</title>
      <link>https://mark-lin.com/posts/20180930/</link>
      <pubDate>Sun, 30 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180930/</guid>
      <description>前言 這辛苦的三十天總於結束了，當初原本只是想要理解直播相關協議的東西一下，但是卻發現越來越多奇怪的名詞跑了出來，就算大概的知道 HLS 是要做什麼，但你總是會覺得前後知識好像缺了什麼，別人問你一下沒有 HLS 前是如何處理直播傳輸你大概就會倒了，然後上網查查相關知識，但卻發現總是沒有連貫起來的知識，越看越冒出更多的名詞，這對一名想入門影音直播開發的初學者，真的非常的辛苦。
因此最後就想說當個好人將這方面的知識都整理成一條線好了，因此就產生了這三十篇的文章。
這三十天的文章基本上理解完後，要開發出一個直播應用事實上就不是太難的事情了，而且你有了這三十篇的知識你接下來要將直播應用開發的更好，你就也更有本錢去學習更進階的東西囉。
接下來這篇文章就來總結一下這三十天咱們學習了那些東西。
影音直播開發的 Junior 工程師攻略本 基本上前二十篇是最基礎的東西，這幾篇文章就在說明，如何將一個人的聲音或影像傳遞給對方。。
!
聲音與影像的採集、編碼與封裝 首先這五篇文章我們學習了聲音與影像是如何的儲放在電腦裡面，並且因為原始的聲音與影像太大，所以我們需要使用編碼來進行壓縮，最後就準備需要將聲音與影像進行封裝，為了可以讓別人一打開來知道要如何處理這一段聲音或影像編碼。
 30-02之聲音的採集與原理 30-03之聲音的編碼與壓縮 30-04之影像的採集與原理 30-05之影像的編碼與壓縮 30-06之聲音與影像的封裝  接下來的兩篇文章，咱們就使用 WebRTC 的一些東西，來實作如何的採集聲音與影像，並且最後將它封裝成一個檔案。
 30-07之Web 如何進行語音與影像採集 ? 30-08之 WebRTC 採集的詳細說明與聲音的加工  聲音與影像的傳輸 咱們已經可以將聲音與影像封裝後，就可以開始傳輸給遠方的某個人。
我們一開始先探討讓對方收到聲音與影像的方法有那些。
 30-09之別人要如何聽到我的聲音呢 ?  接下來花了幾篇文章來理解網路傳輸協議。
 30-10之通訊協議的基本常識 30-11之 TCP 與 UDP 協議 30-12之 RTP/RTCP 傳輸協議 30-13之 RTSP 傳輸協議 30-14之 RTMP 傳輸協議 30-15之 HLS 傳輸協議 30-16之 HTTP-FLV 傳輸協議 30-17之 MPEG-DASH 傳輸協議 30-18之影音傳輸協議總整理  在理解完上面幾篇文章以後，我們應該是可以將聲音與影像傳輸給遠方的某個人。</description>
    </item>
    
    <item>
      <title>30-29之 WebRTC 的 P2P 打洞術 ( ICE )</title>
      <link>https://mark-lin.com/posts/20180929/</link>
      <pubDate>Sat, 29 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180929/</guid>
      <description>正文開始 上一篇文章中，咱們已經理解了為什麼 P2P 連線如此的困難，接下來這篇文章咱們將要學習：
 WebRTC 是如何進行打洞與連線呢 ?
 WebRTC 的打洞流程 ICE WebRTC 它主要使用一個名為ICE ( Interactive Connectivity Establishment ) 的框架來進行打洞，它內部整合了 STUN 與 TURN 協議，下面簡單的說明一下這兩個協議。
STUN ( Session Traversal Utilities for NAT ) 中文為 NAT 對談穿透應用程式，它的最主要用處就是幫助在 NAT 內的用戶找到可以連到它的位置。
STUN-RFC3489 STUN-RFC5389
TURN ( Traversal Using Relay NAT )，它也是一種穿透 NAT 的一樣協議，不過它是使用中繼的方式來進行，通常都是 STUN 的候選位置都無法連線時，才會使用它。
TURN-RFC5766
WebRTC 連線流程 假設目前要連線的雙方情況如下：
A 內網位置：192.168.1.1:5555 B 內網位置：10.10.1.1:7777 A 外網位置(經過 NAT 轉換)：310.110.1.1:9000 B 外網位置(經過 NAT 轉換)：210.210.1.1:7000 TURN Server：111.111.111.111 下圖為示意圖。表示雙方去外部連 Server 時對外的的位置。</description>
    </item>
    
    <item>
      <title>30-28之 WebRTC 連線前傳 - 為什麼 P2P 連線很麻煩 ? ( NAT )</title>
      <link>https://mark-lin.com/posts/20180928/</link>
      <pubDate>Fri, 28 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180928/</guid>
      <description>正文開始 在開始說明 WebRTC 如何建立 P2P 連線前，咱們要先理解一件事情，那就是 WebRTC 要使用非常多的 P2P 連線技術，那位啥它需要使用如此多的技術呢 ? 那就是本篇文章要探討的主題：
 為什麼 P2P 連線很麻煩呢 ?
 因為如果你理解了這個問題，你就會知道為什麼 WebRTC 要使用怎麼多的技術來進行 P2P 連線囉，這也是為什麼我們會先說明這篇文章。
本篇文章的問題，為什麼 P2P 的連線會很麻煩呢 ? 最主要的問題在於：
 NAT 與防火牆的存在。
 因此本篇文章將針對這兩個東西來理解
 NAT 與防火牆是啥 ? NAT 的運作原理。 為什麼有了 NAT 後 P2P 會很麻煩 ? NAT 的分類。  NAT 與防火牆是啥 ? NAT NAT (Network Address Translation) 中文就做網路位置轉換，它是用來將私網 IP 轉換成公網 IP 的技術。
為啥會有 NAT ? 先說說它的起源。
在咱們世界裡有個叫 IPV4 的地址規則，由於它數量稀少，不可能讓每一台電腦都有一個地址，因此就有了以下的解法如下圖，就是每個家庭或公司只有一組地址，然後公司內的電腦就使用這位置來上網。
其中常用的私有 IP 段為：</description>
    </item>
    
    <item>
      <title>30-27之 WebRTC 的 Signaling Server</title>
      <link>https://mark-lin.com/posts/20180927/</link>
      <pubDate>Thu, 27 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180927/</guid>
      <description>正文開始 上一篇文章中，咱們已經學習完了 WebRTC 的一些基本知識，接下來咱們要針對 Signaling Server 這東東來做做一些比較深的的探討。
 Signaling Server 要做的事情。 WebRTC 與 SDP。 Signaling Server的實作選擇。  Signaling Server 要做的事情 在上一篇文章，我們大概知道了 Signaling Server 要做的事情，它要做的就是：
 在建立 WebRTC 時，讓不認識的雙方可以相互的認識 (也就是知道對方的位置)
 順到說一下 WebRTC 並沒有定議 Signaling Server 的標準。
那 Signaling 是如何讓雙方知道對方的位置呢 ? Signaling 是如何讓雙方認識呢 ?
它就像是一個交友仲介商，每當某位用戶要進行聯誼時，用戶會提交一份履歷，這裡面就寫這他家在那，然後有配對到時，就會將這份履歷交給配對者，然後配對者如果覺得可以認識看看，他也會提供一份履歷給 Signaling Server，這樣雙向就可以進行面談了，其中已 Signaling 角度而言，履歷就是指 SDP。
什麼是 SDP ? 下章節在說。
為啥 WebRTC 不建立 Signaling Server 的標準呢 ? 因為事實上要讓兩個瀏覽器能進行溝通，可以不需要 Signaling Server，如果你知道對方在那的情況下，在筆者的『30-10之通訊協議的基本常識』這篇文章中有提到，假設你知道了對方的 port 就代表你可以找到對方電腦內某個應用程式的位置，而你知道了 ip 那就代表你知道對方在那，所以這時你事實上就可以與對方溝通。
WebRTC 與 SDP SDP (Session Description Protocol) 中文叫會話描述協議，在一段會話建立起來前，咱們需要一些建立這會話雙方的資訊，假設 A 與 B 要建立會話，所以這時 A 會發送一個 SDP 給 Signaling，內容包含了 A 的地址、媒體類型、傳輸協議、媒體格式等或是一些它所在的時區資訊，然後 Signaling 會將 A 發送的 SDP 給 B，這樣雙方就知道如何建立連線了。</description>
    </item>
    
    <item>
      <title>30-26之 WebRTC 的 P2P 即時通信與小範例</title>
      <link>https://mark-lin.com/posts/20180926/</link>
      <pubDate>Wed, 26 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180926/</guid>
      <description>正文開始 在很前面的文章中，咱們有簡單的介紹如何使用 WebRTC 來採集聲音與影像，但那時只是很簡單的介紹一下而以，所以接下來的幾篇文章，咱們將要來深入的了解 WebRTC。
這篇文章將要介紹幾個 WebRTC 的基概念，大約分成以下幾個章節:
 WebRTC 的誕生與內部架構。 WebRTC 所支援的語音視編碼與傳輸協議。 WebRTC 提供的基本 P2P 功能。 WebRTC 的簡單通訊實作。  WebRTC 的誕生與內部架構 首先在 Web 通信的世界中，基本上都是所謂的 C/S 架構，也就是所謂的 client 與 server 架構，通常 client 要取資料時就是發送一個請求給 server 然後它會回傳資料回去，其中 ajax 的出現讓我們更能以少量的資源來取得資料，在這階段時都部份都是單向溝通，也就是 client 請求 server。
而在二階段能，人們開始有種需求，例如股票報價網站，人們希望可以看到當有股價變動時，網頁可以也同時更動，這時如果用上面那種模式，那就只能 client 定時的去 server 拿資料，也就是咱們所謂的輪詢，但這種方法很明顯的非常的浪費資源，你可以呼叫 server 十次，但只有一次才真的有新的資料。而這時webSocket就用來解決這向事情，它提供了雙向溝通功能，server 就可以透過它，來將資料推給 client。
基本上以上已經解決了 client 與 server 的雙向互動，但這時人們又在想，假設我是做個一對一的聊天工具，那為什麼還需要 server 呢? 不能直接 client 與 client 進行溝通就好呢 ? WebRTC 就是可以幫助我們完成的工具，它就是用來專門處理瀏覽器與瀏覽器之間的即時溝通。
備註：雖然說是 cleint 與 client 直接進行溝通，但不是說不需要 server，後面會說明。</description>
    </item>
    
    <item>
      <title>30-25之直播連麥的挑戰與方案 ( P2P )</title>
      <link>https://mark-lin.com/posts/20180925/</link>
      <pubDate>Tue, 25 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180925/</guid>
      <description>正文開始 現今大部份的直播咱們要可以與漂亮的直播主姐姐或硬漢大叔進行互動，基本上咱們只能使用文字，也就是所謂的聊天室，而這篇文章咱們將要介紹另一種互動方式，那就是直播連麥，也就是直播主與聽眾可以進行語音溝通，更白話文的是說可以和漂亮姐姐進行語音聊天。這也就是本篇文章的主題。
 可以和漂亮姐姐進行語音聊天的難題與方案。
 本篇文章將分成兩個章節：
 直播連麥的挑戰 直播連麥的架構  直播連麥的挑戰  直播連麥最大的難題就是『 延遲 』問題。
 假設我們在一般直播時，以比較低的延遲 2 秒來計算的話 ( 就是主播說話聽眾 2 秒鐘後才能聽到 )，那這樣在直播連麥時會發生什麼事情呢 ?
如下圖所示，直播主說話以後，要經過 4 秒以後才會聽到連麥者的回復，而連麥者也相同的要等 4 秒後才能聽到直播主的回應，你覺得這樣還可以對話嗎 ?
這裡來問個問題。
為什麼直播會延遲呢 ? 基本上可以分四個部份，如下圖。呃下面兩個箭頭算一部份，所以分別為直播主處理、網路傳輸、CDN 與 Media Server 處理、聽眾端處理。
首先第一個部份是直播主 Client 它需要花時間來進行聲音與影像的採集，接下來進行編碼，最後就準備封裝然後準備送貨。
這部份有沒有可以優化的地方呢 ?
基本上可以在編碼上加速，網路上有提到說硬編碼與軟編碼這兩個聽起來很硬東西，其中軟編碼就是使用 CPU 來編碼，而硬編碼就是使用非 CPU 來進行編碼，例如使用 GPU。
而硬編碼效能優於軟編碼，不過需要硬體支援，這方面我沒很熟，請當參考。
第二部份為網路傳輸 只要實用網路進行傳輸，基本上都一定會發生延遲問題，而最主要產生的原因有兩個：
 距離。 傳輸時的封包維護。  首先距離是不用說的，直播主離你越遠，它的聲音要傳到你的小耳朵裡，一定比較花時間。
然後第二點是傳輸時的封包維護，在網路傳輸時基本上會發生兩件事情網路抖動與網路掉包。
網路抖動就是你傳送 A、B、C 封包給某個人，但某個人收到的封包為 C、B、A，那這時就要針對這狀態做一些處理，方法可能是緩存等到某段時間後，在根據封包裡面的時間來依順序播放，但緩存那邊就會產生延遲時間囉。
而網路掉包就是你傳送 A、B、C 但實際上對方只收到 A、B，而這時如果是 TCP 的話，它就會一段時間後，會在發送一次封包 C，然後這段時間也就產生延遲囉。</description>
    </item>
    
    <item>
      <title>30-24之直播與點播可動版的改良 ( 正式版 )</title>
      <link>https://mark-lin.com/posts/20180924/</link>
      <pubDate>Mon, 24 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180924/</guid>
      <description>正文開始 上一篇文章中咱們學習完了 CDN 的相關知識以後，接下來這篇文章，我們將要將上一篇所學的來改善咱們以下兩篇文章可動版的架構。
 使用 CDN 來調整可動版的架構
 30-20之如何建立像 KKTV 一樣的點播功能呢 ? 30-21之如何建立的像 17 一樣的直播功能呢 ?
點播 直播 本篇文章會分成以下幾個章節：
 可動版本的問題。 點播的架構改善版本。 直播的架構改善版本。  可動版本的問題 在筆者這篇文章中『30-22之點播與直播可動版問題探討』，我們探討了可動版有以下的問題：
 人多時連線數限制問題。 人多時頻寬問題。 人多時效能消耗問題。 遠距離看片卡頓的問題。  基本上 1、3 我們可以用傳統的方法(加機器)來解決，而 2、4 就無法使用加機器來進行解決，因為以 2 的頻寬問題，就算你加了在多的機器，如果你在出去的網路還是在同一條，那頻寬還是沒加大，問題還是沒解決。而 4 的話就更不用說，只能讓使用者離機器更近一點才能解決。
點播架構的改善版本 基本上點播的架構會改成如下圖，它會將 CDN 加上去，而這樣就可幫助我們解決頻寬與距離看片卡頓的問題。
先來說說頻寬的部份， CDN 基本上分散在不同的地方，這也代表這基本上它們的頻寬是各別獨立的，所以不太會發生搶頻寬的問題，而另一點距離的問題，由於大部份的 CDN 都會搭配使用智能 DNS 來幫助找到最近的 CDN，因此可以解決因為離影片來源太遠，而容易造成封包遺失與封包順序不一致問題。
而且用了 CDN 事實上還有一個好處，那就是可以保證接近 100 的機率可以看片，你想想如果是自已建的一台 Media Server 來提供看片，如果它倒了，不就不能看片了，而有 CDN 就可以自動的轉到另一個臨近的 CDN 來取得資料。
接下來說說它的運行流程，基本上如下 (以 HLS 拉流為範例)：</description>
    </item>
    
    <item>
      <title>30-23之 CDN 的說話島 ( AWS CloudFront  CDN 實作 )</title>
      <link>https://mark-lin.com/posts/20180923/</link>
      <pubDate>Sun, 23 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180923/</guid>
      <description>正文開始 上一篇文章中，咱們有提到點播與直播可動版本的一些問題，如下所列。
 人多時連線數限制問題。 人多時頻寬問題。 人多時效能消耗問題。 遠距離看片卡頓的問題。  接下來咱們要來理解一下，解這上述問題的關鍵技術 CDN 是什麼東西 ?
本編文章將分為以下幾個章節：
 什麼是 CDN 呢 ? 它又是用來解決啥呢 ? CDN 的請求運作方式。 使用 AWS CloudFront 來建立 CDN。  什麽是 CDN 呢 ? 它又是用來解決啥呢 ? 在開始理解 CDN 之前，咱們先來說說傳統上一個 client 連線到一個網站的流程。
首先看看下面這張圖，這張圖說明了每當一個 client 發送一個請求到 web 網站時，web 網站會回傳 html、css 與 javascript 回來，這裡假設咱們的 web 網站還在台灣，然後回應時間大約在 100 ms 以內 (假設)。
然後呢 ~ 這時付你錢的老大叫你將 web 網路架設到美國，因爲免費，然後這時發現回應時間變成 1000 ms 左右。
然後開始了有以下的對話 :
老大：回應時間怎麼回事 ? 碼農仔：老大你叫我架到美國啊 !? 老大：我要的不是這回答，而是問你為啥回應時間你沒修改回來 ?</description>
    </item>
    
    <item>
      <title>30-22之點播與直播可動版問題探討</title>
      <link>https://mark-lin.com/posts/20180922/</link>
      <pubDate>Sat, 22 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180922/</guid>
      <description>正文開始 前面文章中咱們簡單了可以動的點播 ( like KKTV )與直播 ( like 17 )的功能，那接下來這篇文章主題要探討的目問題為：
 這兩篇文章實際上應用會有什麼問題 ?
 30-20之如何建立像 KKTV 一樣的點播功能呢 ? 30-21之如何建立的像 17 一樣的直播功能呢 ?
點播可動版架構 直播可動版架構 本篇文章分根據問題分成以下幾個章節：
 人多時連線數限制問題。 人多時頻寬問題。 人多時效能消耗問題。 遠距離看片卡頓的問題。  人多時連線數限制問題 咱們都知道，每當 Client 要和 Server 要資料時，如果是以 TCP 傳輸為基礎的，那就一定要建立一條連線，那對 Server 而言連線是啥了 ?
在 unix 中每一個 TCP 連線都要占用一個 file descriptor，而它有一定的限制數量，當使用完後，新的 TCP 連線到來就會發生錯誤以下的錯誤訊息 :
Socket/File: Can&#39;t open so many files。 那一個 process 我們可以開啟幾個檔案呢 ? 我們可以用以下的指令來看看 :
ulimit -n 那這個最大值為多少呢 ? 這個我不確定，像我家用的 Aws Elasticsearch 就有 128000。</description>
    </item>
    
    <item>
      <title>30-21之如何建立的像 17 一樣的直播功能呢 ?</title>
      <link>https://mark-lin.com/posts/20180921/</link>
      <pubDate>Fri, 21 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180921/</guid>
      <description>正文開始 上一篇文章中，咱們已經學習了如何建立點播這種類型的網站應用，接下咱們要來學學如何建立直播應用。
在筆者的30-09之別人要如何聽到我的聲音呢 ?有提到三種影音的傳遞方式，分別為：
將聲音檔案直接丟給對方 ( 方法 1 ) 將聲音檔案以串流的方式傳送給對方 ( 方法 2 ) 像直播或網路電話一樣即時的將聲音傳送給對方 ( 方法 3 )
接下來我們將來實作方法 3 的選項，而這東西事實上就是直播網站的應用，像 17 就是這種類型的應用，本篇文章將會說明：
 如何建立的像 17 一樣的直播功能呢 (可以動就好版) ?
 本篇將分為以下幾個章節：
 直播架構原理。 實作 - 建立 Media Server。 實作 - 網頁用戶端取得串流影像。  直播架構原理 直播的架構最基本的如下圖，基本上和點播很相似，只差了直播主推送聲音到 Media Server 這個步驟。
然後基本上推流的協議，應該是只有一種選擇RTMP，網路上看到有人說 HLS 這點我還要待調查，我先打個問號， 然後還有提到 WebRTC 這個可以當推流 (不過它應該不算傳輸協議)，這理論上應該是行，這之後 WebRTC 的文章會來聊聊。
而拉流就有不少RTMP、HLS、HTTP-FLV、MPEG-DASH。
老樣子問個問題。
那要選擇那個協議來當拉流呢 ? 首先我覺得要先看你的直播應用是否為互動性很要求的，如果是它就只有兩個選擇 RTMP 與 HTTP-FLV。不過 RTMP 拉流應該會有不少設備無法使用(果粉)，所以最後應該會選 HTTP-FLV 吧。
而如果是不會太在意互動性的直播，例如運動賽事直播這種，那選那個，我覺得就看用戶那的支援度吧。</description>
    </item>
    
    <item>
      <title>30-20之如何建立像 KKTV 一樣的點播功能呢 ? </title>
      <link>https://mark-lin.com/posts/20180920/</link>
      <pubDate>Thu, 20 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180920/</guid>
      <description>正文開始 前面聲音與影像的基本原理都學習完後，咱們接下來要來實作一些東西。
在筆者的30-09之別人要如何聽到我的聲音呢 ?有提到三種影音的傳遞方式，分別為：
 將聲音檔案直接丟給對方 ( 方法 1 ) 將聲音檔案以串流的方式傳送給對方 ( 方法 2 ) 像直播或網路電話一樣即時的將聲音傳送給對方 ( 方法 3 )  接下來我們將來實作方法 2 的選項，而這東西事實上就是點播網站的應用，像 KKTV、楓林網就是這種類型的應用，本篇文章將會說明：
 如何建立的像 KKTV 一樣的點播功能呢 (可以動就好版) ?
 先說好，如果真的要建立像 KKTV 一樣的可營運的應用，還需要做不少架構的調整，這裡就是只是學習如何做出可以動的點播網站，也就是可以看片 (不是全部下載完才可以看)。
本篇將分為以下幾個章節：
 點播架構原理。 實作 - 建立 Media Server。 實作 - 網頁用戶端取得串流影像。  架構原理 基本上點播的架構，最基本(不管流量或 CDN 這些鬼)的樣貌會如下：
然後基本上可以選擇的協議有RTMP、HLS、HTTP-FLV、MPEG-DASH。
那這裡問個問題 ?
我要選擇那個協議呢 ? 基本上我覺得是要看你的用戶端的裝置取向，基本上以現在的狀態選擇 HLS 與 MPEG-DASH 在點播類的應用，應該是最安穩的，最主要我覺得有以下三個原因：
 這兩個都是使用 HTTP 來傳輸，不太會發生有的用戶可以看有的不行。 大部份的平台都可以找到方法支援。 這兩種都有支援依劇網路狀況，來自動調整畫質的功能，這在看影片時尤其有用。  這兩個協議可以去參考筆者的以下兩篇文章。</description>
    </item>
    
    <item>
      <title>30-19 之收到聲音後要如何的播出呢 ?  ( FFMpeg )</title>
      <link>https://mark-lin.com/posts/20180919/</link>
      <pubDate>Wed, 19 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180919/</guid>
      <description>正文開始 在前面的文章中，咱們咱們已經會了如何將聲音傳送給對方，而接下來這篇文章咱們就要來學習
 收到了聲音已後，要如何的播出呢 ?
 咱們收到聲音以後(檔案或串流) 那接下來要如何播出了 ?
答案就是使用播放器，而接下來我們就要來介紹大部份播放器的內核ffmpeg。
基本上本篇分成以下的章節來理解 ffmpeg 這好用的東東：
 ffmpeg 是啥 ? ffmpeg 的基本架構。 ffmpeg 的簡單使用範例。  FFMpeg 是啥 ?  它就是可以幫咱們進行一些影音的奇技淫巧 (ex. 解碼、編碼、轉碼、抽取、串流)
 FFmpeg (Fast Forward MPEG) 它是一個開源的影音多媒體的火藥庫，有了它我們可以很簡單的將前面幾個章節中提到的採集、編碼、封裝內容給串連起來。
它最核心的應用是當播放器的核心。
前面的章節有提到，我們將一段聲音從麥克風採集下來後，先經過編碼將它縮小，然後在封裝成一個容器，最後在透過網路傳輸協議，將它丟到對方的電腦後，接下要如何處理呢 ?
對方電腦的處理過程如下圖，它會先解析容器，然後進行解碼，最後在輸出聲音到對方的耳機或啥的。
其中處理解析容器與協定，然後再進行解碼的就是咱們電腦中所使用的播放器，像是 KMPlayer、千千靜聽、QuickTime Player，而有不少的播放器裡面都是以 ffmpeg 為內核，像是 KMPlayer 與 QQ 影音。
當然 ffmpeg 還有很多的使用功能，下面簡單的列幾個例子：
 它可以將一個影音檔，轉換成多張的圖片與分割出聲音。 它將某個影音檔的編碼轉換成其它的編碼。 它可以將影音檔使用 RTMP 推送到 Server ( 就是可以模擬直播主推聲音到 Server ) 它可以使用 HLS、RTMP 這些傳輸協議將聲音拉下來。  總而言之，它就是個影音軍火庫。
FFMpeg 的基本架構  它事實上是一系列的工具，基本上是由以下幾個組合而成。</description>
    </item>
    
    <item>
      <title>30-18 之影音傳輸協議總整理</title>
      <link>https://mark-lin.com/posts/20180918/</link>
      <pubDate>Tue, 18 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180918/</guid>
      <description>正文開始 30-12之 RTP/RTCP 傳輸協議 30-13之 RTSP 傳輸協議 30-14之 RTMP 傳輸協議 30-15之 HLS 傳輸協議 30-16之 HTTP-FLV 傳輸協議) 30-17之 MPEG-DASH 傳輸協議)
前面的幾面文章，咱們學習了各種型的影音傳輸媒體，接下來將會在這一篇文章中，進行這些協議的總結。
 各種影音傳輸協議之比較與整理
 一張圖來簡單的理解各種協議的運作方式 RTSP RTMP HLS HTTP-FLV MPEG-DASH 特點整理    協議 傳輸層選擇 聲音編碼 影像編碼 延遲性     RTSP RTP、TCP、UDP RTP 可支援的都行 RTP 可支援的東行 低   RTMP TCP AAC、MP3 H.26X 系列 低   HLS TCP (因為它是用 HTTP ) AAC、MP3 H.26X 系列 高   HTTP-FLV TCP (因為它是用 HTTP ) AAC、MP3 H.</description>
    </item>
    
    <item>
      <title>30-17之 MPEG-DASH 傳輸協議</title>
      <link>https://mark-lin.com/posts/20180917/</link>
      <pubDate>Mon, 17 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180917/</guid>
      <description>正文開始 接下來咱們要來介紹 MPEG-DASH協議。
 MPEG-DASH 協議
 本篇文章將會分成幾個章節來理解 MPEG-DASH 協議：
 MPEG-DASH 協議是要用來完成什麼事情呢 ? MPEG-DASH 協議如何完成它想做的事情呢 ? 建立 MPEG-DASH 的串流傳輸流程。 MPEG-DASH 的特點總結。  MPEG-DASH 協議是要用來完成什麼事情呢 ?  讓 client 與 server 可以透過 Http 來進行流媒體的傳輸
 嗯事實上它想完成的事情和 HLS 事實上是相同的，那為啥他會誕生出來呢 ? 比較大的問題是
 HLS 是由蘋果所主導的協議，而不是國際通用協議，這也代表蘋果怎麼改，其它人也要一起動，也就是說一切蘋果說的算。
 因此在 MPEG 的主導下在與一些大廠合作下 MPEG-DASH 這種國際標準的協議就誕生了。
ISO/IEC 23009-1:2012
MPEG-DASH 協議如何完成它想做的事情呢 ?  它將聲音切成一小個一小個檔案，然後 client 就一個一個發 http 去下載。
 就如同 HLS 一樣。
建立 MPEG-DASH 的串流傳輸流程 它的基本流程如下圖。
1. 直播主將聲音或影像傳輸到 Server 這裡可以使用 RTMP 來將聲音推收到 Server，又或是如果不是直播情況可以直接將聲音檔例如 .</description>
    </item>
    
    <item>
      <title>30-16之 HTTP-FLV 傳輸協議</title>
      <link>https://mark-lin.com/posts/20180916/</link>
      <pubDate>Sun, 16 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180916/</guid>
      <description>正文開始 接下來咱們要來介紹 HTTP-FLV 協議。
 HTTP-FLV 協議
 本篇文章將會分成幾個章節來理解 HTTP-FLV 協議：
 HTTP-FLV 協議是要用來完成什麼事情呢 ? HTTP-FLV 協議如何完成它想做的事情呢 ? 建立 HTTP-FLV 的串流傳輸流程。 HTTP-FLV 的特點總結。  HTTP-FLV 協議是要用來完成什麼事情呢 ?  可以使用 HTTP 來完成低延遲的串流媒體傳輸。
 那為啥他想使用 HTTP 呢 ?
先來說說 RTMP，它不是基於 Http 來進行傳輸，所以他個缺點，那就是有一定的機率被封，而且還有另外一點，通常使用 Http 的來進行傳輸的 html5 會支援的不錯，像在 chrome 比較新的幾個版本就有開始支援 HLS，而當然 RTMP 不支援。
那為啥不用 HLS 呢 ?
使用 HLS 的極大缺點就是它的延遲問題，可能直播主說個話後，大約要 10 秒左右聽眾才可以聽到，而 HTTP-FLV 就是想要解決這件事情。
HTTP-FLV 協議如何完成它想做的事情呢 ?  將聲音與影像封裝成 FLV 流容器，然後在使用 Http 進行流式傳輸。
 以直播情況來看，直播主會將聲音用任何方式 ( RTMP 或啥的 ) 傳送到 Server，然後 Server 會將它轉換成 FLV 檔，然後 Client 會使用 Http 來請求這個畫面，請求如下，然後 Server 就會用 Http 流的方式就影像一段一段的傳輸過去。</description>
    </item>
    
    <item>
      <title>30-15之 HLS 傳輸協議</title>
      <link>https://mark-lin.com/posts/20180915/</link>
      <pubDate>Sat, 15 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180915/</guid>
      <description>正文開始 接下來咱們要來介紹 HLS 協議。
 HLS 協議
 本篇文章將會分成幾個章節來理解 HLS 協議：
 HLS 協議是要用來完成什麼事情呢 ? HLS 協議如何完成它想做的事情呢 ? 建立 HLS 的串流傳輸流程。 HLS 的延遲問題。 HLS 的特點總結。  HLS 協議是要用來完成什麼事情呢 ?  讓 client 與 server 可以透過 Http 來進行流媒體的傳輸
 HLS ( HTTP Live Streaming ) 是由高大尚的蘋果公司所開發，再 HLS 還沒誕生之前，這世界大部份的流媒體傳輸都是被 RTMP 所佔據，最主要的原因在於當時，大部份的電腦都有裝 Flash Player。
而蘋果開發出 HLS 主要有兩個原因：
 不想被 Flash 綁死，所以它大部份的設備都慢慢的把 Flash 拔掉(當時)。 RTMP 有個問題就是，它不是透過 HTTP 來進行傳輸，所以它很有可能會被一些防火墻防掉。  HLS 協議如何完成它想做的事情呢 ?  它將聲音切成一小個一小個檔案，然後 client 就一個一個發 http 去下載。</description>
    </item>
    
    <item>
      <title>30-14之 RTMP 傳輸協議</title>
      <link>https://mark-lin.com/posts/20180914/</link>
      <pubDate>Fri, 14 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180914/</guid>
      <description>正文開始 接下來咱們要來介紹 RTMP 協議。
 RTMP 協議
 本篇文章將會分成幾個章節來理解 RTMP 協議：
 RTMP 協議是要用來完成什麼事情呢 ? RTMP 協議如何完成它想做的事情呢 ? 建立 RTMP 的串流傳輸流程。 RTMP 的特點總結。  RTMP 協議是要用來完成什麼事情呢 ? 它當初的動機為：
 在 Flash 平台與伺服器進行串流媒體傳輸的協議
 RTMP( Real-Time Messaging Protocol )，為 Adode 所開發，它就是要用來讓 Server 可以與 Flash 平台進行串流傳輸。
這裡問個問題。
為什麼不要用 RTSP 來進行傳輸呢 ? 這裡我覺得有兩個原因：
 因為 RTSP 大部份還是基於 RTP over UDP 上，由於當時 RTSP 大部份都用在 IPTV 或 VOD 上這些都是有專門一條線給它用，所以網路很穩定。但是 RTMP 當初是希望開發在互聯網上，所以不能保證網路很穩定，因此它選擇用 TCP 來傳輸。2. 因為想建立一個更符合 Flash 用途的協議。我猜的。  更多有支援的請參考RTMP Spec在 31、32 頁。</description>
    </item>
    
    <item>
      <title>30-13之 RTSP 傳輸協議</title>
      <link>https://mark-lin.com/posts/20180913/</link>
      <pubDate>Thu, 13 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180913/</guid>
      <description>正文開始 本篇文章咱們將要開始介紹第一個應用層的流通訊協議 RTSP，別忘了上一篇介紹的 RTP 是傳輸層。
 RTSP 協議
 本篇文章將會分成幾個章節來理解 RTSP 協議：
 RTSP 協議是要用來完成什麼事情呢 ? RTSP 協議如何完成它想做的事情呢 ? 建立 RTSP 的串流傳輸流程。 RTSP 的特點。  RTSP 協議是要用來完成什麼事情呢 ?  它是被設計出來為，為了控制串流媒體 Sever 的協議 (ex. 快轉、暫停影片之類)
 RTSP 它被設計出來是為了可以控制串流媒體伺服器的協議 (所以他是 C/S 架構)，例如我們先發送一個觀看影片的請求給 Server，然後它就開始以串流型式來傳輸影片，然後這時我們可以用 RTSP 所提供的一些方法，來進行影片的快轉或暫停，為了能控制串流就是它被設計出來的原理。
就如同下圖所示，RTSP 讓我們可以操控串流媒體。
RTSP 協議如何完成它想做的事情呢 ? 那它要如何控制呢串流呢 ?
 它定義了控制的方法與參數
 就如同 HTTP 一樣，它定義了一些方法可以給我們控制，例如 Play 這個動作，當串流 Server 看到這個動詞後，就會開始傳輸影片給請求者。
建立 RTSP 的串流傳輸流程 我們直接去使用網路上所提供的 RTSP 進行請求看看。這個連結你可以使用 ffplay 來開啟 (ffplay 之後會提)。</description>
    </item>
    
    <item>
      <title>30-12之 RTP/RTCP 傳輸協議</title>
      <link>https://mark-lin.com/posts/20180912/</link>
      <pubDate>Wed, 12 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180912/</guid>
      <description>正文開始 在前一篇學習完了 TCP 與 UDP 協議以後，咱們要介紹另一個傳輸層協議：
 RTP 協議 (RTCP 後來會提到)
 本篇文章將會分成幾個章節來理解 RTP 協議：
 RTP 協議是要用來完成什麼事情呢 ? RTP 協議如何完成它想做的事情呢 ? RTP 協議的基本概念與封包組成。 RTP 要如何進行 Qos 的保證呢 ?  RTP 協議是要用來完成什麼事情呢 ?  RTP 協議想可以完成『 端點到端點的串流媒體傳輸 』 (ex. 聲音、影像)
 它目前廣泛的使用於流通訊領域，例如 VOIP、網路會議，網路電視等。
這裡問個問題，為什麼 RTP 是傳輸層的呢 ? 因為它只是專門用來傳輸串流媒體的協議，而不管實際如何應用。你列出幾個傳輸層應用想完成的事情，大概就可以理解為啥它是傳輸層的。
傳輸層 UDP：傳輸資料 TCP：可靠的傳輸資料 RTP：傳輸多媒體資料 應用層 HTTP：HTTP server 與客戶端的表準應答 RTP 協議如何完成它想做的事情呢 ?  它定義了要傳輸串流媒體的參數標準 (封包標準)
 RTP 協議它定議好了多媒體傳輸的參數標準，咱們來思考一下，如果直接使用 UDP 或 TCP 來傳送媒體資料會發生什麼事情。
先以簡單的 UDP 為例子，它的封包大約會長的如下：</description>
    </item>
    
    <item>
      <title>30-11之 TCP 與 UDP 協議</title>
      <link>https://mark-lin.com/posts/20180911/</link>
      <pubDate>Tue, 11 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180911/</guid>
      <description>正文開始 上一文章中咱們理解了每一層通訊協議大約是在做什麼事情以後，咱們這篇文章中將專門來說明，在傳輸層的兩個協議TCP與UDP。
為什麼會選這兩個出來說呢 ? 因為在即時影音傳輸的世界中，這兩個協議常常拿出來進行比較(雖然大部份還是 TCP)，而且這兩個是所有資料傳輸的基本，不論是要傳輸文字、檔案、語音都一定會透過這兩個來傳送資料，所以這兩個很重要。
這篇文章的主是題就是：
 什麼是 TCP 和 UDP 呢? 這協議到底用來做啥的 ?
 接下來會就簡單的分成兩個章節：
 UDP (User Datagram Protocol) TCP (Transmission Control Protocol)  UDP (User Datagram Protocol) 首先我們已經知道協議是用做完成某事件的過程，那 UDP 是想用來做什麼呢 ?
咱們已經知道傳輸層主要是處理應用程式與應用程式如何進行傳輸，而要送到某個應用程式最基本所需要的東西就是 Port。
UDP 就是符合咱們最低需求的東西。
 UDP 就是用來傳輸資料到某台電腦中的應用程式 (有沒有收到不用管)
 它的封包長的如下。
UDP 封包 = 表頭 + 資料 其中表頭欄位如下，事實上也就只是加上 Port 而以，其中 length 只是用來說明它是資料有多大。
Source Port: 55084 Destination Port: 443 Length: 31 (byte) UDP 注意事項  UDP 的特點就是射後不理，他不會管對方有沒有收到的 (不可靠傳輸)。 它有可能會發生到達順序不一致問題。  Ex.</description>
    </item>
    
    <item>
      <title>30-10之通訊協議的基本常識</title>
      <link>https://mark-lin.com/posts/20180910/</link>
      <pubDate>Mon, 10 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180910/</guid>
      <description>正文開始 在開始進行流媒體通訊協議前，咱們要先來學習什麼是通訊協議，這個東西沒有學習好，雖然你還是可以幹出一個直播服務器，但就只是做出來，但是當你碰到問題時，或是想要追求更高的效能時，一定卡關。
 通訊協議的基本常識
 接下來本篇文章會分成以下的章節，為了來理解上面的主題：
 什麼是通訊協議呢 ? TCP/IP 通訊協議架構。 從 A 到 B 發送數據的流程。  什麼是通訊協議呢 ? 我相信很多人都已經有使用過很多 http、tcp、udp 這些東東，但是我相信還是有人應該只是懂的在瀏覽器打個 http 網址而以，然後說這就是通訊協議，某些方面不能說錯，但是我相信你這樣說給一個初學者聽一定很難理解的。接下來咱們來理一理到底什麼是通訊協議。
先來理理什麼是協議呢 ? 簡單的用白話文就是：
 協議就是 A 與 B 雙方要完成某件事情，所約定好的處理流程。
 咱們來舉個例子，假設有位仁兄，雙方住在一間屋子裡面，然後他們只有一把鑰匙，所以這時他們就在思考，一個人已經在房子裡面了，然後另一個回來以後就要敲門，然後在家的人就打開來。
但這時要如何確保敲門的人是室友呢 (先假設看不到外面) ? 如果是壞人敲門你直接開門，那你就準備呵呵呵了，所以 A 與 B 就約定好了一個確認室友協議，這個協議如下：
協議想完成事項：確認對方是不是室友
協議標準： 假設 B 在家，A 在外面。 A 敲 3 下門。 B 聽到後，要求 A 說暗語 (你今天真帥) A 說暗語(你今天真帥) B 收到後，就開門。 先不管上面的協議是否真的實用，只要知道它就是個協議就好囉。
最後所謂的通訊協議就是：
 所謂的『 通訊協議 』就是網路上 A 與 B 雙方要進行溝通所約定好流程。</description>
    </item>
    
    <item>
      <title>30-09之別人要如何聽到我的聲音呢 ?</title>
      <link>https://mark-lin.com/posts/20180909/</link>
      <pubDate>Sun, 09 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180909/</guid>
      <description>正文開始 之前的八篇文章中，我們已經理解完聲音與影像的採集與編碼原理，並且也簡單的進行 Web 方面的採集實作，接下來咱們就要開始進入網路的部份，而這部份最主要探討的主題為：
 別人要如何聽的到我的聲音呢 ?
 基本上這題的大約有三種思路，而這也是本篇文章的三個章節：
 將聲音檔案直接丟給對方 ( 方法 1 ) 將聲音檔案以串流的方式傳送給對方 ( 方法 2 ) 像直播一樣即時的將聲音傳送給對方 ( 方法 3 )  備註 讓對方看的到影像的方法也與聲音相同，所以這裡就以聲音為例來進行說明。
將聲音檔案直接丟給對方 ( 方法 1 ) 這個是最原始的一種方法，它就是將檔案丟給對方，然後等對方全部下載完後，才能聽到聲音，概念圖如下：
但是實作上的概念圖應該是如下圖，基本上在即時通訊軟體上，不太會是 client 與 client 進行 P2P 連線來直接丟聲音檔案，例如 line 之類的通訊軟體，因為它都要支援離線傳輸，因此架構實際上應該是會選擇將檔案丟到 server 然後再發送個通知給對方說有個檔案你可以下載。
這種作法基本一小段的聲音檔還行，但如果是要傳送一段很長的聲音或影像檔(ex 電影)，那基本上這個方法的缺點就會被放大，因為它要全部下載完你才可能看或聽，而且占空間，並且如果是音樂或電影，說不定還有版權的問題，因為這也代表你有音樂檔，可以分享給其它人。
這也是為什麼後來誕生了串流傳輸的技術囉。 將聲音檔案以串流的方式傳送給對方 ( 方法 2 ) 串流用比較白話文一點的說話就是:
 它是一種將資料一段一段的丟給去給你，而不會將所有的資料。
 詳細的串流說明可以去筆者之前寫的文章『Node.js 的串流之旅之基本概念』
那這樣有什麼好處理 ?
基本上有以下幾個好處：
 客戶端可以一邊下載一邊收聽。 不會花費客戶端的儲存空間，它會將一小段一小段的聲音傳送到客戶端的緩衝記憶體中，然後播放器會去記憶體中讀取後並播出，然後再捨棄掉。 由於客戶端沒有實際上儲放檔案，因此不會有一些音樂或影片版權的問題 (有檔案就可以傳來傳去)。  然後咱們這個方法的實作概念圖大概如下。
上面的簡易架構圖有一些東西咱們要來理解一下。</description>
    </item>
    
    <item>
      <title>30-08之 WebRTC 採集的詳細說明與聲音的加工</title>
      <link>https://mark-lin.com/posts/20180908/</link>
      <pubDate>Sat, 08 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180908/</guid>
      <description>正文開始 前一篇文章『30-07 Web 如何進行語音與影像採集 ?』咱們已經學習到如何使用 WebRTC 來進行聲音與影像的採集，並且將採集的結果儲放成一個 stream，最後在將儲放成檔案，接下來我們將研究一下 stream 裡面的東西，以及來簡單的將所採集到的聲音進行加工。
 採集的詳細說明與聲音的加工。
 本篇文章會將之分成以下幾個章節：
 WebRTC 的 Stream (Media Stream) 組成。 如何對 Media Stream 的聲音進行加工 ？  WebRTC 的 Stream ( Media Stream ) 組成  stream = track A + track B
 前一篇文章中，咱們有提到可以用以下的程式碼，將聲音與影像給採集下來。
const constraints = { audio: true, video: true } navigator.mediaDevices.getUserMedia(constraints) .then((stream) =&amp;gt; { // stream 就是咱們的聲音與影像 }) .catch((err) =&amp;gt; { // 錯誤處理 }) 然後咱們這裡來問個問題：
 stream 是由什麼組合的 ?</description>
    </item>
    
    <item>
      <title>30-07之Web 如何進行語音與影像採集 ?</title>
      <link>https://mark-lin.com/posts/20180907/</link>
      <pubDate>Fri, 07 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180907/</guid>
      <description>正文開始 前面幾篇咱們已經學習了聲音與影像的採集相關知識，那接下咱們來學習一下如何在 Web 上進行聲音與影像的採集。
 如何在 Web 上進行聲音與影像的採集 ? ( 其它平台的別問我 )
 這篇文章中，咱們將會用到一個東東叫做WebRTC，接下來會以它為主，將之分成以下三個章節：
 WebRTC 是啥 ? 使用 WebRTC 來採集聲音與影像 將採集到的聲音儲放成一個檔案  WebRTC 是啥 ?  讓瀏覽器不需加裝任何套件就可以進行即時文字、語音與影像對話的 API 。
 WebRTC　全名為　Web Real-Time Communication，中文為網頁即時通訊，這東東用途就是讓咱們的瀏覽器不用裝認何啥套件就可以進行和其它瀏覽器進行即時文字、語音與影像對話。
它在 2011 年時進入了 W3C 的推薦表準，並且到了現在(2018)，大部份的瀏覽器都有支援 (IE 例外)。
它主要有三種類型的 API：
 getUserMedia：用來處理音視串流採集。 (採集聲音或影像)。 RTCPeerConnection：用來建立兩個瀏覽器之間的直接通訊。 (建立與管理 p2p 連線) RTCDataChannel：負責用來傳送資料。(操作那條 p2p 連線)  基本上在這篇文章中只會用到第一個 getUserMedia 其它的 API 在後面文章會詳細的進行說明。
備註 當前（2018）支援各平台的狀態請參考以下連結：
WiKI: WebRTC Support
使用 WebRTC 來採集聲音與影像 事實上就是如此的簡單，下面程式碼中，我們使用 getUserMedia 來採集聲音與影像，而 stream 就是咱們所採集到的聲音與影像，它們都是 raw data，也就是說聲音是 PCM 編碼，而影像就是單純的一堆連續的圖片編碼。</description>
    </item>
    
    <item>
      <title>30-06之聲音與影像的封裝</title>
      <link>https://mark-lin.com/posts/20180906/</link>
      <pubDate>Thu, 06 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180906/</guid>
      <description>正文開始 前面的文章咱們已經學習到麥克風或攝影機如何的將聲音與影像進行採集，並且也學會了將這些 raw data 進行編碼為了讓它們儘量小點兒，好讓咱們傳輸時輕鬆些，接下來咱們要學習將這些東東封裝在一個容器中。
 聲音與影像的封裝
 本篇文章中我們將會分為以下章節，來探討這個主題：
 什麼是封裝呢 ? 常見的容器(文件、格式) 容器的實際模樣 ( 以 wav 為範例 )  什麼是封裝呢 ?  封裝就是將聲音與影像編碼丟到一個容器中的過程。
 簡而言之如下圖：
那為啥要封裝到容器呢 ? 基本上有以下幾個理由：
 可以讓不同的媒體內容同步變的方便，例如聲音與影像。 可以提供索引內容，讓用戶可以決定想要看或聽什麼地方。 如果沒有容器，只傳送一串影像編碼，那你還要在傳送聲音編碼才會有聲音。 如果只傳送編碼，如果沒有一些編碼資訊，那接受要如何解碼呢 ?  編碼與容器是一對多的關係 有些東西需要先搞個清楚一下，不然我一開始研究時常常在混亂中。
例如咱們很常說的 MP3 編碼、文件、格式，它到底是指啥 ? 編碼還是容器 ?
 咱們常看到的 .mp3 檔是個容器(文件、格式)，然後它裡面放了 MP3 編碼，再外加一些資訊。
 那 mp3 編碼可以放到其它容器裡嗎 ? 當然可以 ! 像他就可以放到 .mp4 或 .avi 容器中。
所以說基本上一種音頻編碼是可以有多種容器選擇的。
常見的容器(文件、格式) 接下來將介紹一些常見的容器，這也先說一下網路上在說明容器時有很多種名稱，例如音頻文件、音頻格式、音頻檔這些，它們指的都是容器的概念。
.wav (聲音) WAV (Waveform Audio File Format) 它是微軟開發出來的聲音容器，雖然它是微軟開發出來的，但在其它的平台也廣泛的支持，基本上它就是聲音 raw data 容器，就是用來儲放 PCM 編碼的。</description>
    </item>
    
    <item>
      <title>30-05之影像的編碼與壓縮</title>
      <link>https://mark-lin.com/posts/20180905/</link>
      <pubDate>Wed, 05 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180905/</guid>
      <description>正文開始 本篇文章中我們將要學習以下的主題:
 影像編碼
 接下來我們會分以下三個章節來進行學習:
 什麼是影像編碼呢 ? 如何進行壓縮呢 ? 常用的編碼  什麼是影像編碼呢 ?  用來描敘影像的有規則二進位。
 這個東西事實上就和音頻編碼一樣，都是使用電腦看的懂的東西(二進位)來說明一部影像，並且希望儘可能的在不損失畫質的前提下，將它弄小，可以方便我們傳輸與儲放。
但是為什麼要弄小呢 ? 它會很大嗎 ?
嗯超大。
我們來看看一個例子，假設有一部影像的資訊如下：
FPS：30 fps 每幀大小：1024 x 768 每個像素所用的 bit：10 bit 影像長度：10 分鐘
所以我們這部 10 分鐘的影像所需的空間為如下:
 30 X 1024 X 768 X 10 X 60 X 10 = 大約等於 18 GB 嗯哼， 10 分鐘的影片如果什麼都沒處理，那就需要 18 GB，你覺得你的小電腦可以儲放幾部迷片呢 ?
所以才會一堆人研究了各種的編碼。
如何將影像變小呢 ?  就是用一些奇技淫巧來壓縮。
 接下來我們來簡單的看一下壓縮的原理，比較白話文的是說可以去除影像中的什麼。
主要有以下幾個冗餘點(Redundancy)可以處理:
 圖像冗餘：圖像是由像素所組成，但是每個相鄰的像素，相似性非常的高，所以這裡可以動點手腳兒。 時間冗餘：影像是由連續的圖片組成，但每個相鄰的圖片，相似性非常的高，所以這裡也可以動點手腳兒。 視覺冗餘：人的小眼晴事實上不是很敏感的，所以你動點小手腳事實上也看不出來。 編碼冗餘：就是某些時後會不小心用到多餘的編碼來描述某個事物，所以這裡也可動手腳。  這個地方主要是參考智庫百科的數據冗餘</description>
    </item>
    
    <item>
      <title>30-04之影像的採集與原理</title>
      <link>https://mark-lin.com/posts/20180904/</link>
      <pubDate>Tue, 04 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180904/</guid>
      <description>圖片來源:馬克
正文開始  影像的產生與採集
 在聲音的採集與編碼後，咱們要開始學習影像採集的部份，在開始採集之前咱們要先理解圖片，接下來我們還要學習對電腦來說影像到底是如何組成的。
 對電腦來說圖片是啥呢 ? 那對電腦來說影像又是啥呢 ? 那一個連續的影像有多大呢 ?  對電腦來說圖片是啥呢 ?  它是一堆像素 (Pixel) 的組合體，白話文就是一堆顏色格子的合體。
 數位影像(點陣圖)是由一堆方塊所組成，然後每一個方塊中都有一些顏色，這個每一個方塊我們就稱它為像素 (Pixel)。
然後通常我們說 1024 X 1024 的圖片就是代表這張圖，有 1024 X 1024 個像素。
對電腦來說，一張圖片就是包含了一塊顏色方塊的資訊，例如方塊位置、顏色、亮度等，這就是一張圖片在電腦中的基本組成。然後當然它和聲音一樣，都是有規則的二進位。
圖片來源: http://www.52im.net/thread-229-1-1.html
每一格像素的色彩顏色編碼 基本上可以分為以下兩類 RGB 與 YUV.
RGB 它就是由紅綠藍(Red、Green、Blue)三原色所組成顏色，然後每一種顏色咱們可以用 8 bit 來表示，也就是 255 種。
然後咱們常見的色彩類型說明如下：
 黑白：只有黑與白，所以只要 1 bit。 灰階：還是黑與白，但最黑到最白有 255 種的選擇，所以只要 8 bit，也就是 1 byte。 全彩：就是每個三原色都有 255 種選擇，然後有三原色，所以要 3 x 8 bit 等於 24 bit，也就是 3 byte。  圖片來源:網路</description>
    </item>
    
    <item>
      <title>30-03之聲音的編碼與壓縮</title>
      <link>https://mark-lin.com/posts/20180903/</link>
      <pubDate>Mon, 03 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180903/</guid>
      <description>圖片來源 : 馬克
正文開始 在上一篇文章中，在咱們理解了麥克風幫我們將聲音進行採集，並且透過 PCM 方法轉化成電腦看的懂的東東後，接下來咱們要來學習以下主題 :
 聲音的編碼與壓縮
 這篇文章中咱們會先說明一下編碼是什麼東西，然後接下來要理解編碼與壓縮的關係，最後咱們在來介紹一些現在在即時音頻通訊中比較常見的幾個編碼。
 什麼是聲音的編碼 ? 那為啥會有這麼多種編碼 ? 要如何將聲音所花費的空間變小呢 ? 各種聲音的編碼。  什麼是聲音的編碼 ?  一段用來描述聲音的有規則二進位
 上一篇文章中咱們有提到使用 PCM 來將聲音進行數位化，將聲音變成所為的二進位，也就是大概長的如下面這樣，這個 1 與 0 是有規則的，而正常來說這就咱們所謂的編碼。
10101010010101010100000000111111 …… 而最開始用 PCM 所產生出來的東西，咱們也稱為 PCM 編碼，順到一提它又被稱為無損編碼，但不是指它能完美無損的描敘真實聲音，而是無限接近真實的聲音。
那為啥會有這麼多種編碼 ?  因為用 PCM 所產生出來的 raw data 太大囉，所以某些神人就幹了一些壓縮編碼
 有點兒年紀的人們 ( ex. 馬克 ) 年輕時應該都有用過 MP3 這東東，它裡面裝的就是用 MP3 編碼後的音樂，然後現在常聽到的 AAC 和 Opus 也都是音頻編碼的東東，那為啥會怎麼多種編碼呢 ? 那是因為 raw data 太大了(如下範例)，不適合所有場景，像以前的 MP3 播放器空間小小的( 128 MB ?</description>
    </item>
    
    <item>
      <title>30-02之聲音的採集與原理</title>
      <link>https://mark-lin.com/posts/20180902/</link>
      <pubDate>Sun, 02 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180902/</guid>
      <description>圖片來源:馬克
正文開始 首先最一開始的文章，咱們要來討論聲音的採集這個主題，但是我覺得比較準備的說法是下面這種說明:
 要如何採集聲音到電腦中呢 ?
 要理解這個問題，咱們就需要從最源頭開始說起，什麼是聲音呢 ? 知道以後，咱們還要思考那電腦又是如何知道聲音是啥呢 ? 最後咱們會理一理當你採集了一段聲音，它需要花費多少的空間來儲放它呢 ?
本篇文章將分成以下三段如下:
 聲音是啥呢 ? 要如何將聲音採集到電腦裡，而且電腦也看的懂呢 ? ( PCM ) PCM 所採集到的聲音有多大呢 ?  聲音是啥呢 ?  它是一種震動所產生的聲波。
 聲波就是當一個人在說話時，它發出的聲音震動到空氣中，使得聲音周圍的空氣產生了變化，然後產生的一種波，這個就是所謂的聲波。
然後說到了振動，就該說到頻率，通常咱們用來描述它振動的多快的單位就是赫茲(Hz)它的定義如下:
赫茲(Hz)代表單位時間內周期性事件發生的事件
ex. 1Hz = 1/s (就是一秒動一次的意思)
咱們人耳可以聽到的範例約為 20 ~ 2萬赫茲，高於它的就被稱為超音波。
要如何將聲音採集到電腦裡，而且電腦也看的懂呢 ? ( PCM )  就是使用麥克風，然後將聲音轉成數位訊號，也就是 0 與 1。
 這裡我們就要提到一個叫PCM 脈波編碼調變的東東，它是一種將類比訊號數位化的方法。
類比訊號是啥 ? 它就是一種連續的訊號，像聲音與電壓都是屬於這類型，而數位訊號就是將連續的訊號進行加工，讓它只有 0 與 1 的非連續的訊息。
回來到 PCM 來看它的處理過程如下圖，總共有三個流程分別為抽樣、量化、編碼。
PCM 過程進行中，首先會先將聲音進行定期性的採樣，來看看當時的頻率是多少，那我們的採樣的頻率要多高呢 ? 像咱們人類能聽到的聲音最大為 20kHz(2萬赫茲)，也就是代表 1 秒振動 2 萬次，那這樣的話通常會進行 4 萬次的採樣(By 採樣定理)，才能確保有採集到人類可以聽到的聲音樣本數。而採樣率就會用 40kHz 來表達。</description>
    </item>
    
    <item>
      <title>30-01之開篇的心得感言</title>
      <link>https://mark-lin.com/posts/20180901/</link>
      <pubDate>Sat, 01 Sep 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180901/</guid>
      <description>前言 現今可以說是即時網路影音平台的戰國時代，17 直播、KKBOX、KKTV 、Youtube、 IG 等這些平台一個一個都推出了不少直播、影音串流內容提供(點播)，接下來這 30 天咱們將要從 0 到 1 的來研究要如何將聲音、影象或音樂傳送給遠在天邊的某位仁兄，並且也看看現今的直播或點播基本是如何建造而成的。
為什麼會寫這個主題呢 ? 事情的開端是降的。
忘了是啥時，咱公司的某些人在討論一下關於音視頻開發的東西，說了很多的專有名詞 ~ 例如 HLS、RTMP、AAC、H.264、MP4 啊，然後呢我就表現的像下面這張臉一樣。嗯嗯你們了的。
圖片來源:網路
然後我就開始研究這些名詞，一個一個慢慢研究，然後發覺奇怪怎麼都完全無法連成一條線呢 ? 例如 rtmp 我雖然知道它是做啥用的，但它的前身是啥，不知道，然後他傳輸時的有規定要用啥編碼嗎 ? 嗯不知清楚好像是 H.264 ，那 H.264 是語音還是視頻編碼呢? 嗯不知道……，那如果不能用 rtmp 要用啥? 嗯還是不知道……
圖片來源:網路
由於以上的種種慘況，所以我希望透過這三十天的文章，希望從 0 到 1 的完全理解即時音視頻開發的種種事情，並且希望可以讓想學習這塊領域的人，能更輕鬆的將這些專有名詞的知識連成一條直線，別謝我。 (BTW 這塊領域真的有點難連成線)
開端 這 30 天的主題是『30天之即時網路影音開發攻略(小白本)』，事實上我很想將他縮到成直播應用(ex. 如何在30天幹出一個 17 直播)就好，但是這樣很多東西會無法解釋，因為直接研究直播會發生缺了一些東西，因此將題目命名為此，但是這樣事實上還是有點兒抽象，所以一開咱們會從最基本的一個問題來進行探討，問題如下:
 馬克的俊臉與美聲要如何給遠在天邊的夢中人呢看到與聽到呢 ?
 下圖就是這問題的基本解圖，接下來的 30 天咱們就會根據這張圖的內容，來一步一步的理解裡面每個部份的內容，並且儘可能的將每編文章的知識都連灌起來，並且也順到理一理，現今咱們熱門的直播應用或是語音通話這些應用到底是如何建立起來的，然後最後在介紹 WebRTC 的相關資訊，這 30 天大概就降。
! 圖片來源:我做的
最後就開始吧 ~ BTW 這是我的第二次 ~ 好痛啊 </description>
    </item>
    
    <item>
      <title>一個基於 AWS Elasticsearch 的用戶行為 log 系統建立 ( 加強版 )</title>
      <link>https://mark-lin.com/posts/20180809/</link>
      <pubDate>Thu, 09 Aug 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180809/</guid>
      <description>在之前筆者的這篇文章中：
一個基於 AWS Elasticsearch 的用戶行為 log 系統建立
在們學習了如何使用　AWS 的相關工具來建立一個用戶行為的　LOG 分析系統。
但是這篇文章中所提到的架構有個問題。
這個版本有什麼問題呢　？ 那就是在某些情況下它會一直噴以下錯誤 :
ServiceUnavailableException: Slow down. 那為什麼會一直噴 Slow down 呢 ?
會發生這個的原因在於，我們有採到 aws firehose 的限制，如下： Amazon Kinesis Data Firehose 有以下限制。
如果将 Direct PUT 配置为数据源，每个 Kinesis Data Firehose 传输流 都会受以下限制的约束： * 对于 美国东部（弗吉尼亚北部）、美国西部（俄勒冈） 和 欧洲（爱尔兰）：5,000 条记录/秒；2,000 个事务/秒；5 MB/秒。 * 对于 欧洲 (巴黎)、亚太地区（孟买）、美国东部（俄亥俄州）、欧洲（法兰克福）、南美洲（圣保罗）、亚太区域（首尔）、欧洲 (伦敦)、亚太区域（东京）、美国西部（加利福尼亚北部）、亚太区域（新加坡）、亚太区域（悉尼） 和 加拿大 (中部)：1000 条记录/秒；1000 个事务/秒；1 MB/秒。 ! 注意 当 Kinesis Data Streams 配置为数据源时，此限制不适用，Kinesis Data Firehose 可无限扩展和缩小。 來源 : 官網</description>
    </item>
    
    <item>
      <title>Elasticearch 與 kibana 之日期的愛恨情仇</title>
      <link>https://mark-lin.com/posts/20180808/</link>
      <pubDate>Wed, 08 Aug 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180808/</guid>
      <description>我相信有使用過 Elasticsearch 的人都應該是會被他的日期時區的問題搞到很火。
在開始搞前先說說我的簡單需求:
 馬克大希望可以使用 ISO 標準來進行範圍搜尋，例如2017-07-16T19:20:30。
 這時通常時間的儲法會有兩種選擇:
 Timestamp ISO 標準  咱們先來看看 Timestamp 的儲法與查找 下面為範例程式碼(nodejs)，其中 putRecord 我就不寫了，因為只是範例，反正就是透過 aws kinesis 來將資料丟到 aws elasticsearch 上。
其中 test 為我們要丟到 elasticsearch 的資料，這裡我們要注意的 created_at 我們將會丟 timestamp 的進去。
const streamName = &#39;mark-stream&#39;; const test = { name: &#39;Mark III&#39;, age: 40, created_at: Date.now() // timestamp 1533634630945 , }; putRecord(streamName, test, (err, res) =&amp;gt; { console.log(err); }); Elasticsearch 查找 然後我們直接下來找找剛剛新增的那一筆。
curl 127.0.0.1/_search?pretty { &amp;quot;_index&amp;quot; : &amp;quot;api&amp;quot;, &amp;quot;_type&amp;quot; : &amp;quot;log&amp;quot;, &amp;quot;_id&amp;quot; : &amp;quot;2139103&amp;quot;, &amp;quot;_score&amp;quot; : 1.</description>
    </item>
    
    <item>
      <title>一個基於 AWS Elasticsearch 的用戶行為 log 系統建立</title>
      <link>https://mark-lin.com/posts/20180629/</link>
      <pubDate>Fri, 29 Jun 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180629/</guid>
      <description>本篇文章中，我們要說明的主題為 :
 如何使用 AWS Elasticsearch 來建立一個用戶行為 log 系統。
 本篇文章中，我們將分成以下的主題:
 Log 系統的架構說明 AWS 的工具申請 (Elasticsearch、Kinesis、S3) Log client 端的小實作  Log 系統的架構說明 V1 一個最簡單的 log 架構，應該會長的如下圖一樣，一個 log 來源與 log 接受端。
其中 log 接受端，有很多種選擇，你可以選擇來源端的本機，並且選擇將之儲放成文字檔，又或是儲放在某個資料庫中，各種儲放法都優有缺。
這裡我們選擇了使用Elasticsearch來當接受端，主要的理由如下:
 可以進行快速的搜尋 可擴展性強  但相對的與文本儲放相比，那缺點就是空間一定比文本的大，因為文本可以壓縮，不過文本的搜尋速度可就 QQ 囉。
V2 那 V1 有什麼缺點呢 ? 假設我們 Elasticsearch 上天堂，或是要停機更新一下，那這些 log 會著麼樣呢 ? 當然就是消了囉，雖然你可能會覺得 log 消失一些沒啥差別，但如果剛好是出問題的地方，那你真的會罵髒話了。
所以這裡我們會增加一個Broker，架構圖如下，所有的資料來源都會先送到Broker來後在送到儲放點。
這裡我們選擇了AWS kinesis，它的優點如下:
 擁有 Queue 的機制，也就是說如果資料儲放點上天堂在 24 小時以內，只要回復了，它會自動將這些 log 在丟過去。 AWS Kinesis 可處理任何數量的串流資料，不用擔心它爆掉就對了。 可以設定 log 同步也備份到 S3。  !</description>
    </item>
    
    <item>
      <title>如何使用 AWS Athena 去尋找 S3 的資料 (plus kinesis 丟到 S3 的坑)</title>
      <link>https://mark-lin.com/posts/20180704/</link>
      <pubDate>Fri, 29 Jun 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180704/</guid>
      <description>在筆者的一個基於 AWS Elasticsearch 的用戶行為 log 系統建立中，我們建立了一個使用者行為分析的 log 系統，文章中有提到，我們會將比較舊的 log 放置到 S3 中，所以本篇文章我們將要學習的主題為:
 如何時用 AWS Athena 來尋找 S3 中的資料
 另外本篇另一個外傳也要順到說一下，這外傳的主題為:
 使用 AWS Kinesis 丟 json 資料到 S3 ，你會總是只能 query 到一行資料 !
 接下來下面為本篇章節:
 AWS Athena 的簡單介紹 使用 AWS Athena 將 S3 的檔案建立成類似 SQL 的 Table 使用 AWS Athena 來進行 query (日期區間、指定欄位、大小數量) 坑 ! 使用 AWS Kinesis 丟 json 資料到 S3 ，你會總是只能 query 到一行資料 !  AWS Athena 的簡單介紹 簡單的白話文說一下 AWS Athena 是啥:</description>
    </item>
    
    <item>
      <title>要如何定期的清除 Elasticsearch 文件 ?</title>
      <link>https://mark-lin.com/posts/20180702/</link>
      <pubDate>Fri, 29 Jun 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180702/</guid>
      <description>上一篇文章『一個基於 AWS Elasticsearch 的用戶行為 log 系統建立』中我們說明了，如何使用 AWS Elasticsaerch 來建立收集 log 的系統，而 log 系統通常也有一種需求，那就是需要定期的清除舊的 log ，所以本篇文章的主題為:
 要如何定期的清除 Elasticsearch 文件 ?
 然後我們會分成以下幾個章節:
 最直覺式的定期刪除方法與缺點。 為什麼大量文件的清除對 Elasticsearch 會很耗資源呢 ? 大量文件清除方法 - 時間索引策略。  最直覺式的定期刪除方法與缺點 假設有以下的資料:
{ data: &#39;Hi Mark ~&#39;, created_at: &#39;20180101&#39; }, { data: &#39;HI Fuc u Mark&#39;, created_at: &#39;20180201&#39; } 那我們要清除 1 月份的 log ，那我們最直覺的做法，應該會如下的操作:
 搜尋所有 created_at 為 1 月的 doc。 再將所有搜尋出的 doc 給清除。   上面這方法在小量資料時，是沒問題的，問題是出在大量資料。
 那為什麼大量資料刪除會有問題呢 ?</description>
    </item>
    
    <item>
      <title>Elasticsearch 的 Document 建立原理</title>
      <link>https://mark-lin.com/posts/20180411/</link>
      <pubDate>Sun, 01 Apr 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180411/</guid>
      <description>在這一篇文章中，我們將要理解兩個問題 :
 在新增一個 document 時，會建立 json 實體與索引，那這兩個東東會存放到那兒去 ? 而在建立索引時，它又存放了什麼東東 ?  在開始前，我們先簡單的複習一下 Elasticsearch 的基本觀念。
Elasticsearch ( ES ) 的前提觀念概要 Elasticsearch 是一種分散的搜尋引擎，它也有和關聯式資料庫相似的結構，如下圖。
所以假設我們要新增一筆 document 應該是會長的像下面這樣。
 POST /markcorp/employee (/(index)/(type))
上面這行的語意就是新增一筆 document 到 markcorp (index) 的 employee 類別 (type)
 { id: 123 name: ‘Mark’, age: 18 } 然後當我們要去 ES 尋找這筆資料時，就可以使用它提供的 Restful API 來直接尋找:
 GET 127.0.0.1:9200/markcorp/employee/123
 在有了簡單的基本概念後接下來就可以來尋找我們這篇文章的問題。
新增一個 document 時資料會存放到那 ?? 像我們上面已經建立好了 document ，那實際上在 ES 中它是存放在那呢 ?? 雖然我們上面說它是對應到 RDBMS 的概念，但實際存放的地方不是存放在 markcorp 這個資料庫下的 employee 表下。</description>
    </item>
    
    <item>
      <title>Elasticserach 的操作新手村</title>
      <link>https://mark-lin.com/posts/20180401/</link>
      <pubDate>Sun, 01 Apr 2018 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20180401/</guid>
      <description>本篇文章中，我們將要很快速的學習以下幾個重點:
 elasticsearch 的基本觀念。 使用 docker 建立 elastisearch 服務。 新增 document。 取得 document。 修改 document。 搜尋 document。  elasticsearch 的基本觀念 Elasticserach 是一種分散式的搜尋引擎，它非常適合用來處理大量資料的搜尋與分析，像 github 就是拿他來搜尋它們所有的程式碼，而且它也提供了豐富的 restful api 來給我們進行操作。
Elasticserach 有這和關聯式資料庫相似的結構，如下圖。
所以假設我們要新增一筆在 markcorp 某一位員工的文檔會長的如下:
index: markcorp type: employee { id: 123 name: ‘Mark’, age: 18 } 然後當我們要去 ES 尋找這筆資料時，就可以使用它提供的 Restful API 來直接尋找:
 GET 127.0.0.1:9200/markcorp/employee/123
 使用 docker 建立 elastisearch 服務 接下來的教學可以直接用這個專案來直接執行:
git clone https://github.com/h091237557/docker-composer-tools.git cd elasticsearch/ docker-compose up 下面為官網所直接使用的docker compose的檔案。(官網傳送門)
version: &amp;#39;2.</description>
    </item>
    
    <item>
      <title>為什麼伊斯蘭教會分裂呢 ?</title>
      <link>https://mark-lin.com/posts/20171231/</link>
      <pubDate>Sun, 31 Dec 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20171231/</guid>
      <description>在現今伊斯蘭的世界中，我們常常會聽到遜尼派與什葉派這兩個派別，那這兩個派別有什麼不同嗎 ? 而且為什麼會又分這兩個派別呢 ? 這兩個派別又對現在的世界有什麼影響呢 ? 在這篇文章中，我們會來慢慢的理解這些事情。
伊斯蘭的起源 首先呢我們要將時間拉回到先知穆罕默德創立伊斯蘭教前的時代，在當時，先知還只是默默無名的路人甲，在西元 610 年時，它在麥加的某個山洞沉思，突然間他聽到大天使加百列的聲音，並且叫先知Iqra (誦讀)，而這時它讀出來的東西就是影響了人類世界的古蘭經。
然後先知聽到這聲音後，就把發生的這段事情告訴它的第一任妻子哈蒂嘉，她相信這個聲音是神的使者而非邪靈，也因為哈蒂嘉的這段話，穆罕默德就決定成立伊斯蘭教，並把古蘭經的教義宣楊到全世界。
在這裡我們要介紹另外兩位人士，這兩位都是改變伊斯蘭的人，或許也可以這樣說，因為這兩人，才使得伊斯蘭分裂成遜尼派與什葉派。
真主之獅 - 阿里 阿里最初的先知男追隨者，又被人稱為真主之獅，並且是真主的女婿，可以說是什葉派起源之人。
上面有提到先知決定成立伊斯蘭教時，先知首先做的事情就是先去將親朋好友聚集在一起，其中當然包含先知的堂弟阿里，它這時才 13 歲喔，然後先知說了以下這段話 :
 你們之中誰願意輔助我成就此業 ?
 想當然而，你和親朋好友說，你聽到神的聲音，要將這理念宣楊出去，你看看有誰會輔助你 ? 當然沒有人會支持，但唯獨阿里說了這段話 :
 他們所有人都退縮，而我雖然是這裡最年輕的，我眼晴看不清、肚子最肥大、雙腿最瘦弱，但我會說我，真主的先知，讓我成為您的助手。
 在這時後，伊斯蘭的最初三個信士就誕生了 : 穆罕默德、哈蒂嘉與阿里。
任何人都沒有想到，這個動作改變了全世界。
題外話，阿里他有一把劍，它比亞瑟王的『 Excalibur 』還有名，要不是亞瑟王的傳說太有名並且有很多小說或影集來宣傳，不然在基督教世界中，最有名的劍是阿里的配劍『 Dhu&#39;l Fikar 』中文為『分割者』，而也因為阿里手持這把神兵，奮勇殺敵無數的戰役，而贏得先智賜予『真主之獅』(Assad Allah)之名。
信士之母 - 阿伊夏 阿伊夏先知最年輕的一位妻子，這個人年輕、漂亮、又有才智，更是先知最寵愛的一位，但也是最有爭議的，她幾乎可以說是讓遜尼派產生的導火者。
在咱們現今的社會裡，對伊斯蘭女性的第一印象應該是壓迫，在伊斯國家裡，女性不能一個人 出門，並且出門時必須帶頭巾，伊斯蘭女性在婚姻、離婚以及繼承權等各個層面權利都低於男性。
但阿伊夏不同，她是公認的女權主義先行者，她是頂尖的伊斯蘭學者 又是負責發布伊斯蘭教令的法官，又是能在駱駝背上指揮戰場的指揮官，現今有很多為了伊斯蘭女性發聲的人，很多都會以阿伊夏來當做反駁的論點。
阿伊夏生平最有名的軼事就是項鍊事件，簡單的說阿伊夏和部隊走失了，結果有一名年輕男子恰巧路過，將她帶回麥地那，但回到城裏流言四起，那名年輕男子非常的俊美，阿伊夏則是活潑亮麗，不知道在那段時間，沒有沒發生啥迷不可告人之事 ?
先知那時也有懷疑，而且阿里也有桶一刀，但是最後結果就是先知或得啟示，就是古蘭經的下面這篇經文 :
當你們聽見謠言時候，信士和信女對自已的教胞，為何不作善意的猜想，並且說 『這是明顯的謠言呢?』 他們為何不找四個見證者來證明這件事呢 ? 他們沒有找來四個見證者，所以在真主看來他們是說謊的 二十四章: 十二至十三節 因為找不到四個人看到阿伊夏與那位年輕男子做些不好的事情，所以阿伊夏就降無罪 !
不過說來諷刺，阿伊夏為女權先行者，但也因為這段經文，導致不少穆斯林女性被強爆，而找不到四位見證者，因此施暴者被無罪釋放。
阿里與阿伊夏 阿里是先知的堂弟，也就代表這他和先知有相同的血源，而且他也將先知第一任妻子當成母親，那個時對阿里來說，阿伊夏就是另一位繼母的感覺，這或許也是阿里與阿伊夏相處不好的關係。
那阿伊夏呢 ? 他是先知最愛的最愛的妻子，但可惜的事，她沒有和先知生下孩子，在後宮的電視劇中也很常看出，沒兒子沒權力，這也是母憑子貴的成語由來。阿伊夏沒有孩子，所以他對擁有血源與兒子的阿里，自然而然的也就沒什麼好感。</description>
    </item>
    
    <item>
      <title>如何使用 Prometheus 來優雅的監控 Node Http Server 呢</title>
      <link>https://mark-lin.com/posts/20171001/</link>
      <pubDate>Sun, 01 Oct 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20171001/</guid>
      <description>本篇文章中我們將會學習到以下幾個重點
 什麼是 Prometheus 呢 ? 要如何監控 node http server 呢 ? 我想從 Prometheus 監控自訂的資訊，要如何做呢 ?  什麼是 Prometheus 呢 ? 在我們平常開發完系統時，我們常常會有個需求，那就是要如何監控我們的系統呢 ? 以確保它 cpu 往上衝時，我們會知道呢。
當然我們可以很簡單的寫個小程式，定期的去呼叫系統取他的 cpu，這是很淺的東東 ~ 那如果是還要一個 api 的請求次數呢 ? 或是平均的某個 api 的請求次數或圖表呢 ? 這時如果還要自幹一個，那就太麻煩囉，所以這時我們就可以使用Prometheus ~
Prometheus 官網上面寫了下面這段話 :
 Power your metrics and alerting with a leading open-source monitoring solution.
 這句話就是 Prometheus 存在的目的。
Prometheus 的架構 太細節的不說囉 ~ 這裡大概列出這個架構的三個重點:
 Prometheus 是用 pull 去取得目標資訊，下面的 pull metrics 就是這個意思，而這裡你只先去記一點，如果你有個 http server ，然後你要用 Prometheus 去監控 server ，那 Prometheus 就會去 xxxx_host/metrics 取得資訊。 PromQL 是 Prometheus 所提供的查詢語言，利用它可以快速的找到我們想要的資訊 (大概)。 AlertManager 是一個警告系統，你只要配置好 Prometheus 在某個東東到了報警線時，就自動發送警告到 AlertManager 然後它會使用某些方法通知你，例如 email or slack。  安裝 Prometheus 請直接到官網直接下載下來。</description>
    </item>
    
    <item>
      <title>Socket.io 原始碼分析之建立連線</title>
      <link>https://mark-lin.com/posts/20170915/</link>
      <pubDate>Fri, 15 Sep 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170915/</guid>
      <description>首先我們先來看看最一開始時，要建立連線會那些事情，假設我們的 server 已經開啟 :
var io = require(&amp;#39;socket.io&amp;#39;).listen(8080); io.sockets.on(&amp;#39;connection&amp;#39;, function (socket) { console.log(&amp;#34;Hello xxxx client&amp;#34;); }); 接下來我們要從前端開始追蹤它做了那些事情。
Client 端它做了什麼呢 ?? Socket.io-client 建立連線的地方 在最開始時，一定是前端會去進行連線，那我們來看看他在socket.io-client中什麼地方行處理。
前端與 server 端連結的程式碼如下，從下面程式碼可知，我們執行io(&#39;xxxx&#39;)時，他就會去後端建立連線。
&amp;lt;script src=&amp;#34;/socket.io/socket.io.js&amp;#34;&amp;gt;&amp;lt;/script&amp;gt; &amp;lt;script&amp;gt; var socket = io(&amp;#39;http://localhost&amp;#39;); socket.on(&amp;#39;connect&amp;#39;, function(){}); &amp;lt;/script&amp;gt; 然後我們來看看 socket.io-client 的這段程式碼長啥樣子，如下，但下面程式碼我們只要先注意newConnection裡面做的事情，因為我們是要建立新的連線。
lookup 原始碼
function lookup (uri, opts) { .... if (newConnection) { debug(&amp;#39;ignoring socket cache for %s&amp;#39;, source); io = Manager(source, opts); } else { if (!cache[id]) { debug(&amp;#39;new io instance for %s&amp;#39;, source); cache[id] = Manager(source, opts); } io = cache[id]; } if (parsed.</description>
    </item>
    
    <item>
      <title>Socket.io 的說話島</title>
      <link>https://mark-lin.com/posts/20170914/</link>
      <pubDate>Thu, 14 Sep 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170914/</guid>
      <description>socket io 是 nodejs 所提供的套件，它主要可以做的事情就是推播功能。
你想想，假設你要做個股票報價網站，然後當你後端收到新的股價時，你要如何的送到前端 ? 在傳統的 server 與 client 架構下，因為只能由 client 向 server 發出請求，而不能由 server 發送新的訊息到 client，所以當時的人們的解決方案就是輪詢，固名思意就是指定時的去 server 找資料。
但這種方案有缺點，你想想，你有可能去 server 抓 10 次資料，它有可能 10 次都有新的資料嗎 ? 不一定對吧 ? 所以最理想的方案一定是從 server 端有新資料就自動推送到 client 端。
websocket就是一個由 html 5 所發布的新協議，它就可以做到上面所需要的功能。
那socket.io是啥 ? 它是會根據你的 client 所支援的功能(websocket、comet、長輪詢…)來決定你後端要如何的發送資料，更白話文的說，你不用管你的 client 有沒有支援 websocket，socket.io 一切都自動會處理好，你只要和我說啥時要送資訊到前端就對了。
Socket.io 的組成 請參考筆者的這篇文章。
Socketio 的架構
簡單 client 與 server 的溝通範例 server 端程式碼如下，這段程式碼當與 client 端建立一條 websocket 連線後，會直接對該條連線傳送個{hello: &amp;quot;world&amp;quot;}訊息。
var io = require(&amp;#39;socket.io&amp;#39;).listen(8080); io.</description>
    </item>
    
    <item>
      <title>Socket.io 的架構</title>
      <link>https://mark-lin.com/posts/20170913/</link>
      <pubDate>Wed, 13 Sep 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170913/</guid>
      <description>socket.io 是 node js 的一個 framework，它可以幫助我們建立聊天室這種推播功能的系統，這篇文章我們不會說明它如何使用，而是要理解 socket.io 這個套件的架構組成。
socket.io 主要由以下幾個東東構成的 :
 engine.io、engino.io-client socket.io-parser socket.io-adapter socket.io-client socket.io-protocol  接下來我們將一個一個說明它們是做啥用的，並且最後會在進行一個總結。
engine.io engine.io是一個實際執行 socket.io 通訊層級的 libary，嚴格說起來，socket.io 的核心就是engine.io，所有的建立連線、傳輸資訊實際上都是由它來做，並且根據前端傳送回來的資訊，來決定使用什麼傳輸方式。
目前 engine.io 所提供的溝通方式有以下幾種 :
 polling-jsonp polling-xhr pollin websocket  上面有提到，socket.io 本身不提供連線功能，而是在 engine.io 才提供，所以事實上，如果你沒有一定要使用到 socket.io 的功能，而只是要連線到 http server 或是監聽 port 的話，只要用 engine.io 就夠了，這邊有個重點要記得 socket.io 是個 framework 而 engine.io 只是個 libary，只要分的出這兩個差別，你就可以自由的選你要的使用。
var engine = require(&amp;#39;engine.io&amp;#39;); var server = engine.listen(80); server.on(&amp;#39;connection&amp;#39;, function(socket){ socket.send(&amp;#39;utf 8 string&amp;#39;); socket.send(new Buffer([0, 1, 2, 3, 4, 5])); // binary data }); engino.</description>
    </item>
    
    <item>
      <title>聊天『室』的設計 ~ 安安你好，要打龍嗎? ~</title>
      <link>https://mark-lin.com/posts/20170912/</link>
      <pubDate>Tue, 12 Sep 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170912/</guid>
      <description>在上一篇文章中，我們說明了如何的設計像 line 的聊天群的架構設計，而這一篇我們要來說明聊天室的架構設計，這東西和上一篇有什麼差別 ?
通常聊天群是會由用戶提出申請，然後管理者來加入到該群裡，而聊天室則不相同，它是用戶可以自由自在的加入或退出，這也代表這，通常聊天群會限制人數，像 line 好像就限制 500 人，而聊天室則否，他通常不會限制人數。
那這也代表我們要面對什麼問題呢 ? 我目前想想主要有兩個 :
 由於沒有限制人數，所以通常我們的架構要考慮擴展性。 訊息的即時性非常的要求，如果一個訊息傳輸慢了，會導致其它人無法理解上下文。  最簡單的聊天室架構 V-1 基本上和聊天群的架構相同，都是一個Business Server和一個Message Server，其中前者做的事情是為所有需要使用 http 協議的工作，更正確的說是 http 短連接的工作，如新增聊天室、登入、登出、註冊這類事情的，都屬於 Business Server ，而所有使用 websocket 協議的都是屬於 Message Server 的工作。
聊天室 V-2 上面的架構有沒有啥問題呢 ? 有的 ! 請想像一個情境 :
 用戶 A 從 business server 登入後，然後再去 message server 建立連線，但問題是 message server 怎麼知道這條連線是用戶 A 呢 ?
 在一般的 web 應用中，每當 client 連結 server 時，server 會產生唯一個 sessionId ，並用它來連結 server 內的存放空間，然後會將 sessionId 存放到 cookie 中，這樣每一次 client 進行請求時，server 都會去 cookie 中取得 sessionId 然後再去 session 取得資料。</description>
    </item>
    
    <item>
      <title>一個像 Line 的聊天群設計 ~ 安安你好 ~</title>
      <link>https://mark-lin.com/posts/20170911/</link>
      <pubDate>Mon, 11 Sep 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170911/</guid>
      <description>本篇文章中，我們講要說明，如何開發一個簡單的聊天群系統，這個東東雖然我們很常見到，到和我們平常開發的一些 WEB 有很大的差別。
差別在那呢 ? 假設我們開一個todolist功能，事實上大部份的工作就是crud的事情，每當要新增一個 todo 時，只要發送 http 到後端新增資料到資料庫裡去，然後在回傳結果就好了，但聊天群這種，如果你每發送一個訊息都使用 http 那一定爆掉的。
像聊天群這樣類型的，我們稱為InstantMessaging IM中文為即時通訊，本篇文章我們將會說明要建立這種IM應用所需要的基本知識。
開始吧 ~
從 Web 到 IM 的通信過程轉變 在最開始時瀏覽器它沒有辦法直接連接到另一個瀏覽器的通信功能，也就是說你不能從 A client 直接傳送訊息到 B client 去，我們只能在它們的中間，建立一個 server ，來將 A 要傳送的訊息儲放起來，然後 B 在自已去 server 取得資料，如下圖 :
這種做不行嗎 ? 說實話，功能是有做出來 ~ 但浪費太多的資源，你想想，根據上面的說法，當 A 發送訊息到 server 後，你 B 要如何知道 server 有你的訊息 ? 記好 http 只能從client發送到server，不能反之，所以這也代表這你 B 只能定時的去 server 問問看，說有沒有我的資料啊 ~
很明顯的，你可能問了十次，只有一次才有你要的訊息，那其它九次，不就都浪費掉了，這也代表你的 IM 系統有 90 % 的效能在處理沒用的事情。
當然中間處理的其它方法先不說，後來 html5 提出了一個應用層的協議websocket，來解決這事兒 ~
Hello WebSocket 這個協議可以幫助我們可以實現，從 server 端推送資料到 client 端，而且從建立的通道是持久連接，在 http 1.</description>
    </item>
    
    <item>
      <title>Socket 的哩哩扣扣</title>
      <link>https://mark-lin.com/posts/20170910/</link>
      <pubDate>Sun, 10 Sep 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170910/</guid>
      <description>在前面的幾篇有說到，不同的 process 間可以使用 IPC 通信來進行溝通，但如果是不同電腦呢 ? 要如何溝通呢 ? 我們這時就可以使用 socket 來進行溝通。
在開始說明 socket 前，我們需要先準備一些基本知識，那就是常聽到的 tcp/ip。
TCP/IP 通訊模型 tcp/ip 它是一種網路協定，它定義了點對點如何的傳輸，如何將資料封裝、定址、傳輸、路由以及在目的地如何接受，全部都加以標準化，它基本上可以分為四層應用層、傳輸層、網路互連層與網路介面層，它常被視為簡化的七層 OSI 模型。
圖片來源:鳥哥
在了解 socket 前，我們需要了解應用層與傳輸層的基本概念。
應用層 這個層級主要是定義 :
 應用程式的溝通協定，也可以理解為不同應用程式如何協同工作。
 在這個層級的協定，大部份都會使用到兩個傳輸協定tcp與udp，至於何時使用 tcp 或 udp 取決於，該協定是否保證資料完整的傳送到另一端，這邊我們只要記得tcp可靠而udp不可靠這兩件事情就夠了。
我們常用的 http 就是屬於這一層協定，smtp 也屬於這層，我們簡單的來說明一下 http 的概念。
HTTP (超文字傳輸協定) 它是一種應用層的傳輸協定，它主要定義了下面的事情 :
 它是一個用戶端與伺服器端請求和應答的標準
 通常 http 用戶端的發出一個請求，它會建立一個到伺服器端的 TCP 連線 。
傳輸層 這個層級主要是定義 :
 定義點到點如何傳輸
 其中tcp、udp就是這一層，我們簡單的來說明一下 tcp 的工作，就會知道這個層級主要是做啥事情。
TCP (傳輸控制協定) 它是根據傳輸層的定義，所完成的協定，這個協定宗旨在於 :
 提供一個可靠(不會掉資料)的資料流傳送服務</description>
    </item>
    
    <item>
      <title>Node設計模式之命令模式 ( Command )</title>
      <link>https://mark-lin.com/posts/20170611/</link>
      <pubDate>Sun, 11 Jun 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170611/</guid>
      <description>本文中我們將會知道兩件事件
為什麼要使用命令模式呢 ? 什麼是命令模式呢? 為什麼要使用命令模式呢 ? 我們先來想想，假設我們要做一個簡單的計算機的功能，然後他有提供以下方法:
 加 減 乘 除  然後實際上執行大概會長這樣 :
add(5) =&amp;gt; current = 5 sub(3) =&amp;gt; current = 2 mul(3) =&amp;gt; current = 6 div(3) =&amp;gt; current = 2 這樣我們大概會寫個最簡單的程式碼，大概會長成下面這樣:
class Calculator { constructor(){ this.current = 0; } add(value){ this.current += value; } sub(value){ this.current -= value; } mul(value){ this.current *= value; } div(value){ this.current /= value; } getCurrent(){ return this.current; } } const client = new Calculator(); client.</description>
    </item>
    
    <item>
      <title>Node設計模式之策略模式 ( Stratgey )</title>
      <link>https://mark-lin.com/posts/20170610/</link>
      <pubDate>Sat, 10 Jun 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170610/</guid>
      <description>本篇文章中，我們想要知道以下兩件事情 :
  為什麼要使用它呢 ? 什麼是策略模式呢 ?   為什麼要使用策略模式呢 ? 我們簡單的寫一下，一個多需要用不同方法的登入方法，它可以選擇使用google、facebook的方法，來進行登入。
var user = { login: function (type) { if (type == &amp;#34;google&amp;#34;) { doGoogleLoginSomething(); console.log(&amp;#34;google login process&amp;#34;); } else if (type == &amp;#34;facebook&amp;#34;) { doFbLoginSomething(); console.log(&amp;#34;facebook login process&amp;#34;); } else { doSomething(); console.log(&amp;#34;custom login process&amp;#34;); } } } user.login(&amp;#34;google&amp;#34;); 那上面這段程式碼中，有那些缺點呢 ?
首先第一個，它包含了很多的 if else 判斷，這樣反而增加了該函數的邏輯分支。
第二個為該函數缺泛彈性，如果你想增加twitter的登入，那就必須修改這函數的內部實作，這樣違反了開放封閉原則
 開放封閉原則 : 白話文就是當你增加新功能時，盡量不修改原有的程式碼。
好處 : 較好維護、較好測試、可重複使用
 所以說，當碰到這種情況時，就可以使用策略模式囉 ~
策略模式簡單的來說，就是為了處理以下的情況 :</description>
    </item>
    
    <item>
      <title>Node之可擴展性 --- 訊息佇列 Message queue (RabbitMQ)</title>
      <link>https://mark-lin.com/posts/20170607/</link>
      <pubDate>Wed, 07 Jun 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170607/</guid>
      <description>在前幾篇文章中，我們說明了如何將系統進行擴展，而接下來呢，我們將要說明如何使用訊息佇列來進行整合，事實上之前的每篇文章中都要提到一個名稱IPC通信，其中裡面就包含了訊息佇列 (message queue)。
訊息佇列基本上是用來行程間溝通或是同行程內不同執行序溝通，他提供了異步的溝通協定，這個意思就是指當你傳送一堆訊息給 A 時，A 可以不用即時的來處理這些訊息，這也代表這訊息可堆積再處理，白話文就是 :
 訊息接受者如果爆了，我訊息發送者還是可以一直發送訊息，等你好了，你還是可以取得完整的訊息。
 我們可以想想http協定他是一個同步協定，這也代表你傳送一個request必須等待伺服器發送response。
至於我們為什麼要用message queue請參考下面這篇文章，他真的已經寫的很完整了。
使用訊息佇列的十個理由&amp;mdash;簡中
然後我們先簡單的說明一下訊息系統的基礎。
訊息系統架構 基本上分為以下兩種 :
對等式 (peer-to-peer) 在對等式的架構下，每一個節點都直接將訊息傳送給接受者，這種方法基本上會比較複雜，因為他還要決定各自結點的的通訊協定，但還是有一些優點 :
 避免單點故障。 和中介者模式比較來少了中間一層，速度應該是比較快。 彈性較高。  以下為對等式架構的圖示 :
 zeroMQ 他可以幫助我們建立對等式架構。
 中介者模式 (message broker) 而中介者模式就是所有的節點，都會連結到某個broker，一切都由broke來處理，每個節點不需要知道，我和誰溝通，只需要知道要傳送的訊息內容即可。但缺點就是上面對等式的優點。
以下為中介者架構的圖示 :
 RabbitMQ 就是專門用來建立這個架構的東東。
 接下來的文章中，我們將要先來實作一些rabbitmq。
Rabbit MQ 在上面的章節中，我們應該有說到，分佈式架構除了對等式架構外，還有一個是中介者架構，中介者的主要作用就是讓訊息接受者與傳送者之間完全的解偶，而rabbitmq就是一個支援AMQP (Advanced Message Queuing Protocol)協議的中間介者。
如下圖所示，它就是中間綠綠那個，我們稱他為中介者 broker。
那AMQP是什麼 ? 它是一種協議，AMQP 是一個提供統一訊息服務的應用層標準協議(osi第七層)，也就是設定於其它應用軟體之間的通訊，像 http、https、ftp 等都是應用層協議。
根據該協議，客戶端與訊息中間件(broker)可傳送訊息，不受客戶端/中間件不同產品，不同開發語言的條件限制。
它有三個總要概念 佇列 (queue) : 這東東它是儲存訊息的架構，然後裡面的訊息它會被客戶端拿走。一個佇列可能會推多個客戶端取走訊息，這時處理的方式和我們之前說的負載平衡差不多。
佇列它還有以下三種特性 :
 可延續性 : 意即若 broker 重新啟動時，則佇列也自動重新建立。那裡面的訊息著麼辦呢 ?</description>
    </item>
    
    <item>
      <title>Node之可擴展性 --- 訊息佇列 Message queue (ZeroMQ)</title>
      <link>https://mark-lin.com/posts/20170608/</link>
      <pubDate>Wed, 07 Jun 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170608/</guid>
      <description>上一章節中我們有提到rabbitmq，它是用來建立中介式架構的broker，但這種架構有什麼問題呢 ? 那就是分散式架構的頭號公敵單點失效(single point of failure)。
所以後來就有人提出使用對等式架構來解決這個問題，這個架構就是會將broker給移除掉，每一個用戶端同時也是伺服器端，像比特幣這種應用就是用該結構來處理。
但相對的，它也有缺點，那就是要建置起來較為複雜，用在大規模的網路上，管理較難、安全性較低。
使用 ZEROMQ 進行對等式架構 (peer-to-peer)實作 zeromq它是一套網路通訊函式庫，記得他不是一個伺服器，而是一個lib，它在socket api之上做了一層封裝，將網路、通訊、進程等抽象化為統一的 API 接口，它和 socket 的區別是 :
 socket : 點對對的關係(一對一) zeromq : 多點對多點的關係(多對多)  那 zeromq 有什麼特點呢 ? 它有以下四個特點 :
 去中心化 (無 broker) 強調訊息收發模式 以統一的接口支持多種底層通信方式 異步 速度飛快 (請參考這篇比較)  不過有一點要注意一下，zeromq 它不是一個獨立的伺服器進程 (rabbitmq 是)，所以嚴格來說它不是 mq ，它沒有 mq 這種在中間解耦合的能力，事實上他的名命也說了 zero mq 。
zeromq 主要提供三種類型的通訊模式分別如下 :
REQ (request) / REP (reply) 模式 這模式就是傳統的一個 reuest 配一個 response 的模式，非常的簡單。
下面這段程式碼是發送請求(request)的程式碼。
var zmq = require(&amp;#39;zeromq&amp;#39;); var requester = zmq.</description>
    </item>
    
    <item>
      <title>Passport.js 之 Hello 你好嗎 ~ </title>
      <link>https://mark-lin.com/posts/20170609/</link>
      <pubDate>Wed, 07 Jun 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170609/</guid>
      <description>本篇文章中，我們想要知道以下的重點 :
  passport 是啥鬼 ? 要如何使用它呢 ? 要如何使用一個 passport 的登入系統呢 ?   passport 是啥 ? passport.js是 node 中的一段登入驗證中間層(middleware)，也就是說可以讓你簡單的使用 google 登入或使用 fb 登入，它的架構就是所謂的策略模式，接下來我們來實際上看看他是如何使用的。
 passort.js 活著的目的就是為了驗證 request
 要使用 passport 來進行驗證，需要設定三個東西 :
 驗證策略 (Authentication strategies) 應用程式的中間件 (Application middleware) Sessions (可選擇)  驗證策略的建立 上面我們有提到 passport 本身就是使用策略模式的實作，而它的定義就是 :
 定義一系列的演算法，把它們一個個封裝起來，並且可以相互替換。
 所以在這邊，我們需要定義驗證的策略(演算法)，例如使用 facebook 登入驗證、google 登入驗證或自訂的驗證策略。
而我們這裡直接看官網的自訂驗證策略localStrategy，下面的程式碼中，我們會定義一個localStrategy，它準備用來驗證我們的request。
而LocalStrategy的兩個參數為options和verify，我們option需要先定義要用來驗證的欄位username、passowrd，然後verify就是驗證規則，就是下面那個function裡面的東東。
var users = { zack: { username: &amp;#39;zack&amp;#39;, password: &amp;#39;1234&amp;#39;, id: 1, }, node: { username: &amp;#39;node&amp;#39;, password: &amp;#39;5678&amp;#39;, id: 2, }, } // LacalStrategy(options,verify) var localStrategy = new LocalStrategy({ usernameField: &amp;#39;username&amp;#39;, passwordField: &amp;#39;password&amp;#39;, }, function (username, password, done) { user = users[username]; if (user == null) { return done(null, false, { message: &amp;#39;Invalid user&amp;#39; }); }; if (user.</description>
    </item>
    
    <item>
      <title>Node之可擴展性 --- Nginx反向代理建立</title>
      <link>https://mark-lin.com/posts/20170606/</link>
      <pubDate>Tue, 06 Jun 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170606/</guid>
      <description>在上一篇文章中，我們使用cluster來建立多process的應用，這個方法是我們上一篇所提到X軸擴展的複制的方法之一。
而這一篇文章，我們一樣是要來討論X軸擴展的複制的另一種方法 :
 反向代理器
 這種擴展的方法為，在不同的 port 或不同的機器上，我們會啟動多個應用程式，然後使用反向代理器來存取這些機器，用來分散流量。
他不會像 cluster 上有一個master process然後將工作分配給多個worker，而是有更多個獨立的程式執行在同一個機器不同 port上或是分散在相同的網路中的不同機器上，然後會以反向代理器為入口，由他處理請求並與後端的伺服器做處理，然後在由他回傳給客戶端。
下圖為該結構的圖示 :
那他這樣做有什麼優點呢 ? 事實上他就是 proxy 的用法，也就是說 :
 他可以保護伺服器
 反向代理器可以和我們上一章所說的cluster一起使用，例如單一機器使用 cluster 進行垂直擴展，再使用反向代理器來做水平性擴展。
本篇文章中我們將使用最常用來做反向代理器的Nginx 。
Nginx 做反向代理器，並配置負載平衡 nginx是一個網頁伺服器，它的設計架構和 nodejs 非常的相似，都是單一執行緒架構，並且還有豐富的模組庫和第三方工具可以使用，非常的方便啊。
這邊我們將要使用nginx來作為反向代理器，並且進行負載平衡的功能，它要做的工作就是 :
 我們有多台伺服器，然後請求進來要將請求分給其它台伺服器。
 首先我們先安裝 nginx
// ubuntu apt-get install nginx // mac brew install nginx 然後我們簡單的建立一個 server，它每一次收到請求時，都會回傳這個工作是那個port來進行處理。
// app.js  const http = require(&amp;#39;http&amp;#39;); http.createServer(function (req, res) { console.log(&amp;#34;master:&amp;#34; + process.pid); res.writeHead(200); res.write(&amp;#34;port:&amp;#34; + this.</description>
    </item>
    
    <item>
      <title>Node之可擴展性 --- Node的Cluster</title>
      <link>https://mark-lin.com/posts/20170605/</link>
      <pubDate>Mon, 05 Jun 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170605/</guid>
      <description>本篇文章中將要說明，要如何的擴展 node 應用，從上一篇文章中我們知道， node 它很適合高 I/O 的任務，而不適合高 cpu 的任務，最主要的原因在於它的架構，它是單執行緒架構，但是無論單體的伺服器能力在強大，單一執行緒的效能一定會有界限，因此我們必須將應用程式擴展運用。
根據The Art of Scalabiltiy的內容來知道，在擴展時，可以用下列三個維度來描述可擴展性。這也是被稱為擴展立方(scale cube)的東東。
 X 軸 : 複制 Y 軸 : 以服務/功能分解 Z 軸 : 以資料來分解  基本上Y軸擴展的方法是屬於微服務(Microservices)的範圍所以本篇也不詳細說明，而Z 軸則屬於資料庫方法所以也不加以說明。
我們本篇將要說明X軸 : 複制，它的白話文概念如下 :
 將應用程式加以複制 N 個，這也代表每個實體只須處理 N 分之一的工作量。
 傳統的系統可以利用多執行緒，來完整使用整台機器的效能，但 node 則否，因為它是單一執行緒，並且在 64 位元下有1.7GB的限制，接下來我們將介紹 node 擴展的基本機制 cluster。
cluster cluster是在 node 中的內建模組，他讓我們可以建立一個 cluster，可通過父進程來管理一堆子進程，在 cluster 中父進程被稱為master process，而子進程則被稱為worker process。
每個傳送的連線都會先到master process然後會在將工作分配到worker process中。
我們根據上一篇的程式碼來進行修改。下面程式碼中，首先請先看if(cluster.isMaster)裡面，當執行時，會使用cluster fork根據 cpu 的數量來新增 process，然後每次fork時都會執行else裡面的程式。
const http = require(&amp;#39;http&amp;#39;); const child_process = require(&amp;#39;child_process&amp;#39;); const cluster = require(&amp;#39;cluster&amp;#39;); const numCPUs = require(&amp;#39;os&amp;#39;).</description>
    </item>
    
    <item>
      <title>Node之CPU吃重的任務要如何處理 ? </title>
      <link>https://mark-lin.com/posts/20170604/</link>
      <pubDate>Sun, 04 Jun 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170604/</guid>
      <description>這篇文章中，我們希望學習到 :
 在開發nodejs時，如果遇到cpu密集型的任務時，要如何處理 ?
 首先我們先來複習一下nodejs的機制一下。
我們都知道nodejs是屬於單一執行序架構，在其它的語言裡，每當有一個請求進來時，它們都會產生一個執行緒，但nodejs則否，他是用一個執行緒就來處理所有的請求，而他的背後就是有個事件機制設計才能做到這種方法。請參考這篇。
 但為什麼要設計成用單一執行序架構呢?
 這邊我們要先來說說I/O操作。
I/O 問題 I/O就是電腦中資料與記憶體、硬碟或網路的輸入和輸出，他基本上是電腦作業裡最慢的事物，I/O操作基本上對 cpu 而言通常負擔很小，但是問題就在於它很耗時。
傳統的阻塞I/O設計方式如下 :
data = getData(); print(data); 我們假設getData是要去讀取一個檔案，而這時會等到getData執行完後，就資料傳送給data時我們才可以使用。
那假設我們這個getData要讀很久，那這樣的話其它的請求著麼辦 ?
傳統的作法就會像下面這張圖一樣，系統會分別的開啟不同的執行緒來進行處理，如此一來，當有某個執行緒因I/O操作而阻塞時，就不會影響到其它的請求。
這種作法的缺點就在於 :
 開啟執行緒的成本不低，它會消耗記憶體而且引發環境切換
 那node他著麼處理呢 ?
他使用單一執行緒機制，而他的執行緒中有一個機制被稱為事件機制，簡單的說事件機制可以將所有的請求收集起來，並且將需要長時間處理的工作丟出去工作給其它人做(I/O)，然後繼續接收新的請求，就如同下圖一樣，這樣的優點就在於，他可以接受更多的請求，，而不會因為一個長時間的I/O，其它東西就都卡住不能動。
但他也是有缺點的 :
 它無法充分利用多核 cpu 資源
 當 Event loop 遇到 CPU 密集型任務會發生什麼事 ? 上面有提到單一執行緒機制有一個缺點，那就是無法統分利用cpu資源，這是什麼意思呢 ?
傳統的方式，每個請求分配一個執行緒，他都可以得到一個不同於自已的 cpu，在這種情況下多執行緒可以大大的提高資源使用效率。
而這也代表的單執行緒他就只能占用一個 cpu ，並且如果某個任務是很吃 cpu 的工作時，這執行緒就會被那個任務占用，導致其它的任務、請求都無法執行。
我們下面簡單的寫一段程式碼來看看會發生什麼事情。
下面這段程式碼裡，我們將簡單的建立一個server，它一收到請求，就會開始計算費波南西數列，這種運算基本上就是一個很耗 CPU 的工作。
const http = require(&amp;#39;http&amp;#39;); http.createServer(function (req, res) { console.</description>
    </item>
    
    <item>
      <title>Node 設計模式之代理器 ( Proxy )</title>
      <link>https://mark-lin.com/posts/20170603/</link>
      <pubDate>Sat, 03 Jun 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170603/</guid>
      <description>本篇文章中我們將要解決以下的問答。
  什麼是代理器模式 ? 我們為什麼要使用它 ?   其中本篇文章還會介紹ES6所提供的Proxy使用方法。
什麼是代理器模式呢 ? 首先我們先來看一張下面這張圖，這張圖基本就說明了代理器模式的概念，無論如何，client和Real Object之間一定會由Proxy來進行溝通。
我們還可以用下面這句非常白話文的文字來表達代理器模式的精華。
 我的時間很忙的，除非真的要用到我，不然請直接找我的代理人。
 我們簡單來寫個範例來說明一下，代理器的實際上使用，首先我們先寫一個登入的程式。
Class UserService{ construct () { } GetUser(name,password){ ...... return user; } } 然後通常我們要使用的時後會執行下面程式碼。
const userService = new UserService(); const user = userService.GetUser(&amp;#34;mark&amp;#34;,&amp;#34;123456789&amp;#34;); 這樣看起來是沒什麼問題，東西是都還可以執行，然後我們來改寫成代理器的模式，我們會先建立一個UserServiceProxy，我們外面要使用UserService時，都只能透過這個Proxy進行溝通 (想找明星，只能想找他的代理人)。
 注意 : 這只是其中一種寫法，代理器還有很多的方法可實現。
 Class UserServiceProxy { construct(real){ this.Real = real; } GetUser(name,passowrd){ const real = new Real(); real.getUser(name,password); } } const userServiceProxy = new UserServiceProxy(UserService); const user = userServiceProxy.</description>
    </item>
    
    <item>
      <title>Node.js 的串流之旅之雙工串流與管道</title>
      <link>https://mark-lin.com/posts/20170602/</link>
      <pubDate>Fri, 02 Jun 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170602/</guid>
      <description>在node js 中雙工串流主要有以下兩種，這兩種直接用白話文來講就是同時有read與write的功能。
 Tranform Stream Duplex Stream  那這兩者有什麼差別呢，差別在於duplex的寫出與讀入可以完全的沒關係，你可以把他想像成兩個獨立的readable與writable的組成。
而tranform就是寫出與讀入彼此間的資料存在有轉換關係，我們接下來會直接實作程式碼，更能夠看出它們兩個的差異。
最後我們還會說到pipe，它的功用就是用來接串流組合起來。
Tranform Stream 我們這邊會簡單做個替換指定字串的Transform串流，其中這個類別，我們需要實作兩個方法_transform與_flust。
_transform基本上與readable的_read很像，是將資料寫入水缸中，而不是直接將它寫到資源內，而我們在這個方法中實作了將指定字串連行替換。
_flush是在串流要結束時，如果還有事實沒有處理，這時就可以在_flush進行處理，像我們這個範例中，想要在最後加個!!!!!時，就是寫在這裡。
基本上只要前一篇文章中的readable與writable基本概念都了解，那這些雙工串流你會學的很輕鬆的。
const stream = require(&amp;#39;stream&amp;#39;); class TransofrmStream extends stream.Transform{ constructor(search_string, replace_string){ super({decodeStrings:false}); this.search_string=search_string; this.replace_string = replace_string; } _transform(chunk, encoding, cb){ const result = chunk.toString().replace(this.search_string,this.replace_string); this.push(result); cb(); } _flush(cb){ this.push(&amp;#39;!!!!&amp;#39;) cb(); } } const transofm_stream = new TransofrmStream(&amp;#39;World&amp;#39;, &amp;#39;Mark&amp;#39;); transofm_stream.on(&amp;#39;data&amp;#39;, (chunk) =&amp;gt; { console.log(chunk.toString()); }) transofm_stream.write(&amp;#39;Hello World&amp;#39;); transofm_stream.write(&amp;#39;Mark ! you are my all World&amp;#39;); transofm_stream.</description>
    </item>
    
    <item>
      <title>Node.js 的串流之旅之基本概念</title>
      <link>https://mark-lin.com/posts/20170601/</link>
      <pubDate>Thu, 01 Jun 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170601/</guid>
      <description>串流是啥，事實上這個東東，我們每天都有使用，簡單的說，它是一種傳送內容的技術，在沒有使用串流技術時，我們想要在網路上看影片，需要將它下載下來才能播放，但如果使用串流技術那傳送影片，它會將一小短小短的資料，一直傳送給網頁，所以我們可以直接進行觀看，並且在觀看時它還會繼續傳送後面的片段過來。
串流的優點 在node js中，傳送內容基本上有分兩種形式，一種是緩衝而另一種就是串流，我們先來看看緩衝在處理資料傳送時，它是如何處理。
緩衝它的基本概念就是將所有的資料先收集到緩衝區裡，當資料已經完整的讀取完，在傳送給接受者，如下圖所示，它會將HELLO MARK這所有的資料先讀取完，然後才能傳送給接受者。
然後我們來看看串流，它每個時間點一接受到資料就會直接發送給接受者，所以如下圖所示，在時間點t1時，它會接受到HELLO這串資料，然後在t2時會接受到剩下的MARK資料。
那這樣有什麼好處呢 ? 簡單的說有兩個優點，一個是空間效率，因為如果使用緩衝的方法來進行個10gb以上的資料傳輸，就代表這你需要10gb的緩衝空間，那這樣記憶體一定爆掉。而第二個優點就是時間效率，就如同最上面的影片例子來說明，使用串流，你可以直接看影片，然後再看影片時，它還會繼續傳送剩下的影片片段，節省了等待時間。
緩衝與串流的程式碼實做比較 我們簡單寫一個檔案下載的伺服器，然後分別以緩衝與串流的程式碼，來進行實作，在nodejs中，有個 module 名為fs，它是專門用來處理檔案傳輸的工具，它也同時繼承了node 中的串流模組stream。
緩衝讀取檔案實作 這是一個下載aaa.avi檔案的伺服器，但假設該檔案大小如果大於1024mb(舊版本node)的話，它會直接死掉，因為它緩衝爆掉了。
基本上這種類形的api被稱為Bulk I/O。
const http = require(&amp;#39;http&amp;#39;); const fs = require(&amp;#39;fs&amp;#39;); const server = http.createServer((req, res) =&amp;gt; { fs.readFile(&amp;#39;aaa.avi&amp;#39;, (err, data) =&amp;gt; { if(err) { console.log(err); res.writeHead(500); res.end(err.message); } else{ res.writeHead(200, { &amp;#39;Content-Type&amp;#39;: &amp;#39;video/avi&amp;#39; }); res.end(data); } }); }); server.listen(3000, () =&amp;gt; { console.log(&amp;#39;server up !&amp;#39;); }); 串流讀取檔案實作 下列程式碼就是使用串流來實作的讀取檔案伺服器，這樣如果檔案大小在大，它都可以進行處理，因為它是將大檔案分割成小塊小塊，然後一直傳輸。
const http = require(&amp;#39;http&amp;#39;); const fs = require(&amp;#39;fs&amp;#39;); const server = http.</description>
    </item>
    
    <item>
      <title>排序之桶子排序法(Bucket Sort)</title>
      <link>https://mark-lin.com/posts/20170427/</link>
      <pubDate>Thu, 27 Apr 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170427/</guid>
      <description>比較排序法與非比較排序法 桶子排序法原理 桶子排序法使用時機 桶子排序法複雜度 javascript 演算法實作  比較排序法與非比較排序法 前面幾篇我們學的排序演算法都被歸類為比較排序法，而另一種歸類為非比較排序法，桶子排序法Bucket Sort就是屬於該歸類。
我們這邊簡單的說一下比較排序法與非比較排序法的差別，首先比較排序法是透過資料兩兩比較進行排序，而且它在效能上有根本的限制，在最差的情況下，任何一種比較排序法至少需要O(nlogn)比較操作。
網上有個簡單的證明，就設我們有3個資料要進行排序，1,4,5，那們它有幾種排序組合 ?
答案是 3! = 3 * 2 * 1 = 6，六種排序法，也就是說它六較次數至少為 Log(N!) = O ( N log N )。
而非比較排序法就沒有效能上的限制，通過非比較操作能在``O(n)`完成，但它缺少了靈活性，比較排序法能對各種數據型態進行排序，而非比較排序則不能，這種靈活性也導致了比較排序被更多的應用在大多數實際工作中。
像在Mozilla的javascript的sort預設是Merge Sort，而WebKit則是Selection Sort，都是選用比較排序法。
桶子排序法原理 桶子排序法，它的原理是將陣列，分散到有限數量的桶子中，然後每個桶子再個別進行排序，其中每個桶子的個別排序可以運用其它的演算法來進行排序。
桶子排序法有三個特點
 桶子排序法是穩定的。 它是常見的排序法中最快的一種，大多數的情況下。 它非常快，但缺點是非常的耗空間。   上面有說到穩定，但穩定是什麼意思呢?例子，假設我們有個數列為3,5,19,3*,10，其中3*只是為了識別它和前面的3是不一樣的。
穩定排序結果 =&amp;gt; 1,3,3*,5,10,19
不穩定排序結果 =&amp;gt; 1,3*,3,5,10,19
從上面結果可知穩定的它的順序會與原資料一樣3在3*前面，而不穩定則會有不同結果。
 桶子排序法基本的流程如下。
 建立桶子群。 將資料丟到對應的桶子裡。 個別桶子進行排序。 然後在依順序取出結果。  我們來看看下面的圖片說明，假設我們要排序的資料如下。
[ 7 , 5 , 9 , 2 , 10 , 1 , 8 ]</description>
    </item>
    
    <item>
      <title>排序之合併排序法(Merge Sort)</title>
      <link>https://mark-lin.com/posts/20170426/</link>
      <pubDate>Wed, 26 Apr 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170426/</guid>
      <description>合併排序法的原理 合併排序法的速度效能 合併排序法的空間效能 javascript 演算法實作  合併排序法原理 合併排序法，它也是與上一篇提到的快速排序法一樣，使用分治法的概念，也就是將問題拆分為子問題，各別解決後，再將結果進行合併。
大部份的排序演算法中，都不太需要額外(大量)的儲存空間，而合併排序法，會需要使用到空間，但相對的它在時間複雜度的表現，比其它幾個演算法優質些。
合併排序法實作的概念基本上有分為兩個，Top Down與Bottom Up
首先請看下圖，它是Top Down的概念，它會先將資料拆分開來，然後再進行組合、排序，直到資料全部排序完成。
然後我們在看下圖，它為Bottom Up的概感，將資料以最小單位2為限制，拆分，然後進行排序，再組合成下一個單位4，再進行排序，以此類推，直到排序完成。
合併排序法的速度效能 平均 O(nlogn)
最好 O(n)
最壞 O(nlogn)
合併排序法的空間效能 O(n)
javascript演算法實作  注意，基本上只有在拆分時作法不一樣，但在merge時，這邊都是呼叫它一個方法。
 Top Down實作 debugger; /** * mergeSort_TopDown * @param datas * @returns {undefined} */ function mergeSort_TopDown(datas) { if (datas.length &amp;gt; 1) { var len = datas.length; var mid = Math.floor(len / 2); var right = []; var left = []; //將datas陣列分兩左子陣列與右子陣列  for (var i = 0; i &amp;lt; len; i++) { if (i &amp;lt; mid) { left.</description>
    </item>
    
    <item>
      <title>排序之快速排序法(Quick Sort)</title>
      <link>https://mark-lin.com/posts/20170425/</link>
      <pubDate>Tue, 25 Apr 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170425/</guid>
      <description>快速排序法的原理 快速排序法的速度效能 快速排序法的空間效能 基準點的選擇 javascript 演算法實作  快速排序法的原理 快速排序法，又稱為分割排序法(partioion exchange sort)，是一種最快的排序法之一，它使用分治法的概念，將問題拆分成兩個獨立的問題來進行解決，再將兩個結果合成原問題的答案，這就是說所謂的分治法(傳送門)。
快速排序的過程有四個步驟。
 注意以下皆以由小排到大的流程來進行說明。
 假設我們總共要排序的資料有n個，D1,D2,D3,...,Dn。
 選定一個基準值(privot)，並假設為D。 由左至右尋找 i=2,3,4,..,n，一直到Di &amp;gt; D。 由右至左尋找 j=n,n-1,n-2,...，一直到Dj &amp;lt; D。 當i&amp;lt;j時，Di與Dj互換，而當i&amp;gt;j時D與Dj互換。  範例 我們下面來看看這個範例。
假設我們的基準值設為最左邊的值，也就是陣列的初始值。
 基準值的選擇後面會說明
 而我們要排序的陣列如下。
[ 39 , 15 , 37 , 89 , 45 , 20 , 32 , 51 ]
然後我們開始進行快速排序法，首先我們選定的基準值為39。
[ 39 , 15 , 37 , 89 , 45 , 20 , 32 , 51 ]</description>
    </item>
    
    <item>
      <title>排序之堆積排序法(Heap Sort)</title>
      <link>https://mark-lin.com/posts/20170424/</link>
      <pubDate>Mon, 24 Apr 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170424/</guid>
      <description>本篇文章分成以下幾個章節 :
 堆積樹(Heap tree)。 堆積排序法的原理。 堆積排序法的執行效能。 javascript 演算法實作。  堆積樹 Heap Tree 再說明堆積排序排序前，我們需要先知道一個東西，那就是Heap Tree，它是二元樹(不知道的可以看筆者的這篇文章，不過我們在這篇中還是會簡單的複習)的一種， 那二元樹是啥 ? 就是長的和下圖一樣的東西，而二元樹有兩個比較嚴謹的定義如下。
 1 . 每個節點最多有兩個子節點 2 . 子節點有左右之分
 而其中，我們在這邊需要用的是完全二元樹Complete Binary Tree，它就是Heap Tree，它除了上面的定義外，還有第三個定義。
 3 . 除了最後一階層之外的階層，都必預完全有左與右節點
 它的樣子如下圖。
最大堆積 Max Heap 在了解完Heap Tree後，我們就要來知道，Max Heap是啥，它也是種堆積樹一種，不過它有個條件。
 1 . 父節點的值大於子節點 2 . 樹根(root)一定是所有節點的最大值
 根據以上的條件畫出的圖，大概如下。
我們這邊來看看下面幾張Max Heap產生過程的圖解。
首先我們會先將陣列轉換成Heap Tree。
然後我們會從最後的父節點，開始進行Max Heap判斷，然後再往前遞回。我們會先從09該節點進行判斷，由於09小於16，因此進行互換，結果如下圖。
接下來，我們在往回前一個父節點，11來進行判斷，因為該父節點值都大於子節點02與10因此不需要進行互換。結果如下圖。
最後再來判斷root，也就是最後一個父節點08，它下面兩個子節點11與16都比它大，因此，它選擇最大值16進行交換，然後08再於09進行比較，再進行交換，結果如下。
最後產生出的Max Heap結果如下。
堆積排序法的原理 在了解完上面的預備知識後，我們就可以開始了解堆積排序法的做法囉，它的流程如下。
前置作業
 將陣列轉換成Heap Tree。 在將Heap Tree轉換成Max Heap  重複作業</description>
    </item>
    
    <item>
      <title>排序之選擇排序法(Selection Sort)</title>
      <link>https://mark-lin.com/posts/20170423/</link>
      <pubDate>Sun, 23 Apr 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170423/</guid>
      <description>選擇排序法的原理 插入排序法的執行效能 javascript演算法實作  選擇排序法的原理 選擇排序法，它基本的觀念為 :
 將資料分成已排序與未排序，然後在未排序的資料中尋找最小(大)值，並將它移置已排序資料的右邊。
 我們以下圖來簡單的進行說明。注意，下列的 A[0] 代表陣列的第一個位置。
 第一行 : 已排序資料為空，然後尋找未排序資料中最小值8，並將它移至已排序資料的右邊，也就是A[0]，結果如第二行。 第二行 : 已排序資料為8，尋找未排序資料中最小值23，並將它移至已排序資料的尾端A[1]，結果如第三行。 以此類推，最後可得到從小到大的排序資料。  圖片來源
插入排序法的執行效能 那這個排序演算法效能如何 ? 我們會分成最好與最壞與平均來看。
最好、最壞、平均狀況 O(n^2)
對都是一樣的，就算是排序好的，也是O(n^2)的時間複雜度，我們來看個例子。
[1,2,3,4,5] 我們有上面的陣列，它需要進行排序，我們知道它排序好了，但演算法不知，所以還是要跑。
 第一行 : 已排序資料為空，然後尋找未排序資料最小值，因為演算法不知道最小值是啥，所以還是要從頭找到尾，然後找出1，並將它放到A[0]位置。 然後接下來，每一行還是要從未排序資料中，從頭掃到尾來尋找資料，不管你有沒有排序好。  建議使用情況 根據Wiki的說法，嗯……。
 原地操作幾乎是選擇排序的唯一優點，當空間複雜度要求較高時，可以考慮選擇排序；實際適用的場合非常罕見。
 javascript演算法實作 我們來看看它的演算法，我們採用javascript來進行撰寫。
/** * selectionSort * Selection Sort Algorithmic * @param arr * @returns {Array} , Thie return&amp;#39;s array has been Sorted. */ function selectionSort(arr){ var len = arr.</description>
    </item>
    
    <item>
      <title>排序之插入排序法 ( Insertion Sort )</title>
      <link>https://mark-lin.com/posts/20170422/</link>
      <pubDate>Sat, 22 Apr 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170422/</guid>
      <description>插入排序法是我們第一個學習到的排序方法，我們本篇會針對它來詳細的介紹一下。
 插入排序法的原理 插入排序法的執行效能 javascript演算法實作  插入排序法的原理 我們先來看看下圖，來理論一下它是著麼進行排序，該圖來源為此interactivepython。
首先，我們會將資料分成兩部份，已排序與未排序，然後我們會進行以下作業
 將已排序資料與後一個資料進行比較，如果已排序資料大於它，則進行位移
 我們下面將以前四行來進行說明。注意，下列的 A[0] 代表陣列的第一個位置。
 第一行 : 已排序資料為54，然後我們與後一個26進行比較，54大於26因此我們會將26的位置替換成54，並將26插入至54的原位，結果為第二行。 第二行 : 已排序資料為26、54，然後我們與後一個93進行比較，54小於93因此不用進行位移，因為26、54為已排序資料，因此只需要比較54就好，結果為第三行。 第三行 : 已排序資料為26、54、93，然後與17進行比較，首先93大於17因此將93位移置A[3]，則時還沒插入喔，還要繼續比較，接下來54大於17因此將54位移至A[2]，然後26大於17，因此將26位移至A[1]，最後在將17插入剩餘的空間A[0]，結果為第四行。 第四行 : 已排序資料為17、26、54、93，開始與77進行比較，93大於77因此將93位移至A[4]的位置，然後54小於77，因此54不需要位移，最後將77插入至空缺的位置A[3]，當果為第五行。  插入排序法的執行效能 那這個排序演算法效能如何 ? 我們會分成最好與最壞與平均來看。
最好狀況 O(n)
該演算法最好的情況是時間複雜度為O(n)，假設我們有下列陣列要排序。
[ 1 , 2 , 3 , 4 ] 我們一看就知道，他不用進行排序，但演算法還不知道，所以它至少還是要跑個for迴圈，跑個4次，才知道它不用排序，因為我們這時最好的狀況就是只要跑4次，也就是陣列的大小。
最壞狀況 O(n^2)
假設我們要下列陣列要排序。
[ 4 , 3 , 2 , 1 ] 對就是完全相反的，我們首先要跑for迴圈，然後裡面還要一個while比較，而且因為我們的陣列是完全相反的。
平均狀況 O(n^2)
我也不知道為啥平均是O(n^2)，真的。
建議使用情況  要排序的資料數量不大 : 平均是時間複雜度是O(n^2)，如果來個1百萬個 n，你看看會如何。 大部份的資料已排序 : 上面有說過，該演算法會將資料分成已排序與未排序的來進行比較，也就是說如果已排序的資料越多，你就可以少做越少的比較。  javascript演算法實作 我們來看看它的演算法，我們採用javascript來進行撰寫。</description>
    </item>
    
    <item>
      <title>搜尋之二元搜尋法 Binary search</title>
      <link>https://mark-lin.com/posts/20170421/</link>
      <pubDate>Fri, 21 Apr 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170421/</guid>
      <description>基本上如果我們要在陣列中搜尋一個元素，最簡單的方法就是跑個迴圈一個一個跑，它有個專有名詞叫線性搜尋，這在未排序的資料中，效果還算可以，但是如果在已排序的資料中，要來進行搜尋，就不太有效率了，本篇文章說明的二元搜尋法就是用來搜尋已排序的資料集。
 二元搜尋法原理 程式碼實作(資料結構:陣列) 程式碼實作(二元搜尋樹實作)  二元搜尋法原理 它的基本搜尋概念，是將資料切兩半，然後比較搜尋目標在這兩半的左邊還右邊，如果在左邊，則將左邊的資料再切兩半，以此類推，至到尋找到目標。
我們簡單的用下圖來說明，假設我們有個陣列，資料 1 至 9，並且已經排序，然後我們要搜尋2，首先我們會先比較目標值( 2 )與中位數( 5 )，由於 5 大於 2 ，所以我們接下來只將搜尋左邊 1 至 4 的資料，然後我們再將目標值( 2 )與中位數( 3 )進行比較，由於 3 大於 2 ，因此再來也只搜尋左邊的 1 至 2 的資料，將目標值( 2 )與中位數( 2 )比較，相等，尋找到目標值。
接下來我們簡單的使用js來實現二分搜尋法。
效能 最佳時間複雜度 : O (1) 平均時間複雜度 : O (log n) 最差時間複雜度 : O (log n) 空間複雜度 : O (1) 程式碼實作(資料結構:陣列) function binarySearch(datas, low, heigh, target) { let mid = Math.</description>
    </item>
    
    <item>
      <title>演算法策略---動態規畫法</title>
      <link>https://mark-lin.com/posts/20170325/</link>
      <pubDate>Sat, 25 Mar 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170325/</guid>
      <description>動態規劃法 Dynamic programming ; DP，它與分治法很像，都是將大問題分割成小問題，而它和分治法不同的地方在於，它會將處理過的子問題解答，將它記憶起來，為了避免重複的計算。
費波那西數列 最簡單說明動態規畫法的問題就是費波那西數列，它的定義如下。
 F0 = 0
F1 = 1
Fn = Fn-1 + Fn-2
 也就是說F2所代表的意思為F2 = F1 + F0，也就等於F2 = 1 + 0。
我們直接來看程式碼，首先先看沒有用cache的費波那西數列。非常的簡單就只用遞迴來計算每個數列的值。
function fib (n){ if(n&amp;lt;=1){ return n; } return fib(n-1)+fib(n-2); } 我們這邊使用個例子，來說明它的計算流程，我們執行fib(5)，然後我們直接看下面這張圖來了解它的過程，首先是項點fib(5)，它就是由fib(4)、fib(3)組成，然後再將之分解，就會如下圖的結果。其中我們有用綠色底來上色的地方，它就代表我們有重複的數字，像fib(2)就被計算了3次，所以上面這個演算法事實上做了很多重複的事情。
而接下來，我們就將它改良一下，也就是用動態規畫法的概念下修改而成，它每次計算過一個數字後，就會先存起來，然後有需要時，就在將它拿出來。
程式碼如下，它會將每個有計算過的數列儲放在記憶體內，有用到它時，就將它拿出來用。 下面就是簡單的使用動態規畫法概念實作的費波南西數列。
//有用Cache var memo = []; var count = 0; var fib_cache = function(n){ if(n &amp;lt;=1){ return n; } if( typeof memo[n] !== &amp;#39;undefined&amp;#39;){ return memo[n]; }else{ memo[n] = fib_cache(n-1) + fib_cache(n-2); return memo[n]; } } 背包問題（Knapsack Problem） 這個問題的定義如下。</description>
    </item>
    
    <item>
      <title>演算法策略---分治法</title>
      <link>https://mark-lin.com/posts/20170324/</link>
      <pubDate>Fri, 24 Mar 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170324/</guid>
      <description>在解決一個問題時，有一種很常見的方法，那就是將這個問題，分成很多個小問題，然後將所以小問題全部解決，最後可以合成一個解答。這種將問題分割變小，再將小變回大的方法，在計算機科學中成為分治法。
分治法適用的情況 但並不是所有問題都適合分治法，有以下特性的問題才可以使用。
 問題的規模可小到一定的程式就可以容易解決。 問題可以分解為若干個規模較小的相同問題，該問題有最優子結構性質，最優子結構的意思就是局部最優解能決定全局最優解。(同貪心法) 可使用這個問題分解出的子問題的解，合併成該問題的解。 這個問題的子問題都是獨立的。  分治法的方法 要用分治法來解決一個問題，通常會有以下的步驟。
 分解 : 將大問題分解成小問題。 解決 : 將每個小問題解決。 合併 : 將每個子問題的解合併為原問題的解。  分治法基本上的手段是『遞迴』，也就是自已呼叫自已的意思。
實作練習 以下的問題都出自於培養與鍛鍊程式設計的邏輯腦這個本書裡或leetcode中找到的，但我們這邊的都會使用JS來進行實作。
最大子序列問題 ( Maximum Subarray ) 最大子序列是個經典的問題，它的問題定義如下。
 在一個包含正負值的陣列中，尋找一段連續的元素總合『最大』的區間。
 例如假設我們有陣列[1,5,-8,7,4,1,-9,6]，所以這時我們的最大子序列就為7、4、1。
這邊的解法基本概念如下圖，它會將陣列分成兩塊，並且最大子區塊有可能會落在左邊區塊、中間跨陣列區塊、右邊區塊，而每個區塊又可以在繼續切分成三塊，這樣就可以使用遞回取出，每塊最大子區間，最後再將結果組合起來就ok囉。以下是程式碼。maxCrossover是用來尋找中間那塊的最大子區塊值。
function maxSubarrary(datas, start, end) { if (start == end) { return datas[start]; } else { let middle = Math.floor((start+end)/2); console.log(&amp;#34;startM:&amp;#34; + start + &amp;#34; middleM:&amp;#34;+middle + &amp;#34; end :&amp;#34; + end); return Math.max(maxSubarrary(datas,start,middle),maxSubarrary(datas,middle+1,end),maxCrossover(datas,start,middle,end));	} } function maxCrossover(datas,start,middle,end){ var currentLeftSum =0; var leftSum = 0; var currentRightSum =0; var rightSum=0; for (var i=middle+1;i&amp;lt;=end;i++){ currentRightSum += datas[i]; if(currentRightSum &amp;gt; rightSum){ rightSum = currentRightSum; } } for (var k=middle;k&amp;gt;=start;k--){ currentLeftSum += datas[k]; if(currentLeftSum &amp;gt; leftSum){ leftSum = currentLeftSum; } } let test = rightSum+leftSum; console.</description>
    </item>
    
    <item>
      <title>演算法之策略---貪心法</title>
      <link>https://mark-lin.com/posts/20170323/</link>
      <pubDate>Thu, 23 Mar 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170323/</guid>
      <description>通常當我們遇到一個演算法的問題時，通常都有一些策略可以使用，本篇文章中我們將會說明貪心法這種策略。
 基本概念 實作問題  基本概念 貪心法在解決問題時，基本上它只會根據當前最好的資料，就做出選擇，如果以心理學的忍耐實驗來說明 ; 這個實驗會給一堆小孩 1 塊巧克力，然後和小孩說，如果 15 分鐘後沒有吃掉這巧克力，那你就會有 3 塊巧克力，而貪心演算法它就只會考慮當下最佳解，也就是說它會吃掉巧克力。
簡單用一句話說明貪心法的要義那就是
 只選擇『當時最佳的選擇』
 但是對於一個問題時，我們要著麼知道它是否可用貪心法來解決，以及是否得到問題的最佳解 ? 針對第一個問題『我們著麼知道是否可用貪心法』，我們可以看看問題的性質，如果一個問題，我們可以簡單的猜測，這問題是一個簡單的計算方法，並且答案正確，那這種類型的問題就適合它 ; 那第二個問題『 是否得到最佳解 』，這就不一定了，我們很難判斷我們用貪心法得出的答案是否是最佳解。
那貪心法適合什麼樣的問題呢 ? 這和上面的問題是不同的喔 ? 上面是問可用，這邊是問適合。貪心法在最優子結構的問題中特別有用，最優子結構的意思就是局部最優解能決定全局最優解。
根據wiki，我們可以將使用貪心法的過程分解成以下幾個部份。
 建立數學模型來描述問題。 把求解的問題分成若干個子問題。 對每一個子問題求解，得到子問題的局部最優解。 把子問題的解，合成原來解問題的一個解。  實作練習 以下的問題都出自於培養與鍛鍊程式設計的邏輯腦這個本書裡，但我們這邊的都會使用JS來進行實作。
硬幣問題  一元、五元、十元、五十元、一百元、五百元硬幣。我們想要儘可能少的硬幣支付 A 元。到底需要幾枚硬幣呢 ? 假設這種付款方式至少會存在一種。
 這個問題基本上是貪心法的基本問題，而且也是日常常見的問題。這個問題的重點是『盡可能少的硬幣』，所以很自然的我們直覺會想盡量多付五百，再來是一百，然後已此類推，就可以得到最小的硬幣數量。
程式碼如下，非常的簡單。
var coins = [1,5,10,50,100,500]; var pay = 2430; function greedSol(coins,pay){ var result = {}; for (var i=coins.length-1;i&amp;gt;=0;i--){ var coinNum = Math.</description>
    </item>
    
    <item>
      <title>鄂圖曼帝國掰掰後，中東變成什麼樣 ? </title>
      <link>https://mark-lin.com/posts/20170318/</link>
      <pubDate>Sat, 18 Mar 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170318/</guid>
      <description>鄂圖曼帝國是一個曾經強到在歐、亞、非都有領士的伊斯蘭帝國(1299~1922)，在世紀帝國二中，有一個國家上到城堡時代就可以建立土耳其火槍兵的國家就是它，它在那個時代，以武器來說幾乎可以說是屌打其它周邊國家，這也是為什麼他可以建立如此強大的帝國。
圖片來源: 世紀帝國2征服者入侵 - 土耳其Turkey
但是呢，它到了十九世紀時，就開始慢慢的沒落，至於沒落的原因，本篇文章就不做太多的說明，因為不是這篇的重點，不過我們還是簡單的說一下，就是啊，在二十世紀初，發生了人類史上最大規模的戰爭第一次世界大戰，最後因為它押錯寶，然後鄂圖曼帝國就說掰掰囉 ~ 不過事實它那時本來就很爛了。
掰掰後的發展 首先我們先來看看鄂圖曼帝國在快掰掰時的領土，是錄色的那邊喔。
圖片來源: [烏賊哥的部落格](http://yixiang8780.com/ https://sg2plcpnl0195.prod.sin2.secureserver.net:2083/cpsess3888291770/frontend/gl_paper_lantern/filemanager/index.html?dirselect=ftproot&amp;amp;domainselect=yixiang8780.com&amp;amp;dir=%2Fhome%2Fh091237557%2Fpublic_ftp)
接下來我們在來看看我們現在的地圖。
圖片來源: google map
我可以發現蹦出來了以下幾個國家(先說好不是直接產生的)土耳其、沙烏地阿拉伯、敘利亞、伊拉克、約旦、黎巴嫩、以色列、伊朗，一個帝國爆掉後，為什麼可以跑出著麼多國家，這就是我們這篇文章想要知道的東西。
一戰後的分割 首先我們先來說說鄂圖曼帝國在打完一戰後，它發生啥事情。
他身為一個戰敗國，很理所當然的襖要求簽一些鬼條約，而這個鬼條約就是所謂的色佛爾條約，它的其本內容，主要為削掉帝國的領土與國力，目的就是防止它再發動戰爭，白話文就是我要你的土地。下圖為根據條約瓜分後的慘況。
圖片來源: 維基
土耳其的誕生 （凱末爾） 想當然會有人民當然不爽，然後在土耳其地區，就有一位被後來土耳其人稱為英雄的凱末爾仁兄，就率領一堆人對這項條約表示不爽並否決他，然後更狂的是，他直接與這些佔領國的人打了起來，然後還打贏了，不過也並不是全部用槍來打，主要的原因在於這幾個國家在土耳其的利益並不一致，所以互扯後腿也是常發生的事，然後凱末爾就開始進行挑撥離間這種被稱為來陰的的招式，最後結果就是土耳其建國。而這過程被稱為土耳其獨立戰爭。
土耳其建國後，我們來說說他的統治，我們都知道土耳其在當時主要的宗教為伊斯蘭教，在過去的中亞國家中，大部份都是執行所謂的政教合一，也就是政治領袖同時也是宗教領袖，而且事實上也可以這樣說，伊斯蘭教就是這個國家，不論是仲裁、規定都是根據伊斯蘭的規則。
而凱末爾他做了什麼事呢? 他打破了伊斯蘭教在土耳其的定位，他決定政教分離，將伊斯蘭教從土耳其這個國家分離出來，他做了那些事情呢 ?
 讓女性進入到公共領域。 禁止頭巾和面紗。 一夫多妻是違法的。 公休日從星期五改為星期日  以上這些事情在我們的國家都覺得是應該的，但從尊循古法可蘭經的人，這可是天大的事情，用句中國用語就是目無王法，古蘭經的教導都跑去那了?
不過也因為有以上這些改革我們才能看到現在的土耳其，雖然有人會說他是獨裁者，但也因為他當時是獨裁者才能強制的改變土耳其。而土耳其也成為了伊斯蘭世界中，第一個在這伊斯蘭世界中執行世俗主義的代表，對了說一下，我這個說法是從西方觀點來看，但如果是站在伊斯蘭人的角度我就不知道囉。
伊拉克與約旦的誕生 (哈希姆家族) 在說到這兩個國家誕生前，咱們要先來說說伊斯蘭世界的某個大家族哈希姆家族，這個家族一直以來在伊斯蘭世界裡赫赫有名，因為先知穆罕莫德也屬於這個血脈，而這個家族後來最主要的傳脈者為法蒂瑪也就是先知的女兒，這也使得這個家族上千年來都屬於伊斯蘭世界的望族，你要說是天龍人好像也行。
時間拉回到一次世界大戰時，戰還在打，前線打的你來我往，想當然兒後方當然也要有一些動作，英國這時想要偷插鄂圖曼帝國一刀，所以英國就和一位哈希姆家族的人海珊。本。阿里達成協議，英國答應幫助他從現今地圖中的敘利亞到伊朗的土地上，建立一個統一的阿拉伯國家，然後他要幫英國插刀在他的老東家鄂圖曼帝國上。他答應了，然後他在老東家的土地上建立了漢志王國。
但英國人匡他了，因為英國早以和法國私立下說好，敘利亞地區分給法國，而其它的伊拉克、外約旦、巴勒斯坦都為英國的，英國知道哈希姆家族在伊斯蘭世界的影響力，不敢匡他全部，所以就打個折，分給他的兒子成為漢志國王的繼承人，另一個兒子成為外約旦的國王，第三個兒子成了伊拉克國王。
這時地圖上就多了伊拉克、外約旦、漢志，然後外約旦大約在1946年時就獨立成約旦了，而漢志他的地理位置就是現今的沙烏地阿拉伯，但他在1925年就說掰掰了 ~
沙烏地阿拉伯的誕生 (沙特家族) 上面有提到一個叫漢志王國的地方，但他在1925年時就說掰掰了 ~ 被誰幹掉呢 ? 伊本。沙特。
說到這位大哥，又要來說明一個，一直以來都統治被稱為內志地區的家族沙特家族，這個家族和哈希姆家族不同，並沒有高貴的伊斯蘭血統，哈姆姆家族認為他們只是游牧部落首領，不想和他們平起平坐，而這個家族最大的特點就是他們信奉瓦哈卜主義，這個主義主要的主張如下 :
 回到古蘭經去，恢復先知穆罕默德時代的正道。
 沙特家族與哈希姆家族這對世仇，從西方人的看法，他們比較喜歡哈希姆家族，因為他們代表者伊斯蘭教開明與世俗的一面，而相對的沙特家族的瓦哈卜主義代表回歸傳統和歷史，強調對教義的嚴格尊守，這也是為什麼英國人在找和作對象時，會傾向找哈希姆家族。
伊本。沙特注意到，如果乖乖看這英國人分配的話，那自已不就被哈希姆家族給包圍，那還得了，所以他決定進攻漢志，然後就把漢志給說掰掰了，最後他就建立了我們現今的沙烏地阿拉伯。
敘利亞與黎巴嫩的誕生 上面也有說到，一戰過後，敘利亞這個地方一直被法國人統治，然後直到1944年時才從法國手中獨立，而黎巴嫩他也是被法國人統治，直到1943年才宣佈獨立。
以色列誕生與巴勒斯坦的不爽 (同一個土地的戰爭) 在第一次世界大戰結束後，巴勒斯坦這個地區被割給英國，他當時的地圖如下，有沒有覺得很眼熟? 對，就是現在的以色列，這兩個國家的關係真的只能說，煩 !
要說明為啥巴勒斯坦這塊土地會慢慢的變成以色列真的可以在寫個五篇，不過這篇文章只簡單的說明一下。
首先我們先來說說這塊土地的意義，這塊土地中的耶路撒冷是當今三大亞拉伯罕教的聖地。而且對猶太人來說更是他們的故鄉，但在一次世界大戰時，這塊土地的居民大部份是阿拉伯人並且大部份都是穆斯林。
但是眾所皆知的，在第二次大戰時，納粹德國開始了猶太民族的種族滅絕(genocide)行動，這段其間上百萬的猶太人想盡辦法逃往任何可以去的地方，而其中巴勒斯坦這個地區，因為前面有說到他是猶太人的故鄉，所以很早之前就有移民在那購買土地，所以在那段時間巴勒斯坦湧進了很多的猶太人，當然這也使得住在該地區的阿拉伯人非常不爽。
然後雙方當然開始對幹起來，在二戰後，美國主導下產生了一個東東，就是聯合國，它這時做出一個提案 :</description>
    </item>
    
    <item>
      <title>蘇聯的誕生與結束</title>
      <link>https://mark-lin.com/posts/20170317/</link>
      <pubDate>Fri, 17 Mar 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170317/</guid>
      <description>蘇聯 (Soviet Union)歷史上的超級強國Hyperpower 之一，在 60 年代時，與美國分庭抗禮，同時是社會主義的代表，但『可惜』這個大國在1991年12月25日這天，它的國旗緩緩的從克里姆林宮上空降下，也代表了一個時代的結束。
蘇聯象徵鐮刀與鎚子倒在莫斯科街道上。(圖片來源 : 亞歷山大/法新社)
『可惜』這個字可能很多人會覺得奇怪，因為就算是現在這時代，還是很多人很討厭蘇聯，認為它是應該被消滅的，古拉格群島這禁書更披露了蘇聯強迫勞改營的生活，現在如果有勞改營那個國家應該會被罵到死吧，那為什麼筆者會說『可惜』呢，這兩個字不是筆者的立場，而是獻給喜歡社會主義生活的人的文字，但不代表他們喜歡勞改營，這世界上，不是大部份的人喜歡，就是每個人都喜歡，在二手時代這本書中，有一段話說明了蘇聯解體後那些覺得『可惜』的人們感受。
 大家都在痛罵時代，現在的時代卑鄙、下流、空虛，填滿了抹布和錄影機。偉大的國家又在那裡 ? 事情的結果是，我們今天沒有戰勝任何人，加加林並沒有飛上太空。
(出自 : 二手時代)
 想要理解蘇聯解體前與解體後人民的生活，可以去閱讀二手時代這本書，好書。
(圖片來源 : 誠品網路書店)
轉回來，本篇文章不是要說明當時人民的生活，而是要了解蘇聯的誕生與結束，接下來我們就開始說這段故事囉。
俄羅斯帝國的掰掰 1914年至1918年這段時間爆發了人類史上最慘重的戰爭第一次世界大戰，那時蘇聯可還在蛋裡，而北方那塊冰天雪地的大地的主人是俄羅斯帝國的尼古拉二世，在還在打一次世界大戰時，因為戰爭導致大量的食物短缺與通貨膨漲，使人民生活在地獄，人民的對政府的仇恨值不停的上升，當仇恨值暴表時就爆發了二月革命，然後俄羅斯帝國就說掰掰了。
法國二月革命的圖，同時也影射與俄國二月革命。(圖片來源 : sina新聞中心 )
一堆人開始搶政權與蘇聯成立 在俄羅斯帝國說掰掰後，有個臨時政府上台想穩住軍心，但心都還是冷的，就有個政黨叫俄國社會民主工黨（布爾什維克)連合其它勢力，將臨時政府踢下台囉，這件事情史稱十月革命，對了這個布爾什維克的老大就是列寧。
列寧圖 (圖片來源 : 蘋果日報)
想當然，當有人上台時，自然會有人不爽，也就是所謂的反對黨，後來也組成了個勢力就是歷史上稱為的白軍，而布爾什維克則稱為紅軍。
在歷史上白軍是支持資本主義制度，當然它的後面有其它資本主義的國家在支持，而紅軍就所支持所謂的社會主義，在這場被稱為俄國內戰的紅白大戰，最後因為白軍內部矛盾激烈、內部各派勢力互相扯後腿，而導至這場內戰由紅軍勝利，也就代表著世界最大的社會主義蘇聯正式成立。
史達林的狂人時代 在蘇聯創立不久，老大哥列寧就上天堂了，而它的接班人，就是大名鼎鼎的狂人史達林，而這位狂人他做了那些事情呢 ?
史達林紀念郵票 (圖片來源 : 維基)
五年計畫 首先登場的是五年計畫，簡單一句話來說明五年計畫是啥，那就是『用最短的時間讓蘇聯實現工業化』，但那來的錢呢 ? 蘇聯是傳統的農業國家，對錢就是從農民那邊挖，從低到不能低的價錢收購農產品，然後拿去賣，結果呢 ?
在1932至1933時，發生了蘇聯歷史上最大的飢荒，只能用慘一個字形容，尤其是烏克蘭，慘中之冠，可憐的烏克蘭美人們。
那這五年計畫的成果如何，不能說差，和中國的大躍進?相比，好的多，在那段時間之前剛好發生了1929經濟危機，世界經濟差到不能在差，所以很多的資金與人才都跑到蘇聯，因為它本來就是自已玩自已沒啥影響，所以嚴格來說這個第一個五年計畫還算成功。
但在當時的蘇聯有個很奇怪的現象，重工業發展而快，但人民的日常生活消費品非常的少，整個社會的食物都是用配給的，而且要找個盤子都很難。
大清洗 如同字面上的意思，將家裡清洗乾淨 ; 史達林執行大清洗的目的是為了反對分子清除出蘇聯共產黨，讓自已的權力更牢固，在這段時間，人民都陷入互相不信任的狀態，每個人都怕每別人誣告，或是被指控對黨的反叛，這情況咱們台灣人應該也有感覺。
在這場大清洗期間，有上百萬的人死於非命，許多人不是被送到勞改營勞改到死，就是直接被丟到西伯利亞之類鳥不生蛋的地方法，每個人聽勞改營或古拉格就像聽到佛地魔一樣，那段時間對於當時的人民，真的如同地獄一樣。
 古拉格就是管理全國勞改營的地方，全名為勞造營管理總局。
 第二次世界大戰 史達林少數幾個比較正面的事蹟是領導蘇聯成為第二次世界大戰的戰勝國，前期蘇聯被打的真的很慘，完全是被德國虐假的，但在後期就依靠天時(冬天)、地利(在老家)、人和(人海)將德軍打回老家去，不過死傷人數蘇聯比德國多上很多，七傷拳。
建立華沙公約組織 大約在1949年時，美國、法國、英國這三國家立了北大西洋公約組織，而後也有不少歐洲國家加入，這時蘇聯著麼可能看這自由主義陣營組成聯盟，於是輸人不輸陣，蘇聯就建立了華沙公約組織這個組織的主要功用如下，反正主要就是用來對抗北大西洋公約組織。
 如果在歐洲發生了任何國家或國家集團對一個或幾個締約國的進攻，每一締約國應根據聯合國憲章第五十一條行使單獨或集體自衛的權利，個別地或通過同其他締約國的協議，以一切它認為必要的方式，包括使用武裝部隊，立即對遭受這種進攻的某一個國家或幾個國家給予援助。	” ——華沙公約 第四條 第一款</description>
    </item>
    
    <item>
      <title>資料結構---堆積 Heap</title>
      <link>https://mark-lin.com/posts/20170314/</link>
      <pubDate>Tue, 14 Mar 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170314/</guid>
      <description>這篇文章中，我們將要來說明堆積(heap)這種資料結構，但在說明這個資料結構前，讀者需要先了解二元樹這種資料結構，如果不了解的話，可以看看筆者的這篇文章。
資料結構&amp;mdash;樹狀結構與二元樹
不過我們這邊也簡單的複習一下二元樹 ; 二元樹它是一種樹狀結構，但它要符合每個節點最多有兩個子樹這個特性，才能稱為二元樹。
在大概知道了二元樹後，我們就可以開始本篇文章的重點堆積heap。
 堆積的原理 二元樹轉成堆積 程式碼實作  堆積 Heap 的原理 堆積這種資料結構，它是一種二元樹，而且要有以下兩種特點的，才能被稱為堆積。
 任意節點小於(大於)它的所有子節點，最小(大)的節點一定在根上。 堆積是種完全樹。   完全樹 : 除了最低層外，其它層的節都都被塞滿。
 我們畫個圖來看看，就可以很明顯的知道二元樹與堆積的差別，如下圖，左邊的堆積樹很明顯的，子節點值一定小於父節點，而二元樹的就沒這特性。
二元樹轉換成堆積 上面簡單的說明什是堆積，接下來我們這邊要來說明，如何將二元樹轉換成堆積。
傳統上有二種方法，由下而上與由上而下，我們本章節將說明由下而上的方法，不然文章會太長……。
這個方法的基本流程如下，我們以下說明都以max heap為主，也就是根節點為最大值。
 計算出此棵樹的節點數量，假設為n。 在從其n/2節點(事實上也就是最後一個父節點)開始進行比較。 若子節點的值大於父節點，則相互對調。 若有交換，還比較在去子節點進行比較。  我們來舉個例子，假設我們有如下圖的二元素。
接下來我們開始說明他的轉換成堆積的流程。
最後下圖就是二元樹轉換成堆積的結果。
程式碼實作 最後我們來將來上述說明進行程式碼的實作，將二元樹轉換成堆積。我們先來簡單的複習實作二元樹。首先是二元樹的基本結構。
function Node(data, index) { this.data = data; this.index = index; this.left = null; this.right = null; } function BinaryTree() { this.root = null; this.count = 0; } 然後我們將要新增個方法，可以新增節點到二元樹中。
BinaryTree.prototype.add = function(node) { node.</description>
    </item>
    
    <item>
      <title>資料結構---圖形結構</title>
      <link>https://mark-lin.com/posts/20170311/</link>
      <pubDate>Sat, 11 Mar 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170311/</guid>
      <description>圖學理論(graph theory)它源於1736年的數學家 LeonHard Euler ，它為了解決Koenigsberg bridge問題而發展出來的理論，雖然Koenigsberg bridge問題不是我們這篇的重點，但還是簡單介紹一下這個圖論中的著名問題。
在某個國家內，有條河經過兩個市區，並且在這條河中心上還有兩個小島，小島與河的兩岸有七條橋連接這，下圖就是該環境的模擬圖。
那麼這個問題是 ~
 在所有的橋都只能走一次的前題條件下，如何才能把所有的橋都走過一次。
 雖然 LeonHard Euler 並沒有解決這個問題，但卻發現了新的研究領域圖論。
圖形結構之原理 圖(graph)，是一種用來描述點與點關係的資料結構，也可以說是記錄關聯的結構，它和樹狀結構長的得像，而他們的關係在於
 樹是一種圖
 那什麼時後，它是圖而不是樹呢?
 出現一個環時。 他沒有連通時。  一張圖會由數個節點以及數條邊所構成，節點與節點間使用邊來相接，在數學上通常定義成G = (V,E)來表示，其中V是所有節點所成的集合，而E代表所有的邊所成的集合。圖(graph)畫出來長的如下圖。
接下來我們來認識一些名詞。
 頂點(vertex) : 上圖中的A、B、C就為三個項點。 邊(edge) : 上圖中那個每個項點的連線，就稱為邊。 相鄰(adjacent) : 例如上圖中的A與B就為相鄰的，其它的項點也都如此。 附著(incident) : 上圖中，我們可以說明，邊{A,C}與邊{A,B}『附著』在項點 A 。 路徑(path) : 代表某個項點到某個項點的過程。 簡單路徑(simple path) : 在上圖中 A 到 D 的路徑可能有ACBD和ABD，這時我們可以稱ABD為簡單路徑。 長度(length) : 一條路徑上的長度是指該路徑上所有邊的數量。 分支度(degree) : 例如上圖中，我們可以稱項點 B 的分支度為 3 ，但在有向圖中會分成外分支度與內分支度。 子圖(Subgraph) : 請看下圖。  圖的種類 基本上圖又可以分成下述幾重，要選擇那種來使用取決於你的問題。</description>
    </item>
    
    <item>
      <title>樹狀結構的遍歷 Traversal ( Iteration )</title>
      <link>https://mark-lin.com/posts/20170310/</link>
      <pubDate>Fri, 10 Mar 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170310/</guid>
      <description>在筆者的『基礎資料結構 3 &amp;mdash; 樹狀結構與二元樹』的這篇文章中，我們介紹了樹的基本概念，也學習了如何遍歷樹的方法，在之前的文章中，我們有說到，如果要遍歷樹大至上有以下三種方法 :
 中序追蹤 (in-order) : 先走訪左子樹，然後在根，最後在右子樹。(DBEAFCG) 前序追蹤 (pre-order) : 先走訪根，然後在左子樹，最後在右子樹。(ABDECFG) 後序追蹤 (post-order) : 先走訪左子樹，然後在右子樹，最後是根。(DEBFGCA) level-order : 先走訪第一層節點，再走訪第二層，最後會走到最後一層。(ABCDEFG)   補充: 這裡我們在補充第四種追蹤level-order，事實上它就是BFS，也就是一層一層的掃
 那為什麼我們這裡要在拿來說一次呢 ?
 因為我們之前實作的方法是用『 Recursion 』來實作。
 有寫過程式的人大概會知道，在使用recursion 實作程式碼，常常有可能會發生memory leak事件，所以我們這篇將要來說明，如何不使用它，來實作以上三種 traversal。
中序追蹤 (in-order)  左 =&amp;gt; 根 =&amp;gt; 右
 iteration  直接先深入最深的左子樹，並將行經的節點，存放到 stack 中。 然後深入到最後時，發現是 null ，開始從 stack 中 pop 東西出來。 接下來在從 pop 出的節點的右子樹開始重複第一個步驟。  /** * Tree inordrTraversal (no recursive) * Tip: 左根右 */ BinarySearchTree.</description>
    </item>
    
    <item>
      <title>資料結構---樹狀結構與二元樹</title>
      <link>https://mark-lin.com/posts/20170309/</link>
      <pubDate>Thu, 09 Mar 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170309/</guid>
      <description>在這篇文章中，我們將要仔細的來說明樹(Tree)這個資料結構，它在計算機科學中非常的重要，有很多演算法都一定會運用到這種資料結構。接下來我們將要好好的研究它，目錄如下。
 樹的定義與特性 二元樹 二元樹的實作與方法操作方法實作  樹的定義與特性 在資料結構中，樹這種結構，是用來模擬具有樹狀結構性質的數據集合，它有很明確的層級關係，它長的就像個倒過來的樹，不過你也可以將他想像成祖譜，它真的很像。
在說它的特性前，我們先簡單的知道它的一些素語。我們會搭配著下圖來進行說明。
 節點(node) : 下圖的每一個圈圈都存放資料，稱為節點(node)。 根節點(root) : 就是最上面的節點，如下圖的節點 A 。 邊(edge) : 下圖連節每個節點的線，稱為邊(edge)。 分支度(degree) : 一個節點的分支度是它擁有的子節點數量，如下圖看節點 C 它的分支度為 3 。 階度(level) : 樹中節點的層級數量，一代為一個階度，樹根(A)的階度為 1 ，下圖的樹階度為 3 。 高度(Height)、深度(depth) : 樹中某節點的高度代表此節點至最深階度的子節點距離，也就是邊的數量，例如 A 節點的高度為 2 ，而 B 節點的高度為 1 。  接下來我們來說明樹的特性，它具有以下的特點 ; 只要符合下面特點的，我們就可以稱為樹狀結構。
 每個節點有零個或多個子節點 沒有父節點的節點稱為根節點 每一個非根節點有且只有一個父節點 除了根節點外，每個子節點可以分為多個不相交的子樹  二元樹 ( Binary tree ) 這邊我們要來說明二元樹，它是樹的一種，我們常聽到的二元啥演算法，有很大一部份都是運用二元樹這種資料結構來處理，它的定義如下。
 二元樹是每個節點最多有兩個子樹的樹狀結構
 只要符合上述條件的樹，我們都歸類為二元樹。其中二元樹還是有不同的種類。
滿二元樹 ( Full Binary tree ) 如果一棵樹的階度為 k 的樹，它的節點樹量為 2^k - 1 ，則稱為滿二元樹，也就是說全部塞滿的意思，如下圖就是個滿二元樹，它階度為 3 ， 所以它的節點樹量應該為 2^3 - 1 = 7 ，下圖的節點數量就為 7 。</description>
    </item>
    
    <item>
      <title>資料結構---串列 Linked List</title>
      <link>https://mark-lin.com/posts/20170213/</link>
      <pubDate>Mon, 13 Feb 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170213/</guid>
      <description>前篇文章中，我們說明三種資料結構、陣列、堆疊、佇列，在開始今天的文章前，我們先簡單的複習一下這三個東西是啥。
 array : 最常用使用到的資料結構，它是一種相同形態(!)的資料集合，並且會分配『連續』的記憶體空間給予陣列存放資料。 stack : 後進先出法原理的資料結構，後進去的資料會先取出，就像是你有個箱子，你最先放進去的東西，要先將上面的東西取出後，才能取得。 queue : 先進先出法原理的資料結構，先進去的東西先取出，就像是排隊一樣，先排先贏，理論上(和平)。   剛剛在陣列那有說到相同形態，但事實上javascript的陣列，可以存放任何形態的資料，但其它的語言就需要先宣告形態了，某些方面來說它的陣列比較算是list。
 複習完了上一篇文章後，咱們可以來學習新的資料結構連結串列(linked list)j。
 串列(Linked list)原理 串列與陣列的比較 javascript程式實作  串列 ( Linked List ) 原理 在上一篇中，我們有學習到陣列，它在儲放資料時非常的彈性，但在進行新增或刪除時卻沒著麼方便，主要原因為它的記憶體是連續的。
本篇文章將要說明的連結串列(list)，在新增或刪除時就非常的方便，因為它記憶體不是連續的，而是每個結點分配一段記憶體，然後在結點中記錄下個結點的位置。
連結串列有分很多種，我們在這篇文章中將說明比較常用到的『單向連結串列』與『雙向連結串列』。
單向連結串列 單向連結串列，它主要組成的定義如下。
 由一組節點(Node)組成的有序串列。 每個節點有『資料欄』與一個『連結欄』組成。 『連結欄』指向其它節點的位置。  根據以上的定義，大至上長的如下圖。
接下來假如我們要新增節點D至A與B之間，過程會和下圖一樣，會將A節點的Link連至D節點，然後它再連到B結點上。而刪除結果過程也差不多，就只是重新指向節點位置。
雙向連結串列 (Double Linked List) 雙向連結串列是另一種常用的串列結構，在單向串列中，它只能順著一個方向尋找資料，而且中間不小心有個節點斷掉，那後面串列的資料就會消失且救不回來，而雙向連結就是可以改善『單向』與『節點斷掉』這兩個缺點。
雙向連結串列，它主要組成的定義如下。
 由一組節點(Node)組成的有序串列。 每個節點有『資料欄』與二個『連結欄』組成，一個連結前一個節點，而另一個則連結後一個節點。 『連結欄』指向其它節點的位置。  根據以上的定義，大至上長的如下圖。
然後我們看下圖，來理解如果要插入與刪除節點時，雙向連結串列會如何處理。事際上原理和單向連結串列差不多，都是重新指向位置，只是它要多指向一個。
串列和陣列的比較 由於串列和陣列這兩個使用起來很相似，但原理上，很多地方是不一樣的。以下比較表格來源為此，傳送門。
    連結串列 (List) 陣列 (Array)     記憶體 不需要連續的空間 需要連續的空間   節點型態 各node形態不相同 各node形態相同   操作複雜度 插入、刪除都為O(n) (備註) 插入刪除都為O(1)|   空間配置 不需預留空間 須事先宣告連續空間   資料分割、連結 容易 不容易   存取方式 只能循序存取 可支援隨機與循序存又   存取速度 速度慢 速度快   可靠性 差 佳   額外指標空間 需要額外的指標空間 不需要    備註 這裡所為的插入與刪除是指針對某一個 index 的節點進行插入或刪除，在這種情況下，list 需要走到此 index 在進行對應的操作，因此是 O(n)。</description>
    </item>
    
    <item>
      <title>資料結構---陣列(Array)、堆疊(Stack)、佇列(Queue)</title>
      <link>https://mark-lin.com/posts/20170211/</link>
      <pubDate>Sat, 11 Feb 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170211/</guid>
      <description>接下來的幾篇文章，我們將要簡單的說明幾個基礎的資料結構，那麼資料結構又是什麼呢?
根據 wiki 的解答。
 資料結構是電腦中儲存、組織資料的方式。
 也就是說你丟了一堆資料進去，你的儲存方式，就是資料結構。
那選擇正確的資料結構可以做啥 ? 答案就是可以提供你的演算法效率。接下來我們將在本篇文章說明三種資料結構陣列(Array)、堆疊(Stack)、佇列(Queue)。
本篇文章目錄如下。
 陣列 堆疊 佇列  陣列 ( Array ) 陣列應該算是我們寫程式時，最常使用到的一種資料結構，它就長的下面這樣，上面那行代表我們的資料陣列，下面那行只是表示每個資料對應到的Index，例如array[0]的值為a。
不過有幾點要注意，當初陣列設計之初是在形式上依賴內存分配而成，也就是說必須預先設定陣列的大小。這使得陣列有以下特性。
 設定陣列大小後，不能在改變(資料溢位問題)。 在內存中有該陣列專用的連續空間，不會存在其中程式要調用的資料空間。  由於陣列實在太常使用了，這邊就不多說囉。
時間複雜度  indexing : O(1) find : O(n)  堆疊 ( Stack ) 它事實上與陣列很相似，只是它有幾個特殊的方，它只能允許在陣列的一端進行操作，而且按照『後進先出』 LIFO, Last In First Out 的原理運作。如下圖表示。
然後我們簡單的使用javascript來建立stack的資料結構，由於我們是要練習用，所以我們不使用Js的陣列內本來就有提供的stack方法。
首先我們先建立Stack的類別，事實上在js中不該說類別，_size存放該stack的大小，而_container則存放資料。
/** * Stack * this is stack data structure; * @returns {undefined} */ function Stack(){ this._size =0; this._container = {}; } 接下來我們要建立的方法有兩個push與pop，其中push就是將資料丟到stack內，而pop就是取出資料，由於stack遵循『後進先出法』，也就是後丟進去的資料，反而會比較快取得，所以pop，是要取該stack內最後被丟進去的資料。</description>
    </item>
    
    <item>
      <title>VIM的五四三---vim &#43; syntastic &#43; eslint &#43; react的配置</title>
      <link>https://mark-lin.com/posts/20170201/</link>
      <pubDate>Wed, 01 Feb 2017 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20170201/</guid>
      <description>本篇文章中，我們將要和讀者說明，在使用vim開發javascript應用時，如何可以在每一次儲存時，自動的檢查我們js是否有問題，讓我們在開發時，可以更快速的進行修正。
配置完成果會如下圖，你可以看到他會自動顯示什麼地方需要修改，以及修改的原因。
Step1. 安裝syntastic 首先我們第一步，要先安裝syntastic ，它是一個vim的套件，它的功用就是可以針對程式碼進行檢查，你可以針對不同的程式碼配置不同的檢查器，像我們要檢查javascipt時，就是配置了eslint這個檢查器。
由於我是使用vundle，所以只要在.vimrc加入下面這行。然後再執行PluginInstall就會自動幫你裝好這套件了。
 Plugin &#39;scrooloose/syntastic&#39; 接下來我們會在.vimrc檔案內加入以下的配置。
 set statusline+=%#warningmsg# set statusline+=%{SyntasticStatuslineFlag()} set statusline+=%* let g:syntastic_always_populate_loc_list = 1 let g:syntastic_auto_loc_list = 1 let g:syntastic_check_on_open = 1 let g:syntastic_check_on_wq = 0 let g:syntastic_javascript_checkers = [&#39;standard&#39;] let g:syntastic_javascript_standard_generic = 1 let g:syntastic_javascript_checkers = [&#39;eslint&#39;] let g:syntastic_javascript_eslint_exec = &#39;eslint&#39; Step2. 安裝eslint checker. 上面的步驟我們已經完成了vim的配置，並且已經設置好javascript的檢查器為eslint，但我們實際上還沒安裝好eslint，所以我們這裡將要說明如何安裝eslint。
首先要安裝全域的eslint。
npm install -g eslint 然後在有packjson下的專案，執行下列指令，該指令可以進行eslint的規則配置，它會問你是否用es6或react之類的問題，然後根據你的回答產生出配置檔。
eslint --init 產生出配置檔如下。eslint會根據該配置檔，來檢查javascript檔案。正常來說，這樣就該可以使用，但有時還是會有問題。
module.exports = { &amp;quot;env&amp;quot;: { &amp;quot;browser&amp;quot;: true, &amp;quot;commonjs&amp;quot;: true, &amp;quot;es6&amp;quot;: true }, &amp;quot;extends&amp;quot;: &amp;quot;eslint:recommended&amp;quot;, &amp;quot;parserOptions&amp;quot;: { &amp;quot;ecmaFeatures&amp;quot;: { &amp;quot;experimentalObjectRestSpread&amp;quot;: true, &amp;quot;jsx&amp;quot;: true }, &amp;quot;sourceType&amp;quot;: &amp;quot;module&amp;quot; }, &amp;quot;plugins&amp;quot;: [ &amp;quot;react&amp;quot; ], &amp;quot;rules&amp;quot;: { &amp;quot;indent&amp;quot;: [ &amp;quot;error&amp;quot;, &amp;quot;tab&amp;quot; ], &amp;quot;linebreak-style&amp;quot;: [ &amp;quot;error&amp;quot;, &amp;quot;unix&amp;quot; ], &amp;quot;quotes&amp;quot;: [ &amp;quot;error&amp;quot;, &amp;quot;double&amp;quot; ], &amp;quot;semi&amp;quot;: [ &amp;quot;error&amp;quot;, &amp;quot;always&amp;quot; ] } }; BUG&amp;mdash;沒有出現錯誤訊息 正常來說，上面的流程有配置好，應該就可以使用，但是呢，我就在這邊debug了很久，它的錯誤提示一直沒有跑出來。我來說明一下我的debug流程。</description>
    </item>
    
    <item>
      <title>30-30之MongoDB三十天的學習之旅</title>
      <link>https://mark-lin.com/posts/20160930/</link>
      <pubDate>Fri, 30 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160930/</guid>
      <description>不知不覺~漫長的鐵人賽就進入了尾聲，當初會參加鐵人賽也只是因為，沒參加過 ~ 來試試看，而且也剛好我今年的時間比較多點兒，話說回來，為什麼我會選MongoDB來當題目呢?事實上也只是因為我自已無聊在做的專案，有把mongoDB拿來用，所以就想說認真的來研究一下mongoDB ~
我們簡單的總結一下我們這三十天學了那些東西。
首先最基本的一定是一個資料庫的CRUD，這階段就像玩天堂時的說話島一樣，你要打打哥布林。
 30-3之新手村CRUD&amp;mdash;新增 30-4之新手村CRUD&amp;mdash;新增之Bulk與新增效能測試 30-5之新手村CRUD&amp;mdash;更新 30-6之新手村CRUD&amp;mdash;更新之陣列欄位 30-7之新手村CRUD&amp;mdash;刪除 30-8之新手村CRUD&amp;mdash;搜尋之find與搜尋操作符號 30-9之新手村CRUD&amp;mdash;搜尋之陣列欄位與regex 30-10之新手村CRUD&amp;mdash;搜尋之Cursor運用與搜尋原理  然後在基礎的新手村畢業以後，你就可以坐船前往大陸，不過下船的地方在那我有點忘了。 接下來我們要學習的事情就是，要如何的使我們搜尋速度更快速。
 30-11之索引(1)&amp;mdash;索引的哩哩扣扣 30-12之索引(2)&amp;mdash;複合索引的坑 30-13之索引(3)&amp;mdash;比較特別的索引使用  在我們了解了如何將搜尋速度提升更快後，我們就可以來研究如何使用mongodb來進行資料分析，這個階段就像是龍之谷吧……年代有點久遠有點快忘了。
 30-14之聚合(1)&amp;mdash;Aggregate Framework的哩哩扣扣 30-15之聚合(2)&amp;mdash;Pipeline武器庫 30-16之聚合(3)&amp;mdash;潮潮的MapReduce  可是分析完後，我們發覺有些地方效能還不是不太好，明明索引那些都處理好囉 ? 這時我們只能往架構方面來尋找問題囉。
 30-17之MongoDB的設計&amp;mdash;正規與反正規化的戰爭  在以上的東西都已經學習的差不多時，這時我們就要來驗證一下，我們是否真的有學習進腦袋裡，這時最簡單的驗證方法，就是自已想個題目，然後從0 → 1 自已建立看看。順到一題0 → 1這本書真的不錯看。
 30-18之運用研究&amp;mdash;PO文模擬情境(1) 30-19之運用研究&amp;mdash;PO文模擬情境(2) 30-20之運用研究&amp;mdash;PO文情境模擬(3)  在驗證完以上的東西都學習會後，我們可以往分散式的東西進行學習囉，這邊應該就是傲慢之塔的等級囉。
 30-21之MongoDB的副本集 replica set(1) 30-22之MongoDB的副本集 replica set(2)&amp;mdash;使用Docker建立MongoDB Cluster 30-23之分片Sharding(1)&amp;mdash;Hello Sharding 30-24之分片Sharding(2)&amp;mdash;Chunk的札事 30-25之分片Sharding(3)&amp;mdash;片鍵的選擇  然後接下來的最後一部份也是驗證你上面的東西有沒有學會。
 30-26之運用研究&amp;mdash;股價應用模擬(1) 30-27之運用研究&amp;mdash;股價應用模擬(2) 30-28之運用研究&amp;mdash;股價應用模擬(3)  事實上到這邊應該就可以結束了，但我事實上有忘記一個主題，所以補充在最後面。
 30-29之補充&amp;mdash;忘了講的事務操作   最後忘了講幾句感言的話，事實上我很感謝上天，還能給予我可以參加30天鐵人賽的腦袋與體力，2016年應該是我目前的人生轉哲最大的年度，我生了一場重病，我得的病就是你們腦袋中最不想得的病排行板前三名， ~ 啊喲啊喲 ~ 小的才2開頭而以 ~ 啊喲啊喲 ~ 得這病是真的失去不少東西，而且治療過程，有時後我會想，似乎上天堂好像會輕鬆點兒，上一句只是完笑，得這鬼病也只有一條路，面對現實就對囉~</description>
    </item>
    
    <item>
      <title>30-29之MongoDB--- 事務操作的空虛感</title>
      <link>https://mark-lin.com/posts/20160929/</link>
      <pubDate>Thu, 29 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160929/</guid>
      <description>本篇文章是用來補充一下，前面忘了講的觀念，記得在第一篇時，我們有提過下面這句話。
 MongoDB 不支持事務操作
 但事實上這段話有很多觀念要來說明說明，不然很難讓人了解事務操作是啥，所以我們這篇要用來補充一下這個主題。
~ 事務操作是啥鬼 ~ 咱們首先先來了解一下，事務是啥?根據wiki的定義。
 資料庫事務是資料庫管理系統執行過程中的一個邏輯單位，由一個有限的資料庫操作序列構成。
 這邊用白話文來簡單說明一下，事實操作你可以把他想成一個工作流程，例如煮菜，你首先要先洗菜、切菜、丟到鍋子、加調味料，『煮菜』這名詞就是一個事務，它裡面包含了剛剛說明的流程。
我們轉回的在資料庫中的事務，假設我們是個證券商，我們收到使用者的下單通知，那我們資料庫會著麼進行? 我們下面來試試列出該事務操作過程。其中我們有兩個資料表accounts為使用者的帳戶資料、第二個為orders下單資料，呃對了先不管交割日這鬼，也就是付錢日。
 首先我們會先在orders新增一筆訂單。 再到accounts針對該使用者的帳戶進行扣款。  那如果發生錯誤時，事務會著麼處理?
根據以上的例子，我們拿來繼續使用，假設我們在第二個步驟，準備要扣款時，系統突然gg了，那要著麼樣?在一些資料庫中，當整個事務提交給資料庫時，它會保證這整個事務要嘛全部完成，要嘛全部沒完成。
也就是說，如果我們第二個步驟掛掉時，我們一開始在orders新增的一筆訂單會取消，會保持整個事務的完整性，不會只完成一半。
最後這邊我們來看一下事務操作的四個特性ACID，來腦補一下，以下內容為wiki，並且自已寫寫說明。
 原子性（Atomicity） : 要麼全執行、要麼全取消，沒得商量。 一致性（Consistency）: 這個是指在事務開始與結束後，資料庫的完整性約束沒有被破壞。 隔離性（Isolation）: 多個事務執行時，任一個事務不會影響到其它的事務。 持久性（Durability）: 代表即時停電或啥，事務一旦提交後，則持久化保存在資料庫中。  ~ MongoDB 不支援事務 ~ 對mongodb不支援事務，但它還是有支援一些符合各別特性的操作，總共有三個。
1. 在單個 document 上有提供原子性操作 findAndModify mongodb有提供單個document，操作，也就是說如果你要針對該document進行更新，要麼全部更新完成，不然就全部不更新，我們簡單用個範例來說明如何設計成，符合原子性的功能。
我們把上面的例子拿下來用。
 假設我們是個證券商，我們收到使用者的下單通知，那我們資料庫會著麼進行? 我們下面來試試列出該事務操作過程。其中我們有兩個資料表accounts為使用者的帳戶資料、第二個為orders下單資料，呃對了先不管交割日這鬼，也就是付錢日。
 但注意一點，如果我們是建立將accounts與orders分成兩個collection來建立，那我們就沒辦法使用mongodb所提供的原子性操作，因為就變為多document的操作。
所以我們需要將它修改為都存放在同一個collection，沒錯也就是進行反正規化，資料大概會變成這樣。
{ &amp;#34;user&amp;#34; : &amp;#34;mark&amp;#34; , balance : 10000 , orders : [ { &amp;#34;id&amp;#34; : 1 , &amp;#34;total&amp;#34; : 1000 , &amp;#34;date&amp;#34; : &amp;#34;20160101&amp;#34; }, { &amp;#34;id&amp;#34; : 2 , &amp;#34;total&amp;#34; : 2000 , &amp;#34;date&amp;#34; : &amp;#34;20160103&amp;#34;} ] } 然後我們進行交易時，我們需要先檢查balance確定是否有足的錢，然後在新增一筆下單到orders欄位中，最後才修改balance，而我們這時需要用到findAndModify ，它可以確保這筆交易的，在確定完balance後，不會有其它線程來更新它的balance。</description>
    </item>
    
    <item>
      <title>30-28之MongoDB運用研究---股價應用模擬(3)</title>
      <link>https://mark-lin.com/posts/20160928/</link>
      <pubDate>Wed, 28 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160928/</guid>
      <description>上一篇研究簡單的說明完，股價分析的運用操作後，接下來我們這篇文章將要說明一些程式交易的東西，不過雖然說是程式交易，但事實上也只是簡單的計算出技術分析指標然後產生出買賣時間點，要說是程式交易好像也不太算兒……。
~ 二哈的需求分析 ~ 今天咱們的二哈和我說，啊鳴~ 最近我想搞搞程式交易 ~ 幫我一下，然後我問他你想做啥，他竟然回，我也不知道也 ~ 我只是聽說那很潮、很容易賺錢 ~ 幫我咱 ~咱們是好哥吧，然後我一直在笑他你傻了啊，最後他就用出這種表情。
雖然很想和他說~你何不食屎忽 ~ 但想到要愛護動物就想是幫他想一下。
回到正題，說到程式交易我們先看一下智庫的定義。
 　程式交易在英文中叫做Program Trading, 就是將自己的金融操作方式，用很明確的方式去定義和描述，且遵守紀律的按照所設定的規則去執行交易。
 上面只是定義，不過我簡單的說明一下我的認知，就是『寫個策略計算出買賣點，然後叫電腦乖乖的進行交易』。
網路上以及論文都有提供一些策略，你可以自已去試試看，不過會不會賺錢小的我就不知道了，順到幫我老師打廣告一下，如果對金融應用感興趣的可以看看他寫的書，傳送門在此。
好再一次回來正題，那我們在這邊就簡單的講幾個策略……真的很簡單，因為我模擬的資料只有k線別忘囉。
 二哈可以利用30天移動平均線與當日開盤價進行買點與賣點的計算。 二哈可以用五天期的平均成交量低於十天前的五天期平均成交量的 75%這策略來進行交易。  就來這兩個吧~
~ 實作 ~ 二哈可以利用30天移動平均線與當日開盤價進行買點與賣點的計算 首先咱們先來完成這個需求，在投資股票時，有個東西你在看k線時，幾乎所有的開盤軟體都會提供，它就是移動平均線，其中它又有十天線、月線、季線、年線、二年線等，簡單來說，十天線就是用前十天的平均來計算出來的一條件，非常的Easy。
然後我們來看看我們的月線也就是30天期線的產生，首先先看看最外面有個變數temp，它是一個陣列，用來存放30天的開盤價，為了用來計算平均數用的，但有點注意，如果只是在外面宣告個var temp = []這樣在mongodb的mapreduce函數是無法使用的。
那要著麼使用呢 ? 拉下面一點會看到有個參數物件，其中的scope就是讓我們可以使用全域變數 temp 。
temp看完後在來看看我們的主體mapreduce，但在執行mapreduce之前，我們會先進行query，將code為8111的尋找出來，這邊有個金句要注意一下。
 盡可能的在進行資料分析時，先將不需要的資料篩選剔除掉，這是個黃金法則。
 var temp =[]; var result = db.stocks.mapReduce( function(){ if(temp.length &amp;lt; 30){ temp.push(this.open); emit(this.date,0); }else{ temp.splice(0,1); temp.push(this.open) var sum =0, avg =0, tempCount = temp.</description>
    </item>
    
    <item>
      <title>30-27之MongoDB運用研究---股價應用模擬(2)</title>
      <link>https://mark-lin.com/posts/20160927/</link>
      <pubDate>Tue, 27 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160927/</guid>
      <description>上一篇文章中，我們已經說明完基本的架構以及索引和分片的選擇，接下來我們就要實際的來使用資料來進行一些分析，能用搜尋時就用搜尋，不能用搜尋時就改用 aggreagate framework，然後如果再不能的話則用 mapreduce。
~ 二哈的分析需求 ~ 這二貨根本沒有想需求，只是想說來分析一下，但分析啥也沒說，然後還要我們幫他想一下，然後還用這種表情看我，一臉用這種事情還用問我的表情。
然後我們只能乖乖的幫他想幾個。
 二哈最基本應該會輸入股價代碼，然後輸出該股票的全部資料。 二哈想尋找出該股票某段區間的資料。 二哈想找出當日交易最熱絡的股票。 二哈想找出某日價格波動最高的股票。  那我們先開始吧。
~ 索引與片鍵的建立 ~ 呃對了，雖然上一篇文章中，我們已經將索引與片鍵選出來了，分別為
索引 : { &amp;quot;date&amp;quot; : 1 , &amp;quot;code&amp;quot; : 1 }
片鍵 : { &amp;quot;code&amp;quot; : 1 }
但咱們突然想到一件事，你要建立的片鍵，必須要有索引，當我們的索引是複合索引，這樣我們還可以使用{ &amp;quot;code&amp;quot; : 1 }來建立嗎? 我們來試試。
db.stocks.ensureIndex({ &amp;#34;date&amp;#34; : 1 , &amp;#34;code&amp;#34; : 1 }) sh.enableSharding(&amp;#34;test&amp;#34;) sh.shardCollection(&amp;#34;test.stocks&amp;#34;,{&amp;#34;code&amp;#34;:1}) 結果如下，看來是不行。
那要著麼辦呢?這時我們有三個辦法。
 再增加一個code索引。 選擇 { &amp;quot;date&amp;quot; : 1 }與{ &amp;quot;code&amp;quot; : 1}當索引。 片鍵修改為{ &amp;quot;date&amp;quot; : 1 , &amp;quot;code&amp;quot; : 1 }。  要選那個呢，首先先來說說第一個，增加一個索引，缺點就在於需要更多的空間，而且這索引搜尋時幾乎不太用到，因為幾乎被原本的 { &amp;quot;date&amp;quot; : 1 , &amp;quot;code&amp;quot; : 1 }可取代。</description>
    </item>
    
    <item>
      <title>30-26之MongoDB運用研究---股價應用模擬(1)</title>
      <link>https://mark-lin.com/posts/20160926/</link>
      <pubDate>Mon, 26 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160926/</guid>
      <description>前面幾篇文章我們說明完了分片的運用後，我們接下來，就來實際的模擬個情景，我們來學習要如何的一步一步完成，咱們選擇的模擬情境為股價應用，現在Fintech幾乎天天在報紙上看到，所以我們就來應景一下，來嘗試這建立看看金融應用。
~ 情景說明 ~ 二哈是一位二貨，他平常就有在進行投資，大部份都是買買股票，但平常都只是直接卷商的平台看看資料，然後就直接投資囉，但是這貨兒每買必輸每賣必虧，然後有一天他聽到天賴之音說『請分析一下』，然後它就決定走上資料分析一途……這貨真的很二
回歸主題，二哈的需求只是分析，所以我們再分析前，我們要先建立好資料，通常能分析的資料量是越大越好，所以我們這邊一定會需要用到分片，並且我們先從最基本的股票資料k線與成交量來建立資料，首先我們的資料結構應該如下。
{ 股價代碼	&amp;quot;code&amp;quot; : 1011, 日期	&amp;quot;date&amp;quot; : 20160101, 開盤價 &amp;quot;open&amp;quot; : 100, 最高價 &amp;quot;height&amp;quot; : 100, 收盤價 &amp;quot;close&amp;quot; : 90, 最低價 &amp;quot;low&amp;quot; : 80, 成交量 &amp;quot;volume&amp;quot; : 1000 } 然後我們來正試開始吧。
~ Step 1. 架構分析 ~ 索引架構思考 首先我們根據以上的資料結構可知，我們該主題目前不太需要考慮到正規化與反正規化的問題，那接下來我們來思考看看索引的問題，但那蠢二哈只想到分析但不知道分析啥，我們來幫他想想。
我們來一條一條列出，我們想到的需求。
 二哈最基本應該會輸入股價代碼，然後輸出該股票的全部資料。 二哈想尋找出該股票某段區間的資料。 二哈想找出當日交易最熱絡的股票。 二哈想找出某日價格波動最高的股票。  細細想一下，大部份的使用情境都一定需要時間，而且是個範圍，然後有時在搭配某個股票，所以我們基本上會針對date和code來考慮建立索引，那要選用那種索引呢，目前有三種選擇我們先列出。
第一種 { &amp;quot;date&amp;quot; : 1 , &amp;quot;code&amp;quot; : 1 } 第二種 { &amp;quot;code&amp;quot; : 1 , &amp;quot;date&amp;quot; : 1 } 第三種 { &amp;quot;code&amp;quot; :1 },{ &amp;quot;date&amp;quot; :1 } 還記得{ &amp;quot;sortKey&amp;quot; : 1 , &amp;quot;queryKey&amp;quot; : 1 }這個複合索引時有提到的東西麻，很常用來排序的請放前面，日期和股價代碼，理論上來說日期會很常用到排序，所以我們第二種索引可以刪除。</description>
    </item>
    
    <item>
      <title>30-25之MongoDB分片Sharding(3)---片鍵的選擇</title>
      <link>https://mark-lin.com/posts/20160925/</link>
      <pubDate>Sun, 25 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160925/</guid>
      <description>上一篇文章我們詳細的說明完分片的機制後，接下來我們就要來詳細的說明片鍵的選擇，片鍵的選擇關係到你的分片執行速度與效能，並且一但建立後，要再修改幾乎是不太可能的，所以請像選老婆一樣，用心的選~
 完美的片鍵定義(這鬼不存在的) 片鍵的種類  ~ 完美的片鍵定義(這鬼不存在) ~ 在我們開始學習片鍵的選擇前，我們要先知道，什麼樣的片鍵是最好的，最理想的，但想也知道最好的東西是不存在的，但我們還是要知道，才能給我們的選擇給個基準。
整體來說完美的片鍵有下面特性
 所有的新增、刪除、更新等寫的操作，都可以平均分配到所有的分片。 所有的搜尋等讀的操作，都可以平均分配到所有的分片。 所有的操作都只會發到相關的分片，例如更新時不會跑去分片內是空的進行更新。  我們先來說說第一個特性，如果沒有該項特性會發生什麼事情，假設我們的cluster有四個分片，我們當然是希望每個分片可以處理25%的事情，但是假設我們做那些寫的操作時(ex.新增)全部都集中在其中一個分片，那你會發覺那個分片會越來越大~越來越大~ ，而且別忘了我們上章節說的chunk分配，它是根據數量來進行分配，不是用大小，因此你的那個分片內的chunk不會分配到其它分片，這樣也就失去你用分片的意義了。
而至於第二點特性，mongos在處理搜尋請求時主要會分成下述兩種的處理方式。
 搜尋時不包含片鍵，則會將搜尋分配到發有的分片，然後合并搜尋結果，再返回給client。 搜尋時包含片鍵，則直接根據片鍵，然後找出要尋找的chunk，向相對的分片發送搜尋請求。  根據上面的說明，我們知道mongos的讀操作過程，然後我們這時在回來思考，如果這時搜尋時都集中在一個分片上，會發生什麼事，首先搜尋時不包含片鍵這種類型影響不大，但另一種就會影響到，因為原本該分散的壓力，反而都集中在一個分片，運氣不好搜尋請求過多，就爆掉了。
而至於第三點，就只是浪費資源囉~
這邊我們大概來整理一下，根據以上三點大概可以拆分成幾個良好片鍵的特性。
 容易分割片鍵 : 容易分割的片鍵可以使mongodb更容易的均衡各分片的資料量，不容易發生過大的分片，基數越大的走容易分割資料。   基數是指系統將資料分成chunk的能力，例如性別欄位就是個低基數的例子，只有男與女。
  高隨機性的片鍵 : 具有越高隨機性的片鍵，他所分割出來的資料越容易均衡，也代表可避免任何一個分片承受過多的壓力。 可以指向單個分片的片鍵 : 越可指向單個分片的片鍵，越能降低搜尋效能壓力，像是隨機型的片鍵就無法做到。  這世界沒有著麼美好的事情，基本上幾乎找不到完全符合上述的條件，所以相對的咱們只能選擇盡可能符合你需要的片鍵，而這時就只能根據你專案的需求來決定，例如說這專案是讀吃比較重還是寫吃比較重，比較最大的搜尋條件，或搜尋時間過久的搜尋，這時都是要考量的。
~ 一些片鍵的種類 ~ 這邊開始我們就要來說明一些片鍵的種類。
升序片鍵 這種類型的片鍵，大部份都是欄位為Date類型或是ObjectId，是種會根據時間來增加欄位，或是根據先後順序進來的欄位。
假如我們使用這種欄位做為片鍵，會發生什麼事情 ? 一開始建立片鍵時你不會看到什麼問題，而是再於你新增時會發生，假設我們有下面的分片cluster。
   shard001 shard002 shard003     {min~2000} {2007~2008} {2014~2016}   {2001~2003} {2009~2010} {2017~max}   {2004~2006} {2011~2013}     然後這時我們要問個問題，我們進行新增時，它會加到那個chunk?</description>
    </item>
    
    <item>
      <title>30-24之MongoDB分片Sharding(2)---Chunk的札事</title>
      <link>https://mark-lin.com/posts/20160924/</link>
      <pubDate>Sat, 24 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160924/</guid>
      <description>在上一篇文章中說明完基本的分片概念後，我們本章節要更深的了解分片內的chunk， 它是每個分片組成的東西，我們這篇將要說明它的拆分與分配機制。
 chunk的分配與拆分。  ~ chunk 的分配與拆分 ~ 在上一篇文章中，我們知道每個分片中都包含了多個chunk，而每chunk中，又包含了某個範圍的document組，我們先簡單來畫個圖複習一下。
然後我們接下來要討論的就是，mongodb是如何拆分chunk和如何將chunk分片到shard裡，首先我們先來看看chunk的拆分。
chunk 的拆分 首先我們先想一下，chunk它本身是一堆document的集合體，大概長降,我們使用上一章節的範例，來看一下chunk的詳細資訊，假設我們都已經分片好了，我們直接看結果。
首先我們需要先移動到一個名為config的資料庫。
use config &amp;gt; switched to db config 然後再執行db.chunks.find().pretty()來看一下，目前只有一個chunk，它目前窩在shard0000，而它的範圍是min ~ max，呃對了忘了說，我們的資料是1萬筆的{&amp;quot;name&amp;quot;:&amp;quot;user&amp;quot;+i}這種物件。
這時我們要問個問題囉，它什麼時後會再分成另一個chunk ?
答案是chunk的大小，mongodb預設chunk最大限制為64MB，當超過時mongos會將它拆分為兩塊chunk，如下圖，此圖為官方圖片。
預設是64MB，當然我們也有辦法修改預設，指令如下，下面32代表為32MB。
use config &amp;gt; switched to db config db.settings.save({&amp;#34;_id&amp;#34; : &amp;#34;chunksize&amp;#34; : &amp;#34;value&amp;#34; : 32}) 但是這邊要修改大小時有幾點要思考一下。
 chunk 越小時可以使分片的可以使分片的資料量更均衡，不會有差距太大的狀況，但缺點就是，因為小所以會常移動chunk，所以mongos壓力會比較重。
 chunk 的拆分實驗 咱們來簡單的測試看看chunk的拆分，首先來建立一些資料，大小約為4188890 byte大概為4mb左右，然後我們的chunk大小預設為1mb，所以理論上應會開拆為3~4個chunk。
var objs = []; for (var i=0;i&amp;lt;100000;i++){ objs.push({&amp;#34;name&amp;#34;:&amp;#34;user&amp;#34;+i}); } db.users.insert(objs); 建好後別忘了執行這兩個指令。
db.users.ensureIndex({&amp;#34;name&amp;#34;:1}) sh.shardCollection(&amp;#34;test.users&amp;#34;,{&amp;#34;name&amp;#34;:1}) 然後我們指行sh.status()來看看結果，呃我淚囉為什麼會拆分為8個……
我們來檢查一下chunk size的設定，如下圖嗯沒錯~是1。
use config db.</description>
    </item>
    
    <item>
      <title>30-23之MongoDB分片Sharding---Hello Sharding</title>
      <link>https://mark-lin.com/posts/20160923/</link>
      <pubDate>Fri, 23 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160923/</guid>
      <description>本篇文章將要說明 mongodb 的分片`，上一章節說明了如何將資料同步到其它台節點上，而本篇文章是將要說明，如何將資料分割到其它台節點，讓我們可以更快速、更多容量空間的來做一些哩哩扣扣的事情。
 分片原理。 分片實作。  ~分片原理~ 分片是啥 ? 它主要的概念就是將collection拆分，將其分散到不同的機器，來分擔單一server的壓力。
咱們先來看看我們平常單一server的mongodb結構，其中mongod就代表我們實際上存放資料的地方，它平常都是指令和client端通信，client就有點像咱們平常用的mongodb shell之類的。
而咱們在來看看，如果用了分片會變啥樣，如下圖，三個mongod都會統一通信到mongos，在和client進行通訊，mongos不存儲任何資料，它就是個路由server，你要什麼資料就發給它，它在去決定去那個mongod裡尋找資料。
那這邊有個問題來囉~這三個mongod要著麼決定誰要存放那些資料 ? 答案是下面標題片鍵~
片鍵 Shard Keys 片鍵是啥 ? 它就是當你要進行分片時，你選定的collection切分的依據，假設我們有下面的資料。
{ &amp;quot;name&amp;quot;:&amp;quot;mark&amp;quot; , &amp;quot;age&amp;quot; :18} { &amp;quot;name&amp;quot;:&amp;quot;steven&amp;quot; , &amp;quot;age&amp;quot; :20} { &amp;quot;name&amp;quot;:&amp;quot;ian&amp;quot; , &amp;quot;age&amp;quot; :20} { &amp;quot;name&amp;quot;:&amp;quot;jack&amp;quot; , &amp;quot;age&amp;quot; :30} { &amp;quot;name&amp;quot;:&amp;quot;stanly&amp;quot; , &amp;quot;age&amp;quot; :31} { &amp;quot;name&amp;quot;:&amp;quot;jiro&amp;quot; , &amp;quot;age&amp;quot; :32} { &amp;quot;name&amp;quot;:&amp;quot;hello&amp;quot; , &amp;quot;age&amp;quot; :41} { &amp;quot;name&amp;quot;:&amp;quot;world&amp;quot; , &amp;quot;age&amp;quot; :52} ... ... { &amp;quot;name&amp;quot;:&amp;quot;ho&amp;quot;,&amp;quot;age&amp;quot; : 100} 它就有可能會分片成這樣，假設咱們拆分為三片，然後我們指定片鍵為age欄位，它就大致上可能會分成這樣，會根據片鍵建立chunk，然後再將這堆chunk分散到這幾個分片中，{min~10}就是一個chunk，就是一組document。</description>
    </item>
    
    <item>
      <title>30-22之MongoDB的副本集 replica set(2)---使用Docker建立MongoDB Cluster</title>
      <link>https://mark-lin.com/posts/20160922/</link>
      <pubDate>Thu, 22 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160922/</guid>
      <description>上篇文章我們已經說明完，如何在本機上建立 mongodb 副本集，而本篇文章，我們將要實際的使用docker來建立有三個節點的副本集，也就是所謂 cluster 。
 開始前的準備 建立架構圖 fight !  ~開始前的準備~ 首先再開始之前你當然要先將docker裝好，可以參考下面這章，但你的docker compose那邊可以不用做到，因為我還沒研究出，如何用docker compose來建立cluster……QQ。
 30-2之使用Docker來建構MongoDB環境
 確定執行docker --version有類似下面的資訊出來就ok囉。
Docker version 1.12.3, build 6b644ec 接下來呢咱們需要下載mongodb image，平常我們都是用docker compose直接執行它都會幫我們偷偷下載好，而現在我們就需要自已下載，指令如下。
docker pull mongo 然後咱們就都準備好囉。
~建立架構圖~ 我們來看看下圖，首先我們會先建立一個cluster取名為my-mongo-cluster，然後裡面有三個mongodb並且對外連接port設為30001、30002、30003，並且這三個的container都可以互相溝通。
~建立流程~ Fight !
step1 將my-mongo-cluster加入到docker network裡 我們先執行看看docker network ls然後會出現下圖的列表。
然後我們再執行下面的指令將新增個network到docker network裡。
docker network create my-mongo-cluster 然後你就可以看到我們將my-mongo-cluster加入至docker network裡。
Step2 建立三個 MongoDB 的 Container，並加入至 my-mongo-cluster 這 network 中 首先來看看指令，然後我們來解釋一下每個指令是啥意思。
 docker run : 就只是執行docker而以。 -p 30001:27017 : 將port:27017暴露出來，為了讓其它mongodb可連接到，而30001則為該container的本機port。 --name mongo1 : 將該container命名為mongo1。 --net my-mongo-cluster  : 將該container加入到my-mongo-cluster這docker network裡面，然它們可以互相通信。 mongo mongod --replSet my-mongo-set : 運行mongod時將該mongo加入到名為my-mongo-set的副本集中。  docker run -p 30001:27017 --name mongo1 --net my-mongo-cluster mongo mongod --replSet my-mongo-set 記好上面這些是要縮成一行來執行，如下。</description>
    </item>
    
    <item>
      <title>30-21之MongoDB的副本集 replica set(1)</title>
      <link>https://mark-lin.com/posts/20160921/</link>
      <pubDate>Wed, 21 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160921/</guid>
      <description>本篇文章將要說明， mongodb 的副本集。嗯~想想一個情況，現在咱們只使用一台 server 來存放資料，我們現在只是測試和開發， GG 囉也只是啊一聲，但如果是正式上線環境呢 ? GG 囉可不是啊一聲就可以解決的，你可能就被老闆不要不要的，很慘的~ 而副本集就是用來解決這問題，事實上也就只是被備份。
 副本集原理 副本集建立(單機版給你好測試)  ~副本集原理~ 首先我們先看看mongodb官網所提供的圖。
上面這張圖，你可以想成這個系統它有三個mongodb，其中primary節點接受所有client端的讀或寫，整個副本集只有一個primary，並且每當有資料新增時，primary會同步到其它兩個secondary。
然後當primary節點GG的話，會變成下面這張圖的結果(一樣來至官網)。
在這裡面，各節點都是通過一個叫心跳請求(heartbeat request)的機制來通信，如果當primary節點如果在10秒內無法和其它節點進行通信，這系統會自動從secondary節點中選取一個當主節點。
~副本集建立~ 在上面大概簡單的了解完它的原理後，我們就實際上的來操作看看，首先我們執行下面指令， 來進行到沒有db的mongodb shell環境。
mongo --nodb 然後通過下面的指令，就可以建立一個副本集，其中nodes : 3代表三個節點，一個primary其它兩個為secondary。
replicaSet = new ReplSetTest({&amp;quot;nodes&amp;quot;:3}) 不過執行完上面這行指令它還沒啟動喔還需要執行下面兩行，startSet為啟動那三個節點的進程，而initiate為設定複制功能。
replicaSet.startSet() replicaSet.initiate() 當執行完上面兩行後，我們就要跳到另一個Shell，然後連接到primary的節點，喲~?那它的port是啥?雖然有些文章中說預設是31000、31001、31002但我的電腦卻不是，所以建議還是在執行startSet時看一下，它應該會輸出下面這張圖的資訊。
嗯看到了吧，通常第一個就是primary，不是的話就試試其它的，然後我們這時就可以執行下面指令進入到它的裡面了。
conn1 = new Mongo(&amp;#34;127.0.0.1:20000&amp;#34;) 接下來我們就可以執行一些指令來看看這個副本集的狀態。
primaryDB = conn1.getDB(&amp;#34;test&amp;#34;) primaryDB.isMaster() 結果如下，其中isMaster這欄位就是說明這節點是primary節點。
~驗證一下有沒有備份到 secondary 節點~ 首先我們先新增一些資料。
var objs = []; for (var i=0;i&amp;lt;10;i++){ objs.push({&amp;#34;name&amp;#34;:&amp;#34;user&amp;#34;+i}); } primaryDB.users.insert(objs); 然後我們這時連到secondary。
conn2 = new Mongo(&amp;#34;127.0.0.1:20001&amp;#34;) 進去後在輸入。
secondaryDB = conn2.</description>
    </item>
    
    <item>
      <title>30-20之MongoDB運用研究---PO文情境模擬(3)</title>
      <link>https://mark-lin.com/posts/20160920/</link>
      <pubDate>Tue, 20 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160920/</guid>
      <description>上篇文章中，基本上已經把po文的方法，大部份都完成了，也建立好了索引，並且也將po文常見的搜尋給實作出來，接下來本篇文章，我們將要站在資料分析者的角度，使用聚合工作Aggregate framework與MapReduce來進行一些分析案例，一樣為了怕使用者忘記需求，我們還是再再貼一次~~
~需求說明~ 我們這邊想要簡單的模擬FB的貼文，我們可以新增貼文或做一些事情，並且我們希望還可以進行一些貼文分析，最後這項模擬會建立在有100萬筆下貼文的情況下，所以我們簡單的先列出我們可以用的功能。
 使用者可以簡單的新增發文，並且會存放Text、Date、Author、likes、Message。(完成) 建立100萬筆模擬po文。(完成) 使用者可以刪除發文。(完成) 使用者可以對自已的po文進行更新。(完成) 使用者可以進行留言和刪除留言。(完成) 使用者可以like發文。(完成) 使用者可以根據Text、Author、likes、Date進行搜尋。(完成) 管理者可以速行分析個案(已經想到囉如下)  ~分析個案 (需求8)~  Boss希望可以知道最多人留言的貼文，並且該貼文中前三位留言最熱絡的使用者，並計算留言次數。 Boss想知道最近貼文中最長出現的『單詞』是啥 ? 可以讓老大知道最近最熱門的東西 ~  嗯……才兩個好像有點少，但你往下來就知道可以寫很多了，都是要動腦想三下著麼做的啊……
1. Boss希望可以知道最多人留言的貼文，並且知道該貼文中，前三位留言最熱絡的使用者，並計算留言次數。 首先先來解決這需求，仔細看看不太難，將需求拆解成如下步驟就好。
 將每筆貼文的留言數量計算出來，並存放在messagesCount這變數中。 根據messagesCount進行排序。 將排序好的資料取第一個。 在將messages中的author來進行分組統計，並將結果存放在count中。 在針對count進行排序，取前三名。 交給Boss看……  根據以上的步驟我們使用mongodb的aggreagate framework來寫出下列程式碼，啊咧啊咧…… 著麼只寫到步驟2的排序…… ?
db.posts.aggregate( { &amp;#34;$project&amp;#34; : { &amp;#34;messagesCount&amp;#34; : { &amp;#34;$size&amp;#34; : &amp;#34;$messages&amp;#34; } } }, { &amp;#34;$sort&amp;#34; : { &amp;#34;messagesCount&amp;#34; : 1} } ) 因為GG了，咱們的排序所耗用的記憶體超過mongodb的限制囉，請看下圖~
網路上有人推薦說，在建立document時就多建立一個欄位，來存放它的數量，然後直接建立索引，但在我們這邊是會GG掉的，因為我們的留言隨時都在變，而且沒新增或刪除個留言都還要去對那個存放欄位進行更新，而且還有索引，這樣會讓咱們的效能大大的下降，所以在這應用中否定這選項~
那要著麼辦呢 ? 後來又查到一個方法，那就是allowDiskUse 參數，mongodb有個限制在Pipeline的階段中，規定記憶體只能用100mb，不然就會跳出上圖的錯誤，但如果將allowDiskUse設定為true，則它多出來的資料暫存寫入到臨時的collection，只是會不會有什麼問題或壞處，官網上都沒特別提到……
繼續正題，然後解決完這個sort的問題後，我們就可以使取得貼文的留言數最多的貼文。
db.posts.aggregate( [ { &amp;#34;$project&amp;#34; : { &amp;#34;messagesCount&amp;#34; : { &amp;#34;$size&amp;#34; : &amp;#34;$messages&amp;#34; },&amp;#34;messages&amp;#34; : 1 } }, { &amp;#34;$sort&amp;#34; : { &amp;#34;messagesCount&amp;#34; : -1}}, { &amp;#34;$limit&amp;#34; : 1} ], { allowDiskUse: true } ) 咱們再繼續往下寫，取得了最多留言數的貼文後，我們要繼續來尋找留言最多的人是那位，我們先使用$unwind將messages的陣列欄位，拆分成多個document，以方便我們用來group，再下來我們就可以根據messages的author來進行分組，並且計算每一組的數量存放至count來欄位。</description>
    </item>
    
    <item>
      <title>30-19之MongoDB運用研究---PO文模擬情境(2)</title>
      <link>https://mark-lin.com/posts/20160919/</link>
      <pubDate>Mon, 19 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160919/</guid>
      <description>上篇文章中，咱們已經將資料都建立好了，也完成了第一個需求，使用者可以進行PO文，並且我們建立出了模擬資料共一百萬筆，大約1gb的大小，接下來我們這篇文章將繼續完成需求，為了怕讀者們忘了需求，所以還是在貼一次。 
~需求說明~ 我們這邊想要簡單的模擬FB的貼文，我們可以新增貼文或做一些事情，並且我們希望還可以進行一些貼文分析，最後這項模擬會建立在有100萬筆下貼文的情況下，所以我們簡單的先列出我們可以用的功能。
 使用者可以簡單的新增發文，並且會存放Text、Date、Author、likes、Message。 (完成) 建立100萬筆模擬po文。(完成) 使用者可以刪除發文。 使用者可以對自已的po文進行更新。 使用者可以進行留言和刪除留言。 使用者可以like發文。 使用者可以根據Text、Author、likes、Date進行搜尋。 管理者可以進行分析個案(那些個案之後再想)  以下的步驟不代表上述列表的序號，而只是我們完成這需求的過程。
Step5 (需求3) 使用者可以刪除發文 這個刪除的方法事實上不太難，使用者只要輸入該po文的objectId就可以進行刪除，當然如果是實際有畫面的當然是直接給你選你要刪除的發文，不會還叫你輸入objectId，程式碼如下。
db.posts.remove ({&amp;quot;_id&amp;quot; : &amp;quot;xxxxxxx&amp;quot;}) 不過在使用刪除時有些事情也要想一下，如果是指定objectId來刪除，理論上來說只會刪除一個，並且速度很快，因為objectId系統會自動的幫我們建立索引，但如果是其它的query則可能要根據情況來考慮要不要建立索引，來幫助刪除的更快速，並且如果要刪除多筆資料別忘了使用bulk。
var bulk = db.posts.initializeUnorderedBulkOp(); bulk.find( { &amp;quot;name&amp;quot;: &amp;quot;mark&amp;quot; } ).remove(); bulk.execute();  刪除方面可以看看這篇文章來複習複習 ~
 Step6 (需求4) 使用者可以對自已的po文進行更新 這個也很easy~，就只是針對它的objectId進行搜尋然後更新就好，在做的過程中我們需要使用修改器$set，它的功能就是只針對指定的欄位進行修改~別忘囉~ ,
db.posts.update({&amp;quot;_id&amp;quot;:&amp;quot;XXXXX&amp;quot;}, {&amp;quot;$set&amp;quot; : { &amp;quot;text&amp;quot; : &amp;quot;Hello World&amp;quot; } )  更新複習請看這篇~
 Step7 (需求5) 使用者可以針對po文進行留言和刪除 先來回想一下我們的posts結構長啥樣子，如下~
{ &amp;quot;id&amp;quot; : 1, &amp;quot;text&amp;quot; : &amp;quot;XXXXXX&amp;quot;, &amp;quot;date&amp;quot; : &amp;quot;20160101&amp;quot;, &amp;quot;author&amp;quot; : &amp;quot;mark&amp;quot; , &amp;quot;likes&amp;quot; : 1, &amp;quot;messages&amp;quot; : [ {&amp;quot;author&amp;quot; : &amp;quot;steven&amp;quot; , &amp;quot;msg&amp;quot; : &amp;quot;what fuc.</description>
    </item>
    
    <item>
      <title>30-18之MongoDB運用研究---PO文模擬情境(1)</title>
      <link>https://mark-lin.com/posts/20160918/</link>
      <pubDate>Sun, 18 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160918/</guid>
      <description>咱們來細數一下，我們在前面的幾篇學了那些東西~
 mongodb 的新增、刪除、更新、搜尋。 mongodb 的索引運用。 mongodb 的資料分析工具 Aggregate 聚合。 mongodb 的設計。  是的~雖然看起來很少，但基本上基礎都差不多學會了，接下幾篇我們將要實際上的寫寫程式，來將我們之前學習到的東西都複習一次。
~需求說明~ 我們這邊想要簡單的模擬FB的貼文，我們可以新增貼文或做一些事情，並且我們希望還可以進行一些貼文分析，最後這項模擬會建立在有100萬筆下貼文的情況下，我們簡單的先列出我們要做的需求。
 使用者可以簡單的新增發文，並且會存放Text、Date、Author、likes、Message。 建立100萬筆模擬po文。 使用者可以刪除發文。 使用者可以對自已的po文進行更新。 使用者可以進行留言。 使用者可以like發文。 使用者可以根據Text、Author、likes、Date進行搜尋。 管理者可以速行分析個案(那些個案之後再想)  以下的步驟不代表上述列表的序號，而只是我們完成這需求的過程。
Step1 . 先想想 MongoDB 的架構 首先咱們先來想想，我們應該會有一個collection是會存放貼文資料，我們就取名為posts，然後再想想他裡面大概會長成啥樣，應該是如下的json。
{ &amp;quot;id&amp;quot; : 1, &amp;quot;text&amp;quot; : &amp;quot;XXXXXX&amp;quot;, &amp;quot;date&amp;quot; : &amp;quot;20160101&amp;quot;, &amp;quot;author&amp;quot; : ?? , &amp;quot;likes&amp;quot; : 1, &amp;quot;message&amp;quot; : ?? } 這時應該遇到兩個問題，author與message的格式如何，author應該是比較簡單，應該只要建立者的name，但這時你要考慮一件事，要不要為使用者建立個users的collection，首先回答幾個以下幾個問題。
 使用者資料在其它地方會不會使用到 ? Ans:會的，在留言時會需要用到。 使用者是否會高的頻率修改name ? Ans:不會，頻率很低。  根據上述回答，第一點是建議正規化，而第二點則是建議反正規化，那麼要選擇那個呢? 因為我們這case比較注重搜尋的速度，所以建議選用『反正規化』，也就是如下的結構，而不另外建立users的collection。
{ &amp;quot;id&amp;quot; : 1, &amp;quot;text&amp;quot; : &amp;quot;XXXXXX&amp;quot;, &amp;quot;date&amp;quot; : &amp;quot;20160101&amp;quot;, &amp;quot;author&amp;quot; : &amp;quot;mark&amp;quot; , &amp;quot;likes&amp;quot; : 1, &amp;quot;messages&amp;quot; : ?</description>
    </item>
    
    <item>
      <title>30-17之MongoDB的設計---正規與反正規化的戰爭</title>
      <link>https://mark-lin.com/posts/20160917/</link>
      <pubDate>Sat, 17 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160917/</guid>
      <description>本篇文章將說要說如何設計mongodb的架構，讓你可以更快速的使用mongodb。
 資料庫的正規化(文鄒鄒)。 mongodb正規化與反正規化。 該選用那個方法呢 ?  ~ 正規化 ~ 在開始討論mongodb架構時，有個東西要先講講，那就是『正規化』與『反正規化』，有使用過資料庫的應該都有聽過這名詞，不過這邊還是來解釋解釋，順到回憶一下。
首先什麼是正規化呢 ? 根據wiki的定義。
 Database normalization is the process of organizing the fields and tables of a relational database to minimize redundancy and dependency.
 中文意思為。
 資料庫正規化就是指將關聯式資料庫的欄位與表單進行讓『資料重複性與相依性』能夠降到最低的組織過程。
 是的，真的很文鄒鄒，不過我們只要知道正規化的目的是解決資料的『重複性』與『相依性』這兩個點就夠囉，資料庫正規化有一些規則，每條規則都稱為『正規形式』，符合第一條規則就稱為『第一正規形式』，總共有不少條，但通常到『第三正規形式』就被視為最高級的正規形式， 下面來簡單的說明一下這幾條規則。
第一正規形式 以下條列為第一正規形式的規則，事實上重點還是在說『不要有重複群組』。
 刪除各個資料表中的重複群組。 為每一組關聯的資料建立不同的資料表。 使用主索引鍵識別每一組關聯的資料。  我們假設資料為每個人的交易資料，下表為違反正規化的資料結構，因為它有重複的群組Volume，並且也缺少主索引鍵來識別每一組關聯的資料。
   Name Date Volume     Mark 20160101 10 , -20   Jiro 20160102 -20 , 30   Ian 20160103 34 , -10    如果要符合第一正規形式大概要長的像降。</description>
    </item>
    
    <item>
      <title>30-16之MongoDB聚合(3)---潮潮的MapReduce</title>
      <link>https://mark-lin.com/posts/20160916/</link>
      <pubDate>Fri, 16 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160916/</guid>
      <description>前兩篇說明完 mongodb 所提供的第一種聚合工作 aggregate framework ，本篇文章將要說明 mongodb 所提供的第二種聚合工作， MapReduce` 嗯…只要有微微研究過大數據，應該都有聽個這個潮潮的名詞，尤其應該有不少人有看過這篇『我是如何向老婆解释MapReduce的？』，不過它原文版好像消失了，扣惜。
~MapReduce~ MapReduce是google所提出的軟體架構，主要用來處理大量的數據，而mongodb根據它的架構建構出可以在mongodb中使用的聚合工作，MapReduce它可以將一個複雜的問題拆分為多個小問題(map)，然後發送到不同的機器上，完成時再合併為一個解決方案(reduce)，簡單的畫張圖來看看。
但這個方法和aggregate framework有什麼差別 ?
 aggregate framework 提供較優透的性能。
MapReduce性能較差，但可提供更複雜的聚合功能。
 ~ Mongodb 的 MapReduce 使用~ mongodb中的MapReduce使用的方法如下。
db.collection.mapReduce( map, reduce, { &amp;lt;out&amp;gt;, &amp;lt;query&amp;gt;, &amp;lt;sort&amp;gt;, &amp;lt;limit&amp;gt;, &amp;lt;finalize&amp;gt;, &amp;lt;scope&amp;gt; } ) 其中參數的說明如下。
   參數 說明     map map函數，主要功能為產生key給reduce。   reduce reduce函數。   out 輸出結果集合的名稱。   query 在map前，可用query先進行篩選。   sort 在map前，可用sort進行排序。   limit 在map前，可限制數量。   finalize 可以將reduce的結果，丟給某個key。   scope 可以在js中使用變數。    實際應用1 ~ 根據 class 分組計算每組訂單收入 是的，這個例子我們在aggregate framework時有用過，事實上這種簡單的例子用MapReduce來解決，有點用到牛刀了，不過我們只是要看看如何使用，所以就不用在意太多囉。</description>
    </item>
    
    <item>
      <title>30-15之MongoDB聚合(2)---Pipeline武器庫</title>
      <link>https://mark-lin.com/posts/20160915/</link>
      <pubDate>Thu, 15 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160915/</guid>
      <description>在上一篇文章中說明了 pipeline 操作符號，接下來我們這篇要說明在操作符號內使用的 pipeline 表達式，它讓我們可以在pipeline 內進行計算、比較、字串修改等分析方法。
 數學表達式(mathematical expression) 日期表達式(date expression) 字串表達式(string expression) 邏輯表達式(logical expression)  ~ 數學表達式 ~ 以下列表為比較常用的數學表達式(全部在這)。
   表達式 說明     $add 接受多個表達式，然後相加。   $subtract 接受兩個表達式，用第一個減去第二個作為結果。   $multiply| 接受多個表達式，然後相乘。    $divide 接受兩個表達式，然後相除。   $mod 接受個表達式，然後相除取餘。    實際運用 ~ 我們想要知道訂單總收入是多少。 我們來看看實際上是如何運用，假設我們有下列資料，該資料為訂單資料。
{ &amp;#34;id&amp;#34; : 1 , &amp;#34;price&amp;#34; : 100 , &amp;#34;count&amp;#34; : 20, &amp;#34;discount&amp;#34; : 0 }, { &amp;#34;id&amp;#34; : 2 , &amp;#34;price&amp;#34; : 200 , &amp;#34;count&amp;#34; : 20, &amp;#34;discount&amp;#34; : 100 }, { &amp;#34;id&amp;#34; : 3 , &amp;#34;price&amp;#34; : 50 , &amp;#34;count&amp;#34; : 20, &amp;#34;discount&amp;#34; : 100 }, { &amp;#34;id&amp;#34; : 4 , &amp;#34;price&amp;#34; : 10 , &amp;#34;count&amp;#34; : 210, &amp;#34;discount&amp;#34; : 200 }, { &amp;#34;id&amp;#34; : 5 , &amp;#34;price&amp;#34; : 100 , &amp;#34;count&amp;#34; : 30, &amp;#34;discount&amp;#34; : 20 } 這個應用中，我們希望知道總收入是多少，以下為收入公式。</description>
    </item>
    
    <item>
      <title>30-14之MongoDB聚合(1)---Aggregate Framework的哩哩扣扣</title>
      <link>https://mark-lin.com/posts/20160914/</link>
      <pubDate>Wed, 14 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160914/</guid>
      <description>在前面幾篇都是說明如何尋找到你想要的東西，而在接下來的聚合章節中，我們將說來學習到如何使用聚合工具，來幫助我們分析更多資料，以下為本篇要說明的事情。
 聚合 (aggregate) 是啥 ? 有啥用。 Mongodb 聚合工具 Aggregate Framework。 管道 pipeline 操作符號。  ~ 聚合(aggregate)是啥?有啥用? ~ 在前面幾篇文章中，我們學會了mongodb的CRUD，以及使用索引讓我們搜尋、排序速度更快速，那我們接下來幾篇要學什麼?答案就是『分析』，是的，我們將資料存放進mongodb最終的目的就是要使用分析，而聚合就是能幫助我們分析的工具，它能處理數據記錄並回傳結果。
~ MongoDb 聚合工具之 Aggregate Framework ~ 在mongodb中提供了aggregate framework的聚合工具，使用方法如下，其中AGGREGATE_OPERATION就是指你每一次的處理過程。
db.collection.aggregate(AGGREGATE_OPERATION) 先不考慮mongodb的語言，下面就是一個聚合的範例，mongodb的aggregate framework主要是建立在聚合管道(pipeline)基礎下，而這管道就是可以一連串的處理事件，以下列範例中你可以想成管道中有四節，『將每篇文章作者與like數抓取出來』為第一節，然後它處理完會產生資料，會再丟給第二節[依作者進行分類]，直到最後產生結果。
db.collection.aggregate( [將每篇文章作者與like數抓取出來], [依作者進行分類], [將like數進行加總] [返like數前五多的結果] ) ~ 管道 pipeline 操作符號 ~ Aggregate framework提供了很多的操作符號，來幫助你進行複雜的操作，每個符號都會接受一堆document，並對這些document做些操作，然後再將結果傳至下一個pipeline直到最後結果出現。
project 使用$project可以用來選取document中的欄位，還可以在這些欄位上進行一些操作，或是新建欄位。 下面寫個簡單的使用範例。
首先我們有下列的資料。
{ &amp;#34;id&amp;#34; : 1, &amp;#34;name&amp;#34; : &amp;#34;mark&amp;#34;, &amp;#34;age&amp;#34; : 20, &amp;#34;assets&amp;#34; : 100000000 } 然後我們可以用$project來決定要那個欄位，我們選取id與name欄位。
db.user.aggregate({ &amp;#34;$project&amp;#34; : { &amp;#34;id&amp;#34; : 1, &amp;#34;name&amp;#34; : 1 }}) 結果如下，當然他的功能沒著麼單純，它還可以和很多東西搭配，晚點會說。</description>
    </item>
    
    <item>
      <title>30-13之MongoDB索引(3)---比較特別的索引使用</title>
      <link>https://mark-lin.com/posts/20160913/</link>
      <pubDate>Tue, 13 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160913/</guid>
      <description>本篇文章將要說明幾個比較特別索引使用的方法。
 索引陣列欄位 索引子欄位 全文索引  P.S 快要一半囉~~+u^13
~ 索引陣列欄位 ~ 假設你有下列資料，但發現搜尋fans裡的值很慢，你想要建立索引，要著麼建呢?
{ &amp;#34;name&amp;#34; : &amp;#34;mark&amp;#34; , &amp;#34;fans&amp;#34; : [&amp;#34;steven&amp;#34;,&amp;#34;jack&amp;#34;,&amp;#34;mmark&amp;#34;]} { &amp;#34;name&amp;#34; : &amp;#34;steven&amp;#34; , &amp;#34;fans&amp;#34; : [&amp;#34;max&amp;#34;,&amp;#34;jack&amp;#34;,&amp;#34;mmark&amp;#34;]} { &amp;#34;name&amp;#34; : &amp;#34;jack&amp;#34; , &amp;#34;fans&amp;#34; : [&amp;#34;steven&amp;#34;,&amp;#34;hello&amp;#34;,&amp;#34;mmark&amp;#34;]} 事實上就和之前幾篇建立索引一樣。
db.user.ensureIndex({&amp;#34;fans&amp;#34;:1}) 那我們在再假設資料如下。
{ &amp;#34;name&amp;#34; : &amp;#34;mark&amp;#34; , &amp;#34;fans&amp;#34; : [ {&amp;#34;name&amp;#34; : &amp;#34;a&amp;#34; , &amp;#34;age&amp;#34; :11}, {&amp;#34;name&amp;#34; : &amp;#34;b&amp;#34; , &amp;#34;age&amp;#34; :10}, {&amp;#34;name&amp;#34; : &amp;#34;c&amp;#34; , &amp;#34;age&amp;#34; :21}, ] }, { &amp;#34;name&amp;#34; : &amp;#34;steven&amp;#34; , &amp;#34;fans&amp;#34; : [ {&amp;#34;name&amp;#34; : &amp;#34;e&amp;#34; , &amp;#34;age&amp;#34; :10}, {&amp;#34;name&amp;#34; : &amp;#34;f&amp;#34; , &amp;#34;age&amp;#34; :20}, {&amp;#34;name&amp;#34; : &amp;#34;c&amp;#34; , &amp;#34;age&amp;#34; :21}, ] } 這時如果我們建立fans裡的name為索引，指令會如下。</description>
    </item>
    
    <item>
      <title>30-12之MongoDB索引(2)---複合索引的坑</title>
      <link>https://mark-lin.com/posts/20160912/</link>
      <pubDate>Mon, 12 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160912/</guid>
      <description>本文將會說明以下幾點。
 複合索引是啥~ 複合索引的運用與坑坑坑~  ~ 複合索引是啥 ~ 假設有下列資料。
{ &amp;#34;name&amp;#34; : &amp;#34;mark&amp;#34; , &amp;#34;age&amp;#34; : 20} { &amp;#34;name&amp;#34; : &amp;#34;mark&amp;#34; , &amp;#34;age&amp;#34; : 25} { &amp;#34;name&amp;#34; : &amp;#34;steven&amp;#34; , &amp;#34;age&amp;#34; : 30} { &amp;#34;name&amp;#34; : &amp;#34;max&amp;#34; , &amp;#34;age&amp;#34; : 15} 在上一篇文章中說到，如果要建立name的索引，是像下面這樣。
db.user.ensureIndex({&amp;#34;name&amp;#34; : 1}) 這時mongodb就會大致上~將索引建成如下。
索引目錄 存放位置 [&amp;quot;mark&amp;quot;] -&amp;gt; xxxxxxxx [&amp;quot;mark&amp;quot;] -&amp;gt; xxxxxxxx [&amp;quot;max&amp;quot;] -&amp;gt; xxxxxxxx [&amp;quot;steven&amp;quot;] -&amp;gt; xxxxxxxx 而所謂的複合索引事實上就是只是針對多個欄位建立索引，如下。
db.user.ensureIndex({&amp;#34;name&amp;#34; : 1 , &amp;#34;age&amp;#34; : 1}) 而mongodb就會建立索引如下。
索引目錄 存放位置 [&amp;quot;mark&amp;quot;,20] -&amp;gt; xxxxxxxx [&amp;quot;mark&amp;quot;,25] -&amp;gt; xxxxxxxx [&amp;quot;max&amp;quot;,15] -&amp;gt; xxxxxxxx [&amp;quot;steven&amp;quot;,30] -&amp;gt; xxxxxxxx ~ 複合索引的運用與坑坑坑 ~ 在前一篇文章中有說過，索引是把雙刃刀，建立的不好反而會浪費更多資源，而複合索引更是雙刃刀中連握把可能都有刀刃，以下舉個例子來說明~說明~</description>
    </item>
    
    <item>
      <title>30-11之MongoDB索引(1)的哩哩扣扣</title>
      <link>https://mark-lin.com/posts/20160911/</link>
      <pubDate>Sun, 11 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160911/</guid>
      <description>本篇文章將會說明以下幾點。
 什麼是索引? 索引的優點與缺點 索引的建立 索引與非索引搜尋比較 不要使用索引的時機  P.S +u^11鐵人們 ~ 事實上我已快gg了
~ 什麼是索引? ~ 索引是什麼?最常見的說法是，一本字典中，你要找單字，會先去前面的索引找他在第幾頁，是的這就是索引，可以幫助我們更快速的尋找到document，下面畫張圖來比較一下不使用索引和使用索引的搜尋概念圖。
~ 索引的優缺點 ~ 索引竟然可以幫助我們著麼快的找到目標，那是不是以後都用索引就好??著麼可能!~ 索引好歸好，但他就像雙刃刀，用的不好會gg的。
優點  搜尋速度更(飛)快 ~ 在使用分組或排度時更快 ~  缺點  每次進行操作(新增、更新、刪除)時，都會更費時，因為也要修改索引。 索引需要佔據空間。  使用時機 所以根據以上的優缺點可知，不是什麼都要建立索引的，通常只有下列時機才會使用。
 搜尋結果佔原collection越小，才越適合(下面會說明更清楚)。 常用的搜尋。 該搜尋造成性能瓶頸。 在經常需要排序的搜尋。 當索引性能大於操作性能時。  ~ 索引的建立 ~ 我們簡單建立個索引使用範例。
db.tests.insert( {&amp;#34;x&amp;#34; : &amp;#34;hello&amp;#34;} ) 然後這時我們建立x欄位的索引。
db.tests.ensureIndex({ &amp;#34;x&amp;#34; : 1 }) 然後我們可以達行下列指令，來查看有沒有建立成功。
db.tests.getIndexs() 結果如下，建立成功x的索引，其中_id那個是預設的，mongodb會自動幫objectId建立索引。
~ 索引與非索引搜尋比較 ~ 在mongodb中排序是非常的耗費內存資源，如果排序時內存耗費到32mb(這裡)，mongodb就會報錯，如果超出值，那麼必須使用索引來獲取經過排序的結果。
我們這裡建立些資料，來比較看看兩者的資源耗費不同點。
for (var i=0;i&amp;lt;100000;i++){ db.test.insert({ &amp;#34;x&amp;#34; : i }) } 然後建立x的索引。</description>
    </item>
    
    <item>
      <title>30-10之MongoDB新手村CRUD---搜尋之Cursor運用與搜尋原理</title>
      <link>https://mark-lin.com/posts/20160910/</link>
      <pubDate>Sat, 10 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160910/</guid>
      <description>本篇文章將要說明cursor的用法以及一些curosr的方法，可以搜尋後用來限制或排序結果的功能，以及說明一下在不考慮索引情況下find的搜尋原理。
 Cursor是啥 Cursor的方法 搜尋的原理  P.S 三分之一囉，也代表基本的mongodb的crud要Ending囉。
~ Cursor 是啥 ~ cursor是find時回傳的結果，它可以讓使用者對最終結果進行有效的控制，它事實上也就是Iterator 模式的實作。
除了可以控制最終結果以外，它另一個好處是可以一次查看一條結果，像之前insertMany時，他會一次回傳全部的結果，mongodb shell就會自動一直輸出，結果看不到後來執行的東西。
我們實際來看一下cursor的用法，首先我們還是要先新增一些資料。
for (var i=0;i&amp;lt;10;i++){ db.test.insert({x:i}) } 然後進行搜尋，並用一個變數cursor存放。
var cursor = db.test.find(); while (cursor.hasNext()){ obj = cursor.next(); print(obj.x + &amp;#34; ~呼呼~&amp;#34;) } 結行結果如下圖。
~ Cursor 的方法 ~ limit、skip、sort這三個是很常用的cursor方法，主要功能就是限制、忽略、排序。
limit 要限制find結果的數量可以用limit，不過注意limit是指定上限而不是指定下限， 使用方法如下，limit(10)就是代表最多只回傳10筆資料。
db.test.find().limit(10) skip 當你想要忽略前面幾筆，在開始回傳值時，就是可以用skip，使用方法如下，skip(10)，代表忽略前十筆，然後在開始回傳，不過注意『 skip如果數量很多時速度會變很慢 』。
db.test.find().skip(10) sort sort它主要就是將find出的資料，根據條件，進行排序。
例如假設我們有以下的資料。
{&amp;#34;name&amp;#34;:&amp;#34;mark&amp;#34; , age:20} {&amp;#34;name&amp;#34;:&amp;#34;steven&amp;#34; , age:25} {&amp;#34;name&amp;#34;:&amp;#34;max&amp;#34; , age:10} {&amp;#34;name&amp;#34;:&amp;#34;stanly&amp;#34; , age:40} {&amp;#34;name&amp;#34;:&amp;#34;crisis&amp;#34; , age:5} 然後我們希望可以根據age排序，由小到大，{age:1}代表由小到大，而{age:-1}則相反由大到小。</description>
    </item>
    
    <item>
      <title>30-9之MongoDB新手村CRUD---搜尋之陣列欄位與regex</title>
      <link>https://mark-lin.com/posts/20160909/</link>
      <pubDate>Fri, 09 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160909/</guid>
      <description>本篇文章將要說明其它幾個搜尋方法，包含如何搜尋document中的陣列欄位的值以及運用正規表達式regex 來進行搜尋。
 搜尋陣列內容 正規表達式搜尋  ~ 搜尋陣列內容 ~ 這邊我們將要介紹幾個陣列搜尋符號$all、$size、$slice。
   Tables Are     $all 當需要尋找多個元素節合的document時，就可以使用它   $size 當要尋找特定長度的陣列時，就可以用它~   $slice 可以指定回傳的陣列指定的範例 ex. 10就為前十條，-10就為後十條。   $elemMatch 它會只針對陣列，進行多組query。    假設情況我們collection中有下列document。
{&amp;#34;id&amp;#34;:&amp;#34;1&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;mark&amp;#34;, &amp;#34;fans&amp;#34;:[&amp;#34;steven&amp;#34;,&amp;#34;stanly&amp;#34;,&amp;#34;max&amp;#34;], &amp;#34;x&amp;#34;:[10,20,30]}; {&amp;#34;id&amp;#34;:&amp;#34;2&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;steven&amp;#34;, &amp;#34;fans&amp;#34;:[&amp;#34;max&amp;#34;,&amp;#34;stanly&amp;#34;], &amp;#34;x&amp;#34;:[5,6,30]}; {&amp;#34;id&amp;#34;:&amp;#34;3&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;stanly&amp;#34;, &amp;#34;fans&amp;#34;:[&amp;#34;steven&amp;#34;,&amp;#34;max&amp;#34;], &amp;#34;x&amp;#34;:[15,6,30,40]}; {&amp;#34;id&amp;#34;:&amp;#34;4&amp;#34;,&amp;#34;name&amp;#34;:&amp;#34;max&amp;#34;, &amp;#34;fans&amp;#34;:[&amp;#34;steven&amp;#34;,&amp;#34;stanly&amp;#34;], &amp;#34;x&amp;#34;:[15,26,330,41,1]}; 我們這時想要尋找 fans 中同時有 steven、max 的網紅 我們這時就可以使用$all。
db.user.find({&amp;#34;fans&amp;#34;:{&amp;#34;$all&amp;#34;:[&amp;#34;steven&amp;#34;,&amp;#34;max&amp;#34;]}}) 結果如下，應該是只找到mark、stanly這兩個人。
我們想要尋找 fans 總共有三位的網紅。 我們這時可以用$size，不過有點可惜的一件事，$size無法與搜尋條件(ex.$gte)使用，所以無法尋找3人以上之類的，通常要來實現這種需求就只能多加個欄位了。
我們來看看$size的使用方法。
db.user.find({&amp;#34;fans&amp;#34;:{&amp;#34;$size&amp;#34; :3}}) 我們希望尋找 mark 的第一個 fans。 $slice主要功能就是將陣列切割只回傳你指定的範例。</description>
    </item>
    
    <item>
      <title>30-8之MongoDB新手村CRUD---搜尋之find與搜尋操作符號</title>
      <link>https://mark-lin.com/posts/20160908/</link>
      <pubDate>Thu, 08 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160908/</guid>
      <description>前面幾篇已經說明完了新增、修改、刪除，最後咱們新手村之旅的尾巴將要說明搜尋，這個功能應該是我們最常會使用到的，請好好的學習。
 find方法基本說明 find的搜尋條件(含搜尋故事)  P.S +u^8~
find 方法基本說明 mongodb使用find來進行搜尋，它的第一個參數決定要那些資料，而第二個參數則決定要返回那些key。
基本的使用範例如下，首先我們先建立一些資料。
db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;mark&amp;#34;,&amp;#34;id&amp;#34;:&amp;#34;1&amp;#34;,&amp;#34;age&amp;#34;:20}); db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;steven&amp;#34;,&amp;#34;id&amp;#34;:&amp;#34;2&amp;#34;,&amp;#34;age&amp;#34;:20}); db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;jj&amp;#34;,&amp;#34;id&amp;#34;:&amp;#34;3&amp;#34;,&amp;#34;age&amp;#34;:25}); db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;bb&amp;#34;,&amp;#34;id&amp;#34;:&amp;#34;4&amp;#34;,&amp;#34;age&amp;#34;:20}); 我們想尋找到name為mark的document，並且我們希望回傳值只回傳id這個key就好，搜尋指令如下。
db.user.find({&amp;#34;name&amp;#34;:&amp;#34;mark&amp;#34;},{&amp;#34;id&amp;#34; :1 }) 搜尋結果如下，它只回傳了key id的內容，但是可以看到_id也被回傳回來，因為在默認情況下_id這個key會自動被傳回來，如果真的不想它也回傳回來可以下達下列搜尋指令。
db.user.find({&amp;#34;name&amp;#34;:&amp;#34;mark&amp;#34;},{&amp;#34;id&amp;#34; : 1,&amp;#34;_id&amp;#34;:0}) ~ find 的搜尋條件 ~ 這邊我們將要說明find常用搜尋條件，and、or、大於等於、大於、小於、小於等於、包含、不包含，有了這些條件我們就可以更方便的尋找你所需要的document。
這邊簡單的整理成一張表來對應操作符號。
   條件 操作符號     AND $and，另一種方法也可以直接在query中下{&amp;quot;key1&amp;quot;,&amp;quot;value1&amp;quot;,&amp;quot;key2&amp;quot;:&amp;quot;value2&amp;quot;}|   OR $or   NOT $not   NOR $nor   大於 $gt   大於等於 $gte   小於 $lt   小於等於 $lte   包含 $in   不包含 $nin    我們接下來會先產生幾筆測試資料，再來測試幾個搜尋故事。</description>
    </item>
    
    <item>
      <title>30-7之MongoDB新手村CRUD---刪除</title>
      <link>https://mark-lin.com/posts/20160907/</link>
      <pubDate>Wed, 07 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160907/</guid>
      <description>本篇文章將要來說明MongoDB的刪除方法，rmoeve、deleteOne、deleteMany、bulk，並且簡單的比較一下速有有何差別。
 MongoDB的刪除方法 比較一下速度  ~ MongoDB的刪除方法 ~ remove remove方法是mongodb裡最基本的刪除document的方法，但這邊要注意就算你刪除了 document它的index與預分配空間都不會刪除。
使用方法與參數如下
 justOne預設false，代表query到幾個就會刪除幾個，true則只會刪第一個。 witeConecern為拋出異常的級別。 collation是3.4版開始支持的功能，可依照語言定義來針對文字的內容進行解讀，再還沒支持collation前一徑依字節來對比。  db.collection.remove( &amp;lt;query&amp;gt;, { justOne: &amp;lt;boolean&amp;gt;, writeConcern: &amp;lt;document&amp;gt;, collation: &amp;lt;document&amp;gt; } ) 使用範例如下，我們來新增三筆資料，然後刪除掉steven該筆資料。
db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;mark&amp;#34;,&amp;#34;age&amp;#34;:23}); db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;steven&amp;#34;,&amp;#34;age&amp;#34;:23}); db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;jj&amp;#34;,&amp;#34;age&amp;#34;:23}); db.user.remove({&amp;#34;name&amp;#34;:&amp;#34;steven&amp;#34;}) 刪除所有資料 remove可以用來刪除collection的所有資料，但還有另一種方法也是刪除collection的所有資料，那就是drop，但它同時會將index給全部刪除。
兩種的使用方法如下。
db.user.remove({}) db.user.drop() deleteMany與deleteOne deleteMany與deleteOne也是刪除的方法一種，就一個是刪除多筆和一個是單筆，和remove不同點大概只差在回傳值上，至於速度上等等來trytry看。
使用兩種方法的參數如下，與remove也大至差不多。
db.collection.deleteMany( &amp;lt;filter&amp;gt;, { writeConcern: &amp;lt;document&amp;gt;, collation: &amp;lt;document&amp;gt; } ) 使用範例如下。
db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;mark&amp;#34;,&amp;#34;age&amp;#34;:23}); db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;steven&amp;#34;,&amp;#34;age&amp;#34;:23}); db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;jj&amp;#34;,&amp;#34;age&amp;#34;:23}); db.user.deleteMany({&amp;#34;name&amp;#34;:&amp;#34;steven&amp;#34;}) db.user.deleteOne({&amp;#34;name&amp;#34;:&amp;#34;jj&amp;#34;}) bulk delete bulk操作故明思意就是要來衝一下大筆資料刪除的效能方法。
使用方法如下。
//先新增二筆資料 var bulk = db.collection.initializeUnorderedBulkOp(); bulk.insert( { name: &amp;#34;mark&amp;#34;} ); bulk.</description>
    </item>
    
    <item>
      <title>30-6之MongoDB新手村CRUD---更新之陣列欄位攻略</title>
      <link>https://mark-lin.com/posts/20160906/</link>
      <pubDate>Tue, 06 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160906/</guid>
      <description>本篇文章將要說明陣列修改器 push，主要就是針對 document 中的陣列進行修改，同時他也可以搭配 each、slice、ne、addToSet、pop、pull 來使用。
 陣列更新修改器攻略  呼好多……
~ 陣列更新修改器攻略 ~ $push $push是陣列修改器，假如一個document中已經有陣列的結構，使用push會在陣列的尾末加入一個新元素，要是本來就沒有這個陣列，則會自動新建一筆。
使用方法如下範例，首先先新增一筆資料，然後新增加一個叫jack的fans。
db.user.insert({ &amp;#34;name&amp;#34; : &amp;#34;mark&amp;#34;, &amp;#34;fans&amp;#34; : [&amp;#34;steven&amp;#34;,&amp;#34;crisis&amp;#34;,&amp;#34;stanly&amp;#34;] }) db.user.update({&amp;#34;name&amp;#34;:&amp;#34;mark&amp;#34;}, {$push:{&amp;#34;fans&amp;#34; : &amp;#34;jack&amp;#34;} }) 結果如下圖。
$each $push一次新增只能新增一筆元素，而搭配$each就可以新增多筆。
使用方法如下範例，一樣首先新增一筆資料，然後這時我們一次新增三個fans分別為jack、landry、max。
db.user.insert({ &amp;#34;name&amp;#34; : &amp;#34;mark&amp;#34;, &amp;#34;fans&amp;#34; : [&amp;#34;steven&amp;#34;,&amp;#34;crisis&amp;#34;,&amp;#34;stanly&amp;#34;] }) db.user.update({&amp;#34;name&amp;#34;:&amp;#34;mark&amp;#34;}, {&amp;#34;$push&amp;#34; : {&amp;#34;fans&amp;#34; : {&amp;#34;$each&amp;#34; : [&amp;#34;jack&amp;#34;,&amp;#34;lnadry&amp;#34;,&amp;#34;max&amp;#34;]}}} ) 結果如下圖
$slice 如果你希望限制一個陣列的大小，就算多push進元素，也不要超過限制大小，這時你就可以用$slice，不過注意它是保留最後n個元素。
使用方法如下範例，新增一筆資料，然後我們希望fans人數不超過5人，但我們硬多塞一個人進去。
db.user.insert({ &amp;#34;name&amp;#34; : &amp;#34;mark&amp;#34;, &amp;#34;fans&amp;#34; : [&amp;#34;steven&amp;#34;,&amp;#34;crisis&amp;#34;,&amp;#34;stanly&amp;#34;] }) db.user.update({&amp;#34;name&amp;#34;:&amp;#34;mark&amp;#34;}, {&amp;#34;$push&amp;#34; : {&amp;#34;fans&amp;#34; : {&amp;#34;$each&amp;#34; : [&amp;#34;jack&amp;#34;,&amp;#34;lnadry&amp;#34;,&amp;#34;max&amp;#34;], &amp;#34;$slice&amp;#34; : -5 }}} ) 執行結果如下，可以看到第一位steven被刪除，只保留了最後5位。</description>
    </item>
    
    <item>
      <title>30-5之MongoDB新手村CRUD---更新</title>
      <link>https://mark-lin.com/posts/20160905/</link>
      <pubDate>Mon, 05 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160905/</guid>
      <description>本篇將要來說明MongoDB中更新文檔的方法，並且也同時會說明更新修改器的功能，它能幫助我們進行更有效率的更新。
 基本更新方法Update。 更新修改器 ($set、$inc)。 更新修改器效能比較。  ~ 基本更新方法Update ~ Update函數主要的功用就如同字面所說，更新~，而使用方法如下，query就是指你要先尋找更新的目標條件，update就是你要更新的值。而另外三個參考請考下列。
 upsert : 這個參數如果是true，代表如果沒有找到該更新的對像，則新增，反之則否，默認是false。 multi : 如果是false，則代表你query出多筆，他就只會更新第一筆，反之則都更新，默認是false( !注意multi只能在有修改器時才能用 )。 writeConcern : 拋出異常的級別。  db.collection.update( &amp;lt;query&amp;gt;, &amp;lt;update&amp;gt;, { upsert: &amp;lt;boolean&amp;gt;, multi: &amp;lt;boolean&amp;gt;, writeConcern: &amp;lt;document&amp;gt; } ) 下面來簡單示範一下用法。首先我們先新增三筆資料。
db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;mark&amp;#34;,&amp;#34;age&amp;#34;:23}); db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;steven&amp;#34;,&amp;#34;age&amp;#34;:23}); db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;jj&amp;#34;,&amp;#34;age&amp;#34;:23}); 然後我們將名字為mark這人的age改為18，指令如下，query為{&amp;quot;name&amp;quot;:&amp;quot;mark&amp;quot;}，query的詳細用法會在find那邊詳詳細細的說明。
db.user.update({&amp;#34;name&amp;#34;:&amp;#34;mark&amp;#34;},{&amp;#34;name&amp;#34;:&amp;#34;mark&amp;#34;,&amp;#34;age&amp;#34;:18}) 執行結果如下，不過誒……我只要更新age也，為啥要全部換掉?
~ 更新修改器 ( set、inc ) ~ 修改器 $set $set修改器主要的功用就是用來指定一個字段的值，不用像上面一樣整個替換掉。
所以如我們如果要將mark這位仁兄的age改為18只要下達下面的指令。
db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;mark&amp;#34;,&amp;#34;age&amp;#34;:23}); db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;steven&amp;#34;,&amp;#34;age&amp;#34;:23}); db.user.insert({&amp;#34;name&amp;#34;:&amp;#34;jj&amp;#34;,&amp;#34;age&amp;#34;:23}); db.user.update({&amp;#34;name&amp;#34;:&amp;#34;mark&amp;#34;},{&amp;#34;$set&amp;#34; : { &amp;#34;age&amp;#34; : 18} }) 執行結果如下，成功更新為age為18
修改器 $inc 假設一下情景，假如有個投票網站、或是要存放訪客數的功能，每次更新時都是要+1，這種時後就可以用$inc來更新你的document，理論上來說速度應該會優於$set，等會兒會來測試一下。
注意$inc只能用在數值類型，否則就會提示Modifier $inc allowed for numbers only。</description>
    </item>
    
    <item>
      <title>30-4之MongoDB新手村CRUD---新增之Bulk與新增效能測試</title>
      <link>https://mark-lin.com/posts/20160904/</link>
      <pubDate>Sun, 04 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160904/</guid>
      <description>本篇文章會運用上一篇提到的二種新增方法insert、insertMany，以及另一種新增方法Bulk來做執行速度比較 ; 由於insertMany在mongodb shell執行完會直接輸出結果，所以如果有1萬筆資料他就會一直跑一直跑……跑到天荒地老，看不到我用來計算執行時間的方法，所以本測試打算用node js來建立測試方法。
在開始測試之前，先介紹一下另一個新增方法Bulk Insert。
 Bulk Insert 方法 新增方法的效能測試  ~ Bulk Insert方法 ~ Bulk Insert在2.6版時發佈，它也是種新增方法，效能如何等等會比較，基本使用方法有分有兩Unordered Operations和Ordered Operations。
Ordered Operations Ordered Operations，mongodb在執行列表的寫入操作時，如果其中一個發生錯誤，它就會停止下來，不會在繼續執行列表內的其它寫入操作，並且前面的操作不會rollback 。
使用範例如下。
var bulk = db.collection.initializeOrderedBulkOp(); bulk.insert( { name: &amp;#34;mark&amp;#34;} ); bulk.insert( { name: &amp;#34;hoho&amp;#34;} ); bulk.execute(); Unordered Operations Unordered Operations，mongodb在執行列表的寫入操作時，如果其中一個發生錯誤，它不會停止下來，會繼續執行列表內的其它寫入操作，速度較快。
使用範例如下。
var bulk = db.collection.initializeUnorderedBulkOp(); bulk.insert( { name: &amp;#34;mark&amp;#34;} ); bulk.insert( { name: &amp;#34;hoho&amp;#34;} ); bulk.execute();  Ordered 與 Unordered我們在要如何選擇使用時機呢，記好只要有相關性的操作就要選擇用Ordered，而如果像是log之類的，流失一兩筆也是沒差，這時可以選用Unordered。
 ~ 新增方法的效能測試 ~ 建立測試環境 首先我們先建立個新的資料夾，然後在裡面執行npm init來產生package.</description>
    </item>
    
    <item>
      <title> 30-3之MongoDB新手村CRUD---新增</title>
      <link>https://mark-lin.com/posts/20160903/</link>
      <pubDate>Sat, 03 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160903/</guid>
      <description>安裝好MongoDB後，接下來本篇主要說明如何新增資料至MongoDB中，而用更精確的詞彙來說是，如何新增document至collection中。這邊我們會說明以下幾種MongoDB所的方法，來建立資料, 並說明這三種有何不同，而至於效能部份請看下篇~
 Insert InsertOne InsertMany  ~ Insert方法 ~ 單筆資料Insert insert函數可以將一個document建立到collection裡，我們這裡建立一個簡單的範例來看如何使用insert。
首先我們的需求是要建立一份使用者清單(collection)，然後可以存放多筆使用者資料(document)，我們假設使用者資料如下。
順到一提，mongodb自帶javascript shell，所以可以在shell執行javascript 一些語法。
user1 = { name : &amp;#34;Mark&amp;#34;, age : 18, bmi : 10 } 然後我們要將這筆document新增至user的collection裡。
db.user.insert(user1); 新增完後，我們可以執行find指令，來查看user這collection中的資料。
db.user.find() 程式執行過程如下圖，而回傳值如下，代表成功新增一筆。
WriteResult({&amp;#34;nInserted&amp;#34; : 1}) 多筆資料Insert Insert函數同時也可以執行多筆，但效能好不好下篇會有比較。其中注意insert有個參數ordered ，true時代表如果其中一筆資料有問題，它就會停止下來，後面的資料都不會新增，而false時，則代表不會停下來，後面的資料會繼續新增，預設是true。
我們用下面範例來看看使用方法。
var user1 = { name : &amp;#34;Mark&amp;#34;, age : 18, bmi : 10 }, count = 1000, users = []; for (var i=0;i&amp;lt;count;i++){ users.push(user1); } db.user.insert(users,{ordered:false}) 結果如下圖。
~ InsertOne方法 ~ InsertOne函數事實上用法和insert差不多，只有兩點不同，首先是回傳，insertOne會回傳你所建立的document的ObjectId，ObjectId是系統自動生成的，是唯一值，而第二點不同就如同它的名字，他只能一次新增一筆。</description>
    </item>
    
    <item>
      <title>30-2之使用 Docker 來建構 MongoDB</title>
      <link>https://mark-lin.com/posts/20160902/</link>
      <pubDate>Fri, 02 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160902/</guid>
      <description>由於網站上已經有很多mongodb的安裝方法，所以本篇將說明，如何使用Docker來建立可使用mongodb的環境，這也代表你的電腦只要有安裝docker，都可以使用mongodb，不再需要去找各種東西的安裝方法。
~ Step1. 安裝Docker ~ Mac安裝 https://docs.docker.com/docker-for-mac/
docker最開始時還沒支援mac，而是需要用到其它方法來使用，但現在已經有出docker-for-Mac了，但注意雖然他是穩定版，但在mac自動休眠後，常常發生Bad response from Docker engine……，這目前好像沒啥解法，只能reset docker 或 重開機 ……
Windows7 安裝 https://www.docker.com/products/docker-toolbox
雖然出了docker-for-windows但目前只支援windows10和Server 2016，windows7哭哭。
Windows10 安裝 https://docs.docker.com/docker-for-windows/
懶講。
Ubuntu 安裝 https://philipzheng.gitbooks.io/docker_practice/content/install/ubuntu.html
請參考這篇安裝。
~ Step2. 建立 docker-compose.yml ~ 在某個檔案夾下建立docker-compose.yml，並且內容如下，然後在執行docker-compose up指令，它就自動幫你建立一個裝有mongodb的環境。
version: &amp;#39;2&amp;#39; services: mongo: image: mongo ports: - &amp;#34;27017:27017&amp;#34; volumes_from: - mongodata mongodata: image: tianon/true volumes: - /data/db 下圖為在該檔案夾下執行docker-compose up結果。可以看到他建立一個port為27017並且資料存放在環境/data/db的mongodb。
~ Step3. 進入Docker Container裡操作 MongoDB ~ 在執行完docker-compose up後，換到另一個shell，然後你可以執行docker ps指令來確定有mongodb的container有沒有執行，你可以把container想成為一個很小的VM。
從下圖可知，執行docker ps後可看到你這台電腦有在執行的container，其中mongo就是我們剛剛執行的。
接下來我們就執行docker exec -ti 333fba82b57e bash，其中333fba82b57e為CONTAINER ID，如下圖，你就進入到這個container中囉。</description>
    </item>
    
    <item>
      <title>30-1 之 MongoDB 基礎知識</title>
      <link>https://mark-lin.com/posts/20160901/</link>
      <pubDate>Thu, 01 Sep 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160901/</guid>
      <description>Hello ~ 大家好 ~ 接下來的30天的文章，小的我將要說明如何從0 → 1開始來學習MongoDB，咱們這30天的文章結構大至上會如下。
 首先，先來個十篇的新手村之旅，大致上是說明MongoDB的基本操作CRUD。 再來開始進階一點，當我們上面十篇會基本上的使用MongoDB後，我們接下來就是要學習『如何用的好』，這時我們大概會花個六、七篇左右來說明說明。 然後我們這時要來『驗證』你上面的東西有沒有學會，我們大概會用個三篇來模擬個應用。記好『驗證』自已有沒有學會，是學習過程很重要的步驟，請別老是覺得看過懂了，就算學會，這種道理就像是你腦袋想的和寫出來的程式不見得會一樣，請記得寫測試驗證。 接下來就是進行分散式的章節，大概來個六~七篇。 最後就是一樣驗證你上面的東西有沒有學會。  上面大概就是這30天的簡略流程，那麼就開始吧。
由於是第一天，所以基本上就是要文言文一下，說明一下mongodb是啥。
 什麼是MongoDB MongoDB的優缺與缺點 MongoDB的組成Document與Collection  ~ 什麼是MongoDB ~ MongoDB一種強大，靈活、且易於擴展的文件導向式(document-oriented)資料庫，與傳統的關聯式導向資料庫相比，它不再有row的概念，取而代之的是document的概念，如下圖的fu。
~ MongoDB的優缺與缺點 ~ 優點  Schema-less : MongoDB擁有非常彈性的Schema，這對RDBMS來說非常的難以高效能的方法來實現。 易於擴展 : MongoDB的設計採用橫向擴展，它的document的數據模型使寫能很容易在多台伺服器之間進行數據分割。 優透的性能 : MongoDB能預分配，以利用額外的空間換取穩定，同時盡可能把多的內存用作cache，試圖為每次查詢自動選擇正確的索引。  缺點  不支援事務操作 : 所以通常不適合應用在銀行或會計這種系統上，因為不包證一致性。 占用比較多空間 : 主要是有兩個原因，首先是它會預分配空間，為了提高效能，而第二個原因是欄位所占用的空間。  ~ MongoDB的組成 Document 與 Collection ~ Document Document是mongodb的核心，它就是Key對應個Value組合，例如下列範例。
{ name : &amp;quot;mark&amp;quot;. age : 100 , title : &#39;Mark BIG BIG&#39; } document中的值可以是多種不同的類型，並且Key有幾個規定，首先它是區分大小寫，例如下面的範例這兩種是不同的，mongodb會存成兩份document。</description>
    </item>
    
    <item>
      <title>Cordova-Cordova Chrome Debug</title>
      <link>https://mark-lin.com/posts/20160210/</link>
      <pubDate>Wed, 10 Feb 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160210/</guid>
      <description>在寫網頁時，最常使用到Chrome來進行Debug，對開發非常的有幫助，但如果是在Cordova上呢?這篇文章就是要介紹如何時用Chrome來進行Cordova的Debug。
Step1 將模擬器的Developer USB Debug打開 首先打開你的模擬器，然後到Settings，然後往下拉，找找Developer options，發現著找不到，因為預設是隱藏的，喝喝。
所以要將它打開需要先到About Phone，然後你會看到Build number，這時就『點』下去，記憶中是要點3到4次，然後點完後在回去找Develper options。
發現Magic~Developer options出現了。
最後在將USB debugging打勾就可以了。
Step2 打開chrome://inspect/#devices 首先在Chrome上打chrome://inspect/#devices然後可以看有你的模擬器(記得模擬器要先打開)，但空空的沒地方點。
Step3 執行Corodva Anroid 則時就在你的專案上面執行Cordova run Android，確定有正確的執行後，在Devices你就會看到你執行的專案名稱，然後點一下Inspect，你就可以看到熟悉的Debug方法了。
你看看，親切~!
參考資料  http://geeklearning.io/apache-cordova-and-remote-debugging-on-android/  </description>
    </item>
    
    <item>
      <title>CSS-Box Model 觀念</title>
      <link>https://mark-lin.com/posts/20160201/</link>
      <pubDate>Mon, 01 Feb 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160201/</guid>
      <description>Css Box Model 規定了Element處理元素Content、Padding、border、margin的方式 。
Box Model基本概念 這張圖就是在說明一個Element元素的Box Model，紅色框範圍內表代為Element內的各屬性距離，而橘色框的代表Element與Element之間的距離。
來看看下列的Html與Css
&amp;lt;!--html --&amp;gt; &amp;lt;div class=&amp;#34;box1&amp;#34;&amp;gt;Box 1&amp;lt;/div&amp;gt; &amp;lt;div class=&amp;#34;box2&amp;#34;&amp;gt;Box 2&amp;lt;/div&amp;gt; -------------------------------- &amp;lt;!--Css --&amp;gt; .box1{ padding:10px; border: 5px solid red; margin:10px } 顯示如下，其中Box 1文字到框線的距離為padding 10px，然後框線的寬度為5px， 最後Box1和Box2的距離為margin 10px。
Chrome Tools 的 Elements Style 的結果如下。
Box Model的寬度 如果在一個Element設置width，那麼該Element的寬度是指Box Model的那個範圍呢??根據W3C的標準定義Content Width，如下面Css我們在增加width:500px屬性。
.box1{ width:500px; padding:10px; border: 5px solid red; margin:10px } 結果如下，width:500px所指的為content width，也就是Element的內容寬度。
Box-Sizing屬性 在上一段文章中有提到，在Element上增加width屬性實際上是指content width， 所以有時後有人會很疑惑，明明寬度設了500px或XXXpx卻還是超過，這往往是Box Model不熟悉的問題。
而Box-Sizing屬性的border-box值，就是指將width屬性從content width改成content + padding + border 的 with，如下Css，我們新增加了box-sizing : border-box。</description>
    </item>
    
    <item>
      <title>CSS-Position 觀念</title>
      <link>https://mark-lin.com/posts/20160202/</link>
      <pubDate>Mon, 01 Feb 2016 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20160202/</guid>
      <description>在上一篇Css Box Model討論完Element的大小問題，接來下來談談Element的位置(Position)問題，Css中可以對Element的Position屬性設置四種類型的值分別為static、relative、absolute、fixed。
Static static為position的預設值，它會在頁面上佔據位置，但不能使用top right bottom left移動Element。請看看下面範例。
HTML &amp;lt;div class=&amp;#34;test1&amp;#34;&amp;gt;Test1&amp;lt;/div&amp;gt; &amp;lt;div class=&amp;#34;test2&amp;#34;&amp;gt;Test2&amp;lt;/div&amp;gt; CSS	.test1 { position:static; background-color:red; top:100px; right:100px; } .test2 { background-color:green; } 從結果可看出Test1完全沒有移動，且有佔據位置，所以Test2會在Test1下面。
Relative relative為相對定位，元素在頁面上佔據位置，可使用top right bottom left移動Element。
其中所謂的相對定位概念可以想成，一個元素設置成相對定位，然後可以設置它垂直或水平的位置，讓這個元素相對於原本位置進行移動，並且會保留原本位置的空間。如下圖框2的原本位置空間會保留。
HTML &amp;lt;div class=&amp;#34;test1&amp;#34;&amp;gt;Test1&amp;lt;/div&amp;gt; &amp;lt;div class=&amp;#34;test2&amp;#34;&amp;gt;Test2&amp;lt;/div&amp;gt; CSS .test1 { position:relative; background-color:red; top:10px; left:10px; } .test2 { background-color:green; } 從下圖可知Test1，向下位移了10px，並向右移10px，但注意Test1原本的空間位置還在喔。
Absolute Absolute為絕對定位，相對於最近一級且不是static的父元素來進行定位。元素在頁面不占據位置，你可以想成他從頁面上浮起來，然後它移動的起使位置為父元素，可以使用top right bottom left移動元素位置，如下圖不會像相對定位一樣保留原本框2的空間與位置。
HTML &amp;lt;div class=&amp;#34;test1&amp;#34;&amp;gt;Test1&amp;lt;/div&amp;gt; &amp;lt;div class=&amp;#34;test2&amp;#34;&amp;gt;Test2 &amp;lt;div class=&amp;#34;test3&amp;#34;&amp;gt;Test3&amp;lt;/div&amp;gt; &amp;lt;/div&amp;gt; CSS
.test1 { height:30px; background-color:red; } .test2 { height:50px; position:relative; background-color:green; } .</description>
    </item>
    
    <item>
      <title>HTML5 之走在平行時空的 Web Worker</title>
      <link>https://mark-lin.com/posts/20151001/</link>
      <pubDate>Thu, 01 Oct 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20151001/</guid>
      <description>什麼是Web Worker？，它就是個運行在後台的Javascript，獨立於其它Script，並且不會影響效能，但它不能影響Dom、並不能訪問windows、Document、parent等物件。
Worker 主要的用處在避免重度 CPU 運算的任務阻礙到 UI 執行緒運行。
建立Worker 首先我們來建立worker，並且該獨立的script為work.js，並且在worker建立onmessage監聽器，當work.js有執行postMessage()，則會觸發。
var worker = new Worker(&amp;#39;work.js&amp;#39;); worker.onmessage = function(e){ console.log(e.data); } 下面這段程式碼為work.js，以下只是段簡單的兩秒後觸發postMessage()並回傳一段文字回去。
(fucntion(){ setTimeout(function(){ postMessage(&amp;#39;This work I spend 2s&amp;#39;); },2000); })(); 兩秒後執行結果就為。
	This work I spend 2s 在 Web Worker 中載入 Javascript 在Worker裡面如果要載入Javascript，則需要使用importScripts( &amp;quot;fileName.js&amp;quot; ) ，下列程式碼為使用範例。
importScripts( &amp;#34;work2.js&amp;#34; ) var work2Obj = work2Obj; (function(){ console.log(work2Obj.taskName); setTimeout(function(){ self.postMessage(&amp;#39;This work , I spend 2 s &amp;#39;); },2000); })() work2.js，如下程式碼。
var work2Obj = { taskName:&amp;#34;work2&amp;#34; } Web Worker的限制 有幾點要web worker的限制需要注意一下。</description>
    </item>
    
    <item>
      <title>Jquery 的 Promise 之 when 與 then ( pipe )</title>
      <link>https://mark-lin.com/posts/20150909/</link>
      <pubDate>Wed, 09 Sep 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150909/</guid>
      <description>在這篇文章中，我們將來說明一下when與then(pipe)的用法，這兩個方法都算是promise衍伸技術。
deferred.when 在實務上很常有這種要求，任務１與任務２這兩個非同步方法執行完成，再執行任務３，這時我們就可以運用when來完成這種類型的工作。
When相當與執行Promise情況的AND。也就是說一旦給定的所有Promise均已執行後，就立即執行when方法產生的Promise對象。而一旦任一個Promise被拒絕，則立即拒絕when產生的Promise。
下列程式碼為when的基本使用方法。
var promise1 = $.get(&amp;#39;/test1&amp;#39;); var promise2 = $.get(&amp;#39;/test2&amp;#39;); $.when(promise1,promise2).done(function(){ //promise1與promise2都完成時會執行的事情。 	}); 如果要取得promise1與promise2的回傳參數則如下程式碼，其中arg1為promise1的回傳參數，而arg2為promise2的回傳參數。
var promise1 = $.get(&amp;#39;/test1&amp;#39;); var promise2 = $.get(&amp;#39;/test2&amp;#39;); $.when(promise1,promise2).done(function(arg1,arg2){ //promise1與promise2都完成時會執行的事情。 	}); ##d eferred.then(.pipe)
從Jquery1.8開始，官網建議將deferred.pipe()由deferred.then()替代。
deferred.then()方法的回傳可以做以下兩件事。
 如果then回傳為promise物件，則then生成的promise物件會模仿這個promise物件。 如果then回傳為非promise物件，則then生成的promise物件會立即因該回傳值而執行、拒絕或通知，取決於then那個初使promise發生什麼事了。  來看看使用情況，假設某api回傳發生錯誤時，不是回傳http status XXX，而是回傳個Json如{error:true}之類的，由於promise是在http請求失敗時，才會觸發，因為我們會將處理錯誤流程寫在done裡。
$.get(&amp;#39;/getData&amp;#39;) .done(function(response) { if(response.error) { console.log(&amp;#39;Error&amp;#39;); }else { console.log(&amp;#39;Success&amp;#39;); } }) .fail(function(response) { console.log(&amp;#39;Error&amp;#39;); }); 上述程式碼，不是個好的解決方法，非得要在done做兩次判斷，因此我們這時就可以使用.then，來過濾Promise，如下程式碼。
var getData = $.get(&amp;#39;/getData&amp;#39;).then(function(response){ if(response.error) return $.Deferred().reject(response); else return response; },function(response){ return $.Deferred().reject(response); });	getData.</description>
    </item>
    
    <item>
      <title>Javascript非同步編程的方法 - Promise</title>
      <link>https://mark-lin.com/posts/20150908/</link>
      <pubDate>Tue, 08 Sep 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150908/</guid>
      <description>在上一篇介紹 PubSub 的方法後，發現該方法不適合處理一次性事件，而Promise就是用來解決該問題的手法。那什麼是Promise呢?，他是一種非同步操作的最終結果，你也可以把想成是未來的物件但是現在還不可用，在未來他會有多種狀況，可能是成功又或是失敗，當未來發生成功時他就執行成功的 callBack fucntion，但它失敗`時就執行失敗的callback function。
Promise/A+ 規範 上述說的promise只能說是一種概念，然後有很多人會針對它進行實作，但是因為都沒個規範，所以每個人做出來的promise都不太一樣，因此Kris Zyp提出了 CommonJs 的 promises/A 規範，符合條件如下。
規範 1 : Promise狀態 一個Promise必須要處於以下三種狀態。pending, fulfilled, or rejected
 pending : 當為Pending 狀態時，可以轉換至f fulfilled 或 rejected。 fulfilled : 通常是代表成功。 rejected : 通常代表失敗。  規範 2 : Promise必須要 Then 一個Promise必須提供Then方法，並且接受兩個參數，並且第一個參數onFulfilled為fulfilled執行後調用，而onRejected為rejected後調用。
promise.then(onFulfilled, onRejected) 其它詳細的規範其參考下面的連結。。
hpromises-spec
Jquery 的 Promise 實現 Jquery在1.5之後，我們常用的$.ajax、$.get、$.getJson等這些ajax函數全部都會返回promise，下面給個例子來看看差別。
versin 1.4 $.get(&amp;#39;/getData&amp;#39;, { success: onSuccess, failure: onFailure }); version 1.5 var promise = $.get(&amp;#39;/getData&amp;#39;); promise.done(onSuccess); promise.fail(onFailure); 這種改變的好處在於封裝，你可以將複雜非同步處理輕鬆的模式化，例如希望任務１與任務２完成時在執行任務３，或是任務１執行完在執行任務２這種複雜的非同步任務都可以用promise來解決。</description>
    </item>
    
    <item>
      <title>Javascript非同步編程的方法 - Pub/Sub</title>
      <link>https://mark-lin.com/posts/20150907/</link>
      <pubDate>Mon, 07 Sep 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150907/</guid>
      <description>發布與訂閱模式Pub/Sub它主要的概念為 :
 定義一對多的關係，當一件事情發布時會同時通知所有的訂閱者
 在 Javascript 與 Jquery 非常容易看到該模式的使用。例如 Jquery裡的on，下面的程式就可以想成，$(&#39;.SomeThing&#39;)為訂閱者，訂閱了click，如果click事件發生了，發布者就會執行doSomething。
$(&amp;#39;.SomeThing&amp;#39;).on(&amp;#39;click&amp;#39;fucntion doSomething(){ //doSomething 	}); 該模式的優點在於解耦合，發行者與訂閱者不需要知道對方的存在。
而使用的時機為當一個對象改變時，需要同時改變其它對象，但確不知道實際有多少個對象時，這種情況下，就可以考慮使用Pub/Sub模式。
Pub / Sub 簡單版範例 var EventHub = { topics: {}, subscribe: function(topic, handler) { if(!this.topics[topic]){ this.topics[topic] = []; } this.topics[topic].push(handler); }, publish: function(topic, data) { if(!this.topics[topic] || this.topics[topic].length &amp;lt; 1) return; this.topics[topic].forEach(function(listener) { listener(data || {}); }); } }; 然後就可以使用了，首先訂閱一個Task，並且當Task被觸發時，會自動執行task函數。
EventHub.subscribe(&amp;#39;Task&amp;#39;,function task(data){ console.log(data + &amp;#39;by Task1&amp;#39;); }); EventHub.subscribe(&amp;#39;Task&amp;#39;,function task(data){ console.log(data + &amp;#39;by Task2&amp;#39;); }); 然後在來觸發Task。</description>
    </item>
    
    <item>
      <title>Javascript 非同步編程的方法 - setTimeout</title>
      <link>https://mark-lin.com/posts/20150906/</link>
      <pubDate>Sun, 06 Sep 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150906/</guid>
      <description>在Javascript單線程與Javascript之Event Driven這兩篇文章中，我們大概了解了單線程與非同步事件的工作原理，在這篇中我們將會說明運用SetTimeout來處理非同步事件。
setTimeout基本用法 SetTimeout為Javascript的原生函數，主要的用法為在一個指定的延遲時間後執行某個函數。
下列程式碼為setTimeout的基本使用，代表在１秒鐘後執行console.log(&amp;ldquo;Hello&amp;rdquo;)。
setTimeout(function(){ console.log(&amp;#34;Hello&amp;#34;) },1000); 這邊要注意一點，雖然上面程式碼是設定１秒，但是Javascript為單線程，因此如過將程式碼修改如下，讓單線程被While阻塞，setTimeout就不會在1秒後執行，而是等while執行完在執行。
var start = new Date; setTimeout(function(){ var end = new Date; console.log(&amp;#39;Time elapsed:&amp;#39;, end - start, &amp;#39;ms&amp;#39;); }, 1000); while (new Date - start &amp;lt; 2000) {}; &amp;lt;!-- tas --&amp;gt; 輸出結果： Time elapsed: 2002 ms --- setTimeout ( 0 ) 的意思 SetTimeout為在一個指定的延遲時間後執行某個函數，所以如果帶入(0)，則是否意味馬上執行的意思?來看下面程式碼。
setTimeout(function(){ console.log(&amp;quot;Hello&amp;quot;); },0) console.log(&amp;quot;Mark&amp;quot;);  執行結果為： Mark Hello  嚴來來說不是立即執行，而是立即排進Task Quenu等待執行，等Call Stack空時它會至Task Quenu尋找工作，因此執行結果才為Mark Hello。
如果不知道Task Quenu或Call Stack可至該篇看Event Driven的觀念。 Javascript Event Driven</description>
    </item>
    
    <item>
      <title>Javascript 之 Event Driven</title>
      <link>https://mark-lin.com/posts/20150905/</link>
      <pubDate>Sat, 05 Sep 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150905/</guid>
      <description>在Javascript單線程該篇文章中有提到，大部份這種單線程但可以處理非同步的語言都有共同的特性那就是事件驅動(Event Driven)，它一般是由通過事件循環(Event Loop)與事件隊列（Event Queue）來實現。
事件驅動 ( Event Driven ) 與事件隊列（ Event Queue ） 先來說說事件驅動(Event Driven)，這種類型的程式執行流程基本上是由使用者的動作例如點擊了頁面或按了ENTER之類的事件來決定，而不像一些如批次程式設計（batch programming）是由程式開發者來決定。
我們來看看下面這張Philip Roberts在JSConf EU 2014講述Javascript event-loop時所出現的這圖。
首先左上角為V8 Javascript runtime，其中裡面的Stack代表JS接下來要做的事情（嚴格來說要做的任務被分配到的記憶體空間）由上至下來執行。Philip Roberts在演講中也有提到因javascript單線程而所擁有的等式。
 one thread == one call stack == on thing at time
 其中Stack裡面的工作有些是非同步事件，例如ajax或settimeout等，stack會將工作丟給WebApis該區塊進行（嚴格來說是ｖ８中某個東西會丟），等到執行完後成，會發送個callback給callbackQueue，等到Stack完全清空時，會至callback queue裡尋找看看有沒有callback要執行。
Javascript程式碼單線程運行流程範例 我們將以下列這段簡單的程式碼來看Javascript的執行流程。
console.log(&amp;#34;hi&amp;#34;) setTimeout(function cb(){ console.log(&amp;#34;there&amp;#34;); },5000); console.log(&amp;#34;Mark Lin&amp;#34;); 首先為第一張圖，在還沒執行程式程式碼時，所有的Stack與Task Quenu都是空的。 然後我們開始執行，首先載入這段JS，Stack會產生main()這個區塊，再執行到 console.log(&#39;hi&#39;)時，也會在Stack產生console.log(&#39;hi&#39;)的區塊，並在Console印出hi，最後console.log(&#39;hi&#39;)工作完成，會從Stack中釋放出。
執行到setTimeoout，Stack會產生setTimeout的區塊，並且會向api發送工作，然後繼續往下執行。
執行console.log(&amp;quot;Mark Lin&amp;quot;)，最後工作剛成後，Stack全部清空。
Stack全部空間釋放完後，同時也發現剛剛對api的請求已完成，並且已將CallBack cb放置Task Quenu，並且由於Stack已清空，它會自動去Task Quenu尋找Task，這時發現了Cb然後就執行consoel.log(&amp;quot;there&amp;quot;)。
參考資料  https://www.youtube.com/watch?v=8aGhZQkoFbQ https://vimeo.com/96425312 http://www.ruanyifeng.com/blog/2014/10/event-loop.html  </description>
    </item>
    
    <item>
      <title>Javascript 之單線程</title>
      <link>https://mark-lin.com/posts/20150904/</link>
      <pubDate>Fri, 04 Sep 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150904/</guid>
      <description>首先看看下面的程式碼，會發現永遠跑不出So sad，因為Javascript為單線程，雖然設定１秒過後isEnd為false，然後應該就直接跑出So sad，但因為被while一直佔住線程，因此永遠不會執行setTimeout事件，與console.log(&amp;ldquo;So sad&amp;rdquo;) 。
setTimeout(function () { isEnd = false; }, 1000); while (isEnd); console.log(&amp;#34;So sad&amp;#34;); Javascript的單線程是指一個瀏覽器行程（process）只有一個JS的執行線程（但不代表瀏覽器是單線程），同一個時段內只會有一段代碼在執行，代表一次只能完成一件事，如果有多件事，就代表你要排隊，一件一件的處理，如果有一件事卡死或要做很久，就代表下面的事永遠不會執行，優點是簡單，環境單純，但缺點是如果其中一個事件很耗時間，會拖慢整個程式執行。
Javascript將事件分為兩種同步（Synchronous）與非同步（Asynchronous）來解決單線程的缺點。
同步（ Synchronous ） 就是一個完成換下一個，下一個完再換下下一個處理，程式執行順序與任務的排列順序是相同的，如下程式碼。
console.log(1); console.log(2); console.log(3); 輸出結果。
	１ ２ ３ 非同步（ Asynchronous ） 非同步為每一個任務都有一個CallBack，代表每個任務執行完後會執行該CallBack而不是執行下一個任務，因此程式執行順序與任務的排列順序是不相同的，下列以ajax為範例。
	console.log(1); ＄.ajax({ url:&amp;quot;tests/1&amp;quot; success:function(data){ console.log(2); }	}) console.log(3); 輸出結果。
	１ ３ ２ 也就是說，假設該ajax很耗時，你可以不用等到ajax執行完，才跑console.log(3)，而是先給它個callback等ajax執完後自動插入回線程中執行console.log(2)。
為什麼 Javascript 是單線程 ? Javascript最初做為瀏覽器腳本語言，主要用途在於和使用者戶動與操作DOM，也因此如果該語言為多線程語言就會發生不少混亂，例如Javascript有兩個線程，一個線程針對某個DOM節點新增某些內容，而另一線程為刪除該節點，那瀏覽器要以那個為主?所以為了避免這些亂，因此Javascript被設計為單線程語言。
HTML5提出了Web Worker的標準，web worker是運行在瀏覽器的後台，並且子線程完全由主線程控制，並且不得操作 DOM，所以該標準並沒有影響javascript為單線程的本質。  Javascript 為單線程，又怎著非同步的執行呢 ? 通常這種語言為單線程，但又可以處理非同步的語言都有個一種共同點，那就是事件驅動event driven）機制，一般是由通過事件循環(Event Loop)與事件隊列（Event Queue）來實現。
參考資料  http://www.ruanyifeng.com/blog/2012/12/asynchronous%EF%BC%BFjavascript.html http://sporto.</description>
    </item>
    
    <item>
      <title>物件導向系列菜單 11-『 泛型 ( Generics ) 』</title>
      <link>https://mark-lin.com/posts/20150826/</link>
      <pubDate>Wed, 26 Aug 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150826/</guid>
      <description>什麼是泛型呢 什麼是泛型呢~? 這個東西有看過吧，你有時後會在程式碼裡看到List這種寫法， 這代表List串列中，你可以存放『T』型別，例如List就是裡面存放string，List就是裡面存放int。也被稱為型別參數。事實上我們可以將範例想成簡單點，那就是一個可以讓你自由決定型別的功能。
為什麼要有泛型呢 假設需要我們建立一個ArrayList，但確發現要取出值都需要轉型，這是因為當你將某個物件存入ArrayList集合時，它的型別就隱含轉換成object了。只要是命名空system.Collection的集合類別都是如何(stack之類的)
轉型是沒什麼問題，但在處理集合時，常常都會需要使用迴圈來取出或存入集合元素，假設迴歸數很大很大的話，那就會對程式的執行速度產生一定的影響了(不過不嚴重)。還有一點就是，缺泛編輯時期的安全檢查。
泛型的優點   可以用不同的型別去做相同動作的事情如我上述程式碼的這段。   可以減少Boxing與UnBoxing，使效能增加。
  讓程式碼更有彈性、重複使用程式碼。
  泛型類別和方法 這邊寫個泛型的小範例，來知道一下大概的寫法。下列程式碼建立Car類別，其中Class Car&amp;lt;T,T1&amp;gt;被稱為『泛型類別』，而T power 被稱為『泛型參數』。
輸出結果
類別參數的條件約束 既然泛型可以讓我們自由決定型別，但有時候太自由也不太好，那我們要著麼樣來約束呢?如下，其中『where』就是就是限制的關鍵字，而『T』就是受限制的型別參數，最後Class就是限制的內容。
下列程式碼為多參數限定。
其中限制的內容請參考下圖，來源為MSDN。
我們這邊在來寫個簡單的小程式。
建立個Car類別，並且有二個型別參數T與T1，並限制T型別參數必預是『參數型別』。
然後我們用兩種寫法來測試看看，第一種為T指定為 string型別，第二種為T指定為int型別。 其中，string型別會正確執行，這邊別忘了string為參考型別喔! 而第二種int則會出錯。
注: 如果不知道實值與參考是啥的可以參考一下小弟寫的這篇實值型別與參考型別的記憶體配置
未繫結的型別參數有幾項注意事項  無法使用!= 和 == 運算子，因為不能確定實體的型別引數是否會支援這些運算子。 這些參數可與System.Object相互轉換或明確轉換成任何介面型別。 你可以與NULL比較。如果將未繫結的型別參數與NULL比較，那麼當型別引數為實值型別時一定會傳FALSE。  參考資料  http://frankiestudy.blogspot.tw/2012/09/c.html http://msdn.microsoft.com/zh-tw/library/512aeb7t.aspx http://msdn.microsoft.com/zh-tw/library/d5x73970.aspx http://msdn.microsoft.com/zh-tw/library/kx37x362.aspx  </description>
    </item>
    
    <item>
      <title>物件導向系列菜單 10 -『 委派 ( Delegate ) 』</title>
      <link>https://mark-lin.com/posts/20150825/</link>
      <pubDate>Tue, 25 Aug 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150825/</guid>
      <description>什麼是委派  委派是以特定參數清單和傳回型別表示對方法的參考型別。 當您具現化委派時您可以使其執行個體具有相容簽章和傳回型別的所有方法。(MSDN)
 白話文來說，委派方法是一種參考型別(Type)，可以用來將方法當做引數傳遞給其他方法。
圖為委派型別的宣告範例
為什麼要用委派 從類別的設計者來看，在設計類別時，可能會碰到某個方法需要額外處理，但又不想把該處理想在這個類別裡，因為有可能變化很多，又或是無法預先得知處理的規則。 (註 : 這部份主要參考Huan-Lin的文章)
簡單用個情境來說明委派的用法 維京老大有一艘戰船，這艘船是老大專門買來給小弟用去打劫的(主要原因是因為老大怕死和麻煩)，為了維護自身利益，老大定了一個用船契約範本，上面定了兩個規定分別為回傳string型別與輸入一個string型別的參數，小弟需要自行寫一份參考老大契約範本的契約，裡面一定要符合這兩項規定，小弟才能拿這份契約去和老大借船，然後執行自行寫的打劫計畫。
依上述的模擬情境來寫個程式碼來看看 ~首先先宣告一個委派方法，這就是維京老大所寫的契約範本，上面規定，小弟的契約裡需要符合兩個條件分別為回傳string型別與 輸入一個string型別的參數
public delegate string Attack(string str); 然後小弟1這時想要和老大借船來幹一票大的~~ ，所以開始寫契約，如下，有沒有符合老大的範本要求呢??『回傳string型別』與『輸入一個string型別的參數』，嗯都有，拿去給老大看應該會答應!
public string Attack_Plan1(string str) { //這邊可以小弟可自訂自已的攻擊計畫  //反正最後有回傳黃金(string型別)給老大就好  Console.WriteLine(str); return &amp;#34;給老大的黃金&amp;#34; ; } 這時小弟1就跑去和老大借船. 老大:嗯很好有符合，~ 努力去(為我)打劫吧!
private void button1_Click(object sender, EventArgs e) { //C# 2.0寫法  Attack attack_plan = Attack_Plan1; GoToAttackWithBattleShip(attack_plan, &amp;#34;Attack&amp;#34;); } private void GoToAttackWithBattleShip(Attack attack_plan, string str) { textBox1.Text = attack_plan(str); } 其中這時又來個小弟2，他也想要船，但他沒注意到契約範本規則，然後建立了下面的契約，不符合傳入一個string型別的參數</description>
    </item>
    
    <item>
      <title>物件導向系列菜單 9-『 物件導向特性-封裝 ( Encapsulation ) 』</title>
      <link>https://mark-lin.com/posts/20150824/</link>
      <pubDate>Mon, 24 Aug 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150824/</guid>
      <description>存取修飾詞    存取修飾詞 說明     public 無任何存取限制。   internal 只能在自已類別與專案(組件)中其它類別進行存取。(不包含其它專案)。   protected 只能在自已類別和子類別中存取。   protected internal 只能在目前專案(組件)與子類別存取。   private 在自已類別存取。    封裝的使用 封裝的使用時機 :
 封裝表示讓一個類別對其他類別隱藏特定資訊，這樣有助於防止程式發生臭蟲。 當你回頭編程已經有好一陣子沒有沒看程式碼時，很容易就會忘記當初你要它做什麼，那正是封裝能夠大展身手的地方。  封裝的精神
 只要在必要時才讓欄位與方法為public 將物件想成黑箱。你並不在意該方法到底是怎麼運作的。你只在意它接受你提供的輸入，並回傳正確的結果。 減少程式BUG，因為相依性減少了。  封裝性不良好類別 首先我們先建立個，幾乎沒有使用到封裝的類別BagFamer，這個類別主要是計算該農場需要多少袋飼料來養牛。
農場所需飼料(袋) = 牛隻數量 * 每隻牛需要的飼料 BagOfFeed = NumberOfCows * FeedMulitplier
三個欄位
 FeedMulitplier : 存放一隻牛需要多少袋飼料。 NumberOfCows : 存放這個農場有幾隻牛。 BagOfFeed : 存放這個農場需要多少飼料。  Tip.共同遵循的約定與慣例。</description>
    </item>
    
    <item>
      <title>物件導向系列菜單 8-『 屬性 ( Properties ) 與欄位 ( Field ) 和存取子 ( accessor ) 』</title>
      <link>https://mark-lin.com/posts/20150823/</link>
      <pubDate>Sun, 23 Aug 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150823/</guid>
      <description>區別何謂屬性與何謂欄位 先來說說欄位，欄位(Field)是一個任意型別(Type)的變數，直接在類別(Class)與結構(struct)中宣告。(註: 型別(Type)就是Int 、bool這些在變數前的東東)
public class Car { //這個就是欄位(Field)  private int PeopleNumber; } 而屬性呢?，屬性(Properties)是欄位和方法的綜合體，也是直接在類別(Class)與結構(struct)中宣告，它可以提供完整的控制，你可以控制它為只能讀或寫，有時會與private 欄位(Filed)一起使用，怎麼控制呢，這就需要介紹存取子(accessor)。
public class Car { //這個就是屬性  public int PeopleNumber { get; set;} }  存取子 ( accessor ) 屬性的存取子包含讀取 ( Get )和 寫入 ( Set )。
Get存取子 get存取子可以用於傳回欄位值或計算它並且回傳。
下列程式碼為Test 類別，有公開屬性PeopleNumber，設定為『只能讀』，但寫成降出錯喔，因為一定要有初始值。
class Test { public int PeopleNumber { get ;} } 要改成下列程式碼，才正確。
class Test { //設定唯時一定要給它值。不然會出錯。  public int PeopleNumber { get {return 10 ;} } } 試試看寫入值的話，則有人會打斷你的腿。</description>
    </item>
    
    <item>
      <title>物件導向系列菜單7-『 部分類別 ( Partial Class ) 』</title>
      <link>https://mark-lin.com/posts/20150822/</link>
      <pubDate>Sat, 22 Aug 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150822/</guid>
      <description>部份類別 ( Partial Class ) 部分類別使用時機大都在處理大型專案時，將類別分散至個別檔案，可讓多位程式設計師進行運作。
程式碼說明建立部分類別的方法，就是加上關鍵子『partial』。
//部分類別(Employee其中一個組件)  public partial class Employee { public string PracticeTime; public void DoWork() { } } //部分類別(Employee其中一個組件)  public partial class Employee { public string GoToDinner() { return &amp;#34;GoToDinner&amp;#34; ; } } protected void Page_Load(object sender, EventArgs e) { Employee Employ = new Employee { PracticeTime = &amp;#34;100&amp;#34; TextBox1.Text = Employ.GoToDinner(); TextBox6.Text = Employ.PracticeTime; } 執行結果
	GoToDinner 100 部分類別的特性  所有組件都必需在相同的命名空間(Namespace) 如果有任何組件宣告為abstract則被視為抽象，如果宣告為Sealed則被視為密封，如果其中一繼承某基底類別，整個型別都會繼承 任何組件都可以指定不同的基底介面，最後的型別會實作所有部份宣告的任何介面  部份方法的特性  部分方法的簽章是在部分型別中的一部分定義，而其實作是在型別的另一部分中定義。</description>
    </item>
    
    <item>
      <title>物件導向系列菜單 6-『 Interface 介面 』</title>
      <link>https://mark-lin.com/posts/20150821/</link>
      <pubDate>Fri, 21 Aug 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150821/</guid>
      <description>Interface概念 介面(Interface)你可以將他想成是商品契約，所有要商品的交易，都要經過這個商品契約來決定，例如裡面說交易單位是XXX，就是XXX，裡面如果說要在那交易，就是在那交易，不然有人(編譯器)會打斷你的腿的…很恐怖的…
Interface使用時機
 有時候，你必須根據物件能夠做什麼來將它們歸類。 想要做到類似C++中的多重繼承功能。  程式說明 建立UnitityCar的類別，該類別為未來車的概念。它可以飛(Fly)和跑(Run)，但如果這時讓他繼承飛機類別讓他可以飛，有些飛機的屬性與方法不需用到，但如果在車類別新增飛的動作，但其它種車不會飛啊…。所以這時就需要用到Interface。
首先新增兩個Interface分別為ICanFly 與 IDrive。ICanFly定義飛的方法Fly() 與飛的速度FlySpeed。IRun定義跑的方法Run()與跑的速度RunSpeed (註:新增IRun Interface只是要給各位官爺看多個Interface使用)
//宣告ICanFly介面  interface ICanFly { //介面不可以包含『欄位』。  string flySpeed { get ;} //介面不存放資料，因為不能增加欄位  //string test = &amp;#34;Hello&amp;#34;;  //任何實作該介面的類別必需具備一個接受Fly()的方法。  string fly(); } //宣告IDrive介面  interface IDrive { //driveSpeed屬性，但介面不儲存資料，所以不會有欄位。  string driveSpeed { get ; set; } //任何實作此介面的類別，必需具備接受 drive() 方法。  string drive(); } UnitityCar 繼承基底類別 Car，並實作 IDrive 與 IcanFly ，記得任何實作介面的類別都必需符合它的方法與屬性。
//繼承基底類別Car  //並實作IDrive與IcanFly Interface  //假設UnitityCar在未來，他有兩個種類方法Drive與Fly。  public class UnitityCar :Car , IDrive, ICanFly { //由於在未來飛行速度(FlySpeed)，有限制100，  //因此設立唯讀的FlySpeed，不給人修改。  //一定要有!</description>
    </item>
    
    <item>
      <title>物件導向系列菜單 5 -『 物件導向特性-繼承 ( Inheritance ) 4 - abstract 』</title>
      <link>https://mark-lin.com/posts/20150820/</link>
      <pubDate>Thu, 20 Aug 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150820/</guid>
      <description>使用修飾詞abstract，限定類別只能被繼承 在Class Car 前增加abstract，表是該類別只能繼承、不能實作，也被稱為抽象類別。
//父類別  //增加『abstract』修飾詞，讓該類別只能繼承。不能實作。  public abstract class Car { //車子的速度  protected string Speed; //車子的顏色  protected string Color; // 定義建構子，預設Speed為50，Color為Blue  public Car() { Speed = &amp;#34;50&amp;#34;; Color = &amp;#34;Blue&amp;#34;; } //定義車子移動的方法。  public string DriveCar(string a) { return &amp;#34;正在開『&amp;#34; + Color + &amp;#34;』的車&amp;#34; + &amp;#34;時速『&amp;#34; + Speed + &amp;#34;』在移動&amp;#34; ; } } 抽像類別的特性  抽象類別不能實體化。 抽象類別可能包含抽象方法與存取子。 無法使用『Sealed』修飾詞，因為兩個意思完全相反。 衍生自抽象類別的非抽象類別必須包含所有繼承抽象方法和存取子的實作。  抽象方法的使用 抽象方法只能存在於抽象類別中。不然會出錯喔。
//父類別  //增加『abstract』修飾詞，讓該類別只能繼承。不能實作。  public abstract class Car { //車子的速度  protected string Speed; //車子的顏色  protected string Color; // 定義建構子，預設Speed為50，Color為Blue  public Car() { Speed = &amp;#34;50&amp;#34;; Color = &amp;#34;Blue&amp;#34;; } //定義車子移動的方法。  //抽象方法宣告，沒有提供實際的實作，因此並沒有方法主題。  //抽象方法只能存在於抽象類別中。  public abstract string DriveCar(); } 子類別，使用Overried，來進行抽象類別覆寫。</description>
    </item>
    
    <item>
      <title>物件導向系列菜單 4 -『 物件導向特性-繼承(Inheritance) 3 - Sealed 』</title>
      <link>https://mark-lin.com/posts/20150819/</link>
      <pubDate>Wed, 19 Aug 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150819/</guid>
      <description>特點 1 - 使用 Sealed 關鍵字使類別不能被繼承 下列為簡單的Sealed範例。
父類別Class Car ，有兩個屬性分別為Speed與Color，並自行訂定建構子Car() ，以及DriveCar()方法，在這範例中我們將Car類別，新增Sealed修飾詞，主要目的為不然其它類別繼承。
/// &amp;lt;summary&amp;gt;  /// 父類別  /// &amp;lt;/summary&amp;gt;  public sealed class Car //增加Sealed  { //車子的速度  public string Speed; //車子的顏色  public string Color; /// &amp;lt;summary&amp;gt;  /// 定義建構子，預設Speed為50，Color為Blue  /// &amp;lt;/summary&amp;gt;  public Car() { Speed = &amp;#34;50&amp;#34;; Color = &amp;#34;Blue&amp;#34;; } //定義車子移動的方法  public string DriveCar() { return &amp;#34;正在開『&amp;#34; + Color + &amp;#34;』的車&amp;#34; + &amp;#34;時速『&amp;#34; + Speed + &amp;#34;』在移動&amp;#34; ; } } 子類別BMWCar 繼承父類別Car，並有自行定義建構子BMWCar() ，以及BMWPower屬性。由於父類別Car有加Sealed因此無法被繼承。依下列程式碼，會找不到父類別的Speed與Color，而出現錯誤訊息。</description>
    </item>
    
    <item>
      <title>物件導向系列菜單 3 -『 物件導向特性-繼承 ( Inheritance ) 2- Virtual 與 Override 』</title>
      <link>https://mark-lin.com/posts/20150818/</link>
      <pubDate>Tue, 18 Aug 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150818/</guid>
      <description>Virtual 修飾詞  子類別的方法名稱和父類別的方法名稱一樣，著麼辦呢 ?
 virtual 關鍵字的用途是修改方法、屬性或事件宣告，以及允許在衍生類別中給予覆寫。通常使用的時機是在未來預期該方法可能會被子類別覆寫(override)，則此方法必須宣告Virtual。
//父類別  public class Car { //車子的速度  public string Speed; //車子的顏色  public string Color; // 定義建構子，預設Speed為50，Color為Blue  public Car() { Speed = &amp;#34;50&amp;#34;; Color = &amp;#34;Blue&amp;#34;; } //定義車子移動的方法。  //在該方法加上Virtual，讓子類別可以覆寫該方法。  public virtual string DriveCar() { return &amp;#34;正在開『&amp;#34; + Color + &amp;#34;』的車&amp;#34; + &amp;#34;時速『&amp;#34; + Speed + &amp;#34;』在移動&amp;#34; ; } } Override 修飾詞 Overrride修飾詞為需要用來修改或擴充父類別的方法、屬性，則需要給予該方法或屬性進行宣告。
// 子類別繼承Car  public class BMWCar :Car { //BMWCar類別建構子  public BMWCar() { Speed = &amp;#34;BMW500&amp;#34;; Color = &amp;#34;BWM_Red&amp;#34;; } //BMW的屬性引擎  public string BMWPower; //定義車子移動的方法  //使用存取修飾詞Overried，來進行覆寫  public override string DriveCar() { return &amp;#34;正在開『&amp;#34; + Color + &amp;#34;』的車&amp;#34; + &amp;#34;時速『&amp;#34; + Speed + &amp;#34;』在移動&amp;#34; + &amp;#34;『Override』&amp;#34; ; } } 執行結果 正在開『BMW_Red』的車時速『BWM500』在移動『Override』 Override 修飾詞特性 注意 1 你不能覆寫非虛擬或靜態方法。被覆寫的父類別方法必須是Virtual、abstract、Override。</description>
    </item>
    
    <item>
      <title>物件導向系列菜單 2-『 物件導向特性-繼承 ( Inheritance ) 1 』</title>
      <link>https://mark-lin.com/posts/20150817/</link>
      <pubDate>Mon, 17 Aug 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150817/</guid>
      <description>繼承為物件導向的三大特性之一(封裝、多型)，你可以想像老爸與兒子的關係，兒子會繼承老爸所擁有的特徵(屬性)和)財產(方法)(現實上不一定，但請官爺們想簡單點)，兒子可能會有老爸的大鼻子或小嘴巴，並且可以開著老爸的車(財產)出去玩，這就是繼承。
繼承父類別(基底類別 Base Class)的類別就被稱為子類別(衍生類別 Derived Class)，子類別繼承了父類別的屬性與方法。
繼承的傳遞 : 你也會繼承到你阿公的東西 繼承是可以傳遞，Class C 繼承至 Class B，而 Class B 繼承至 Class A，則 Class C 會繼承至 Class A、B 白話文就是，你也會繼承到你阿公的東西。
以下為繼承程式碼 /// &amp;lt;summary&amp;gt;  /// 父類別  /// &amp;lt;/summary&amp;gt;  public class Car { //車子的速度  public string Speed; //車子的顏色  public string Color; /// &amp;lt;summary&amp;gt;  /// 定義建構子，預設Speed為50，Color為Blue  /// &amp;lt;/summary&amp;gt;  public Car() { Speed = &amp;#34;50&amp;#34;; Color = &amp;#34;Blue&amp;#34;; } //定義車子移動的方法  public string DriveCar() { return &amp;#34;正在開『&amp;#34; + Color + &amp;#34;』的車&amp;#34; + &amp;#34;時速『&amp;#34; + Speed + &amp;#34;』在移動&amp;#34; ; } } /// &amp;lt;summary&amp;gt;  /// 子類別繼承Car  /// &amp;lt;/summary&amp;gt;  public class BMWCar :Car { //BMW的屬性引擎  public string BMWPower; } 以下紅色框框的部份就是從父類別Car繼承而來的屬性與方法</description>
    </item>
    
    <item>
      <title>物件導向系列菜單 1-『 基本概念 』</title>
      <link>https://mark-lin.com/posts/20150816/</link>
      <pubDate>Sun, 16 Aug 2015 19:51:35 +0800</pubDate>
      <author>h091237557@gmail.com (marklin)</author>
      <guid>https://mark-lin.com/posts/20150816/</guid>
      <description>物件導向基本概念為『類別』與『物件』 基本上保哥這篇文章已經寫的很清楚了保哥 (保哥)，但知識的學習還是要經過自已的腦袋與手加眼睛，所以小弟我也用自已的意思來表達這兩個東西的概念。
類別 小弟是把類別想成是『汽車藍圖』，它定義好了汽車的屬性與方法， 但它沒有實體(Instance)，也就是說，你必須實作這張汽車藍圖它才能產生實體(可以開的車~)。
class Car { //定義車子的速度欄位  public int Speed; //車子的顏色欄位  public string Color; //定義車子移動的方法  public string DriveCar() { return &amp;#34;正在開『&amp;#34; + Color + &amp;#34;』的車&amp;#34; + &amp;#34;時速『&amp;#34; + Speed.ToString() + &amp;#34;』在移動&amp;#34;; } } 物件 就是實際做出來的車。以程式術語來說，運用汽車藍圖做出車的過程就是所謂的 『實體化』系統會自動給予物件記憶體。以下為實體化的C#程式碼。
//實體化Car類別為MyCar物件，並設定欄位Speed為100、Color為Red 	Car MyCar = new Car { Speed = 100, Color = &amp;#34;red&amp;#34; }; TextBox1.Text = MyCar.DriveCar(); 執行結果 正在開『red』的車時速『100』在移動  建構子或建構函式 ( constructor ) 其中Car MyCar = new Car ，即為產生一個名叫MyCar的Car實體。 new Car 除了產生實體，它還會幫你呼叫一個名為Car()的方法。該方法就是所謂的建構子(constructor)。</description>
    </item>
    
  </channel>
</rss>